publication venue: arXiv.org
title: ClimaBench: A Benchmark Dataset For Climate Change Text Understanding in English
authors: Tanmay Laud, Daniel M. Spokoyny, Thomas W. Corringham, Taylor Berg-Kirkpatrick
year: 2023
tldr: Climate Change Benchmark (ClimaBench) is introduced, a benchmark collection of existing disparate datasets for evaluating model performance across a diverse set of CC NLU tasks systematically and an analysis of several generic and CC-oriented models answering whether tuning on domain text offers any improvements across these tasks.
abstract: The topic of Climate Change (CC) has received limited attention in NLP despite its real world urgency. Activists and policy-makers need NLP tools in order to effectively process the vast and rapidly growing textual data produced on CC. Their utility, however, primarily depends on whether the current state-of-the-art models can generalize across various tasks in the CC domain. In order to address this gap, we introduce Climate Change Benchmark (ClimaBench), a benchmark collection of existing disparate datasets for evaluating model performance across a diverse set of CC NLU tasks systematically. Further, we enhance the benchmark by releasing two large-scale labelled text classiﬁcation and question-answering datasets curated from publicly available environmental disclosures. Lastly, we provide an analysis of several generic and CC-oriented models answering whether ﬁne-tuning on domain text offers any improvements across these tasks. We hope this work provides a standard assessment tool for research on CC text data.
