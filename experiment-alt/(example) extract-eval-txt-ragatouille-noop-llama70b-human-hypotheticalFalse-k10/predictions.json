[
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Assistant Professor",
    "index":0,
    "Q":"What is Yonatan Bisk's professional title?",
    "A":"Assistant Professor",
    "category":"directory",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Yonatan Bisk.txt"
        },
        "page_content":"Name: Yonatan Bisk\nTitle: Assistant Professor\nEmail ybisk@cs.cmu.edu\nPhone: \nOffice: Gates & Hillman Centers\nInterests: Grounding, RoboNLP, Vision and Language, Embodiment, Unsupervised Learning",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Reasoning about the Unseen for Efficient Outdoor Object Navigation.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Reasoning about the Unseen for Efficient Outdoor Object Navigation\nauthors: Quanting Xie, Tianyi Zhang, Kedi Xu, M. Johnson-Roberson, Yonatan Bisk\nyear: 2023\ntldr: A new task OUTDOOR is introduced, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain are introduced.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Computational Language Acquisition with Theory of Mind.txt"
        },
        "page_content":"publication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Computational Language Acquisition with Theory of Mind.txt"
        },
        "page_content":"publication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Tom Mitchell | Publication | Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nauthors: Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, J. Sinapov\nyear: 2023\ntldr: This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Emma Strubell | Publication | The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nauthors: Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell\nyear: 2023\ntldr: This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nauthors: Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell\nyear: 2023\ntldr: This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-777 Multimodal Machine Learning.txt"
        },
        "page_content":"<start course metadata for 11-777 Multimodal Machine Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Multimodal Machine Learning\nCourse Number: 11-777\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Yonatan Bisk\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-777 Multimodal Machine Learning>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Yonatan Bisk.txt"
        },
        "page_content":"Name: Yonatan Bisk\nTitle: Assistant Professor\nEmail ybisk@cs.cmu.edu\nPhone: \nOffice: Gates & Hillman Centers\nInterests: Grounding, RoboNLP, Vision and Language, Embodiment, Unsupervised Learning",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Reasoning about the Unseen for Efficient Outdoor Object Navigation.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Reasoning about the Unseen for Efficient Outdoor Object Navigation\nauthors: Quanting Xie, Tianyi Zhang, Kedi Xu, M. Johnson-Roberson, Yonatan Bisk\nyear: 2023\ntldr: A new task OUTDOOR is introduced, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain are introduced.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Computational Language Acquisition with Theory of Mind.txt"
        },
        "page_content":"publication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Computational Language Acquisition with Theory of Mind.txt"
        },
        "page_content":"publication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Tom Mitchell | Publication | Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nauthors: Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, J. Sinapov\nyear: 2023\ntldr: This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Emma Strubell | Publication | The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nauthors: Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell\nyear: 2023\ntldr: This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nauthors: Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell\nyear: 2023\ntldr: This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-777 Multimodal Machine Learning.txt"
        },
        "page_content":"<start course metadata for 11-777 Multimodal Machine Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Multimodal Machine Learning\nCourse Number: 11-777\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Yonatan Bisk\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-777 Multimodal Machine Learning>",
        "type":"Document"
      }
    ],
    "model_output":"\nYonatan Bisk's professional title is Assistant Professor.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"What is Yonatan Bisk's professional title?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nName: Yonatan Bisk\nTitle: Assistant Professor\nEmail ybisk@cs.cmu.edu\nPhone: \nOffice: Gates & Hillman Centers\nInterests: Grounding, RoboNLP, Vision and Language, Embodiment, Unsupervised Learning\n-----\npublication venue: arXiv.org\ntitle: Reasoning about the Unseen for Efficient Outdoor Object Navigation\nauthors: Quanting Xie, Tianyi Zhang, Kedi Xu, M. Johnson-Roberson, Yonatan Bisk\nyear: 2023\ntldr: A new task OUTDOOR is introduced, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain are introduced.\n-----\npublication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\n-----\npublication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\n-----\npublication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.\n-----\npublication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.\n-----\npublication venue: arXiv.org\ntitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nauthors: Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, J. Sinapov\nyear: 2023\ntldr: This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.\n-----\npublication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nauthors: Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell\nyear: 2023\ntldr: This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.\n-----\npublication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nauthors: Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell\nyear: 2023\ntldr: This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.\n-----\n<start course metadata for 11-777 Multimodal Machine Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Multimodal Machine Learning\nCourse Number: 11-777\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Yonatan Bisk\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-777 Multimodal Machine Learning>\n-----\n\n### Response ###\n\nUser: What is Yonatan Bisk's professional title?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Principal Systems Scientist",
    "index":1,
    "Q":"What is Ralf Brown's professional title?",
    "A":"Principal Systems Scientist",
    "category":"directory",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Ralf Brown.txt"
        },
        "page_content":"Name: Ralf Brown\nTitle: Principal Systems Scientist\nEmail ralf@andrew.cmu.edu\nPhone: 412-268-8298\nOffice: 5711 Gates & Hillman Centers\nInterests: Information Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Translation, Natural Language Processing and Computational Linguistics",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-601 Coding Boot Camp.txt"
        },
        "page_content":"<start course metadata for 11-601 Coding Boot Camp>\nSemester: Fall 2023 (aka F23)\nCourse Name: Coding Boot Camp\nCourse Number: 11-601\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DH 2315\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-601 Coding Boot Camp>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-927 MIIS Capstone Project.txt"
        },
        "page_content":"<start course metadata for 11-927 MIIS Capstone Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Project\nCourse Number: 11-927\nDepartment: Language Technologies Institute\nNumber of Units: 36\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-927 MIIS Capstone Project>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-696 MIIS Capstone Planning Seminar.txt"
        },
        "page_content":"<start course metadata for 11-696 MIIS Capstone Planning Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Planning Seminar\nCourse Number: 11-696\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-696 MIIS Capstone Planning Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-696 MIIS Capstone Planning Seminar.txt"
        },
        "page_content":"<start course metadata for 11-696 MIIS Capstone Planning Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Name: MIIS Capstone Planning Seminar\nCourse Number: 11-696\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-696 MIIS Capstone Planning Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-920 Independent Study_ Breadth.txt"
        },
        "page_content":"Instructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Anthony Tomasic, Barnabas Poczos, Bhiksha Ramakrishnan, Carolyn Rose, David Mortensen, Dokyun Lee, Emma Strubell, Eric Nyberg, Eric Xing, Graham Neubig, Hyaejin Oh, Instructor TBA, Jack Mostow, Jamie Callan, Jason Hong, Justine Cassell, Katia Sycara, Lorraine Levin, Louis-Philippe Morency, Matthew Gormley, Maxine Eskenazi, Ralf Brown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-925 Independent Study_ Area.txt"
        },
        "page_content":"Number of Units: N\/A\nPrerequisites: None\nInstructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Anthony Tomasic, Bhiksha Ramakrishnan, Carolyn Rose, Christopher Langmead, Eduard Hovy, Eric Nyberg, Eric Xing, Eugene Fink, Florian Metze, Graham Neubig, Instructor TBA, Jack Mostow, Jamie Callan, Justine Cassell, Katia Sycara, Kenneth Koedinger, Lorraine Levin, Louis-Philippe Morency, Madhavi Ganapathiraju, Marcel Just, Maxine Eskenazi, Ralf Brown, Rita Singh, Robert Frederking, Ronald Rosenfeld, Scott Fahlman, Stacey Young, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Ziv Bar-Joseph\nRooms: DNM DNM",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-929 Masters Thesis II.txt"
        },
        "page_content":"Course Number: 11-929\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Alon Lavie, Carolyn Rose, Christopher Langmead, David Mortensen, Eric Nyberg, Eric Xing, Florian Metze, Instructor TBA, Jack Mostow, Jamie Callan, Justine Cassell, Kathleen Carley, Katia Sycara, Kenneth Koedinger, Lorraine Levin, Madhavi Ganapathiraju, Maxine Eskenazi, Noah Smith, Ralf Brown, Rita Singh, Robert Frederking, Ronald Rosenfeld, Scott Fahlman, Stephen Smith, TBA, Tanja Schultz, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Ziv Bar-Joseph",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 24-695 Academic and Professional Development for Mechanical Engineering Masters Student.txt"
        },
        "page_content":"<start course metadata for 24-695 Academic and Professional Development for Mechanical Engineering Masters Student>\nSemester: Fall 2023 (aka F23)\nCourse Name: Academic and Professional Development for Mechanical Engineering Masters Student\nCourse Number: 24-695\nDepartment: Mechanical Engineering\nNumber of Units: 1\nPrerequisites: None\nInstructors: Melissa Brown\nRooms: HOA 160\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 24-695 Academic and Professional Development for Mechanical Engineering Masters Student>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-920 Independent Study_ Breadth.txt"
        },
        "page_content":"Brown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia Tsvetkov, Zachary Lipton, Zico Kolter",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Ralf Brown.txt"
        },
        "page_content":"Name: Ralf Brown\nTitle: Principal Systems Scientist\nEmail ralf@andrew.cmu.edu\nPhone: 412-268-8298\nOffice: 5711 Gates & Hillman Centers\nInterests: Information Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Translation, Natural Language Processing and Computational Linguistics",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-601 Coding Boot Camp.txt"
        },
        "page_content":"<start course metadata for 11-601 Coding Boot Camp>\nSemester: Fall 2023 (aka F23)\nCourse Name: Coding Boot Camp\nCourse Number: 11-601\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DH 2315\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-601 Coding Boot Camp>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-927 MIIS Capstone Project.txt"
        },
        "page_content":"<start course metadata for 11-927 MIIS Capstone Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Project\nCourse Number: 11-927\nDepartment: Language Technologies Institute\nNumber of Units: 36\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-927 MIIS Capstone Project>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-696 MIIS Capstone Planning Seminar.txt"
        },
        "page_content":"<start course metadata for 11-696 MIIS Capstone Planning Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Planning Seminar\nCourse Number: 11-696\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-696 MIIS Capstone Planning Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-696 MIIS Capstone Planning Seminar.txt"
        },
        "page_content":"<start course metadata for 11-696 MIIS Capstone Planning Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Name: MIIS Capstone Planning Seminar\nCourse Number: 11-696\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-696 MIIS Capstone Planning Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-920 Independent Study_ Breadth.txt"
        },
        "page_content":"Instructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Anthony Tomasic, Barnabas Poczos, Bhiksha Ramakrishnan, Carolyn Rose, David Mortensen, Dokyun Lee, Emma Strubell, Eric Nyberg, Eric Xing, Graham Neubig, Hyaejin Oh, Instructor TBA, Jack Mostow, Jamie Callan, Jason Hong, Justine Cassell, Katia Sycara, Lorraine Levin, Louis-Philippe Morency, Matthew Gormley, Maxine Eskenazi, Ralf Brown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-925 Independent Study_ Area.txt"
        },
        "page_content":"Number of Units: N\/A\nPrerequisites: None\nInstructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Anthony Tomasic, Bhiksha Ramakrishnan, Carolyn Rose, Christopher Langmead, Eduard Hovy, Eric Nyberg, Eric Xing, Eugene Fink, Florian Metze, Graham Neubig, Instructor TBA, Jack Mostow, Jamie Callan, Justine Cassell, Katia Sycara, Kenneth Koedinger, Lorraine Levin, Louis-Philippe Morency, Madhavi Ganapathiraju, Marcel Just, Maxine Eskenazi, Ralf Brown, Rita Singh, Robert Frederking, Ronald Rosenfeld, Scott Fahlman, Stacey Young, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Ziv Bar-Joseph\nRooms: DNM DNM",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-929 Masters Thesis II.txt"
        },
        "page_content":"Course Number: 11-929\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Alon Lavie, Carolyn Rose, Christopher Langmead, David Mortensen, Eric Nyberg, Eric Xing, Florian Metze, Instructor TBA, Jack Mostow, Jamie Callan, Justine Cassell, Kathleen Carley, Katia Sycara, Kenneth Koedinger, Lorraine Levin, Madhavi Ganapathiraju, Maxine Eskenazi, Noah Smith, Ralf Brown, Rita Singh, Robert Frederking, Ronald Rosenfeld, Scott Fahlman, Stephen Smith, TBA, Tanja Schultz, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Ziv Bar-Joseph",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 24-695 Academic and Professional Development for Mechanical Engineering Masters Student.txt"
        },
        "page_content":"<start course metadata for 24-695 Academic and Professional Development for Mechanical Engineering Masters Student>\nSemester: Fall 2023 (aka F23)\nCourse Name: Academic and Professional Development for Mechanical Engineering Masters Student\nCourse Number: 24-695\nDepartment: Mechanical Engineering\nNumber of Units: 1\nPrerequisites: None\nInstructors: Melissa Brown\nRooms: HOA 160\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 24-695 Academic and Professional Development for Mechanical Engineering Masters Student>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-920 Independent Study_ Breadth.txt"
        },
        "page_content":"Brown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia Tsvetkov, Zachary Lipton, Zico Kolter",
        "type":"Document"
      }
    ],
    "model_output":"\nRalf Brown's professional title is Principal Systems Scientist.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"What is Ralf Brown's professional title?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nName: Ralf Brown\nTitle: Principal Systems Scientist\nEmail ralf@andrew.cmu.edu\nPhone: 412-268-8298\nOffice: 5711 Gates & Hillman Centers\nInterests: Information Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Translation, Natural Language Processing and Computational Linguistics\n-----\n<start course metadata for 11-601 Coding Boot Camp>\nSemester: Fall 2023 (aka F23)\nCourse Name: Coding Boot Camp\nCourse Number: 11-601\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DH 2315\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-601 Coding Boot Camp>\n-----\n<start course metadata for 11-927 MIIS Capstone Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Project\nCourse Number: 11-927\nDepartment: Language Technologies Institute\nNumber of Units: 36\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-927 MIIS Capstone Project>\n-----\n<start course metadata for 11-696 MIIS Capstone Planning Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Planning Seminar\nCourse Number: 11-696\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-696 MIIS Capstone Planning Seminar>\n-----\n<start course metadata for 11-696 MIIS Capstone Planning Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Name: MIIS Capstone Planning Seminar\nCourse Number: 11-696\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-696 MIIS Capstone Planning Seminar>\n-----\nInstructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Anthony Tomasic, Barnabas Poczos, Bhiksha Ramakrishnan, Carolyn Rose, David Mortensen, Dokyun Lee, Emma Strubell, Eric Nyberg, Eric Xing, Graham Neubig, Hyaejin Oh, Instructor TBA, Jack Mostow, Jamie Callan, Jason Hong, Justine Cassell, Katia Sycara, Lorraine Levin, Louis-Philippe Morency, Matthew Gormley, Maxine Eskenazi, Ralf Brown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia\n-----\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Anthony Tomasic, Bhiksha Ramakrishnan, Carolyn Rose, Christopher Langmead, Eduard Hovy, Eric Nyberg, Eric Xing, Eugene Fink, Florian Metze, Graham Neubig, Instructor TBA, Jack Mostow, Jamie Callan, Justine Cassell, Katia Sycara, Kenneth Koedinger, Lorraine Levin, Louis-Philippe Morency, Madhavi Ganapathiraju, Marcel Just, Maxine Eskenazi, Ralf Brown, Rita Singh, Robert Frederking, Ronald Rosenfeld, Scott Fahlman, Stacey Young, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Ziv Bar-Joseph\nRooms: DNM DNM\n-----\nCourse Number: 11-929\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Alon Lavie, Carolyn Rose, Christopher Langmead, David Mortensen, Eric Nyberg, Eric Xing, Florian Metze, Instructor TBA, Jack Mostow, Jamie Callan, Justine Cassell, Kathleen Carley, Katia Sycara, Kenneth Koedinger, Lorraine Levin, Madhavi Ganapathiraju, Maxine Eskenazi, Noah Smith, Ralf Brown, Rita Singh, Robert Frederking, Ronald Rosenfeld, Scott Fahlman, Stephen Smith, TBA, Tanja Schultz, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Ziv Bar-Joseph\n-----\n<start course metadata for 24-695 Academic and Professional Development for Mechanical Engineering Masters Student>\nSemester: Fall 2023 (aka F23)\nCourse Name: Academic and Professional Development for Mechanical Engineering Masters Student\nCourse Number: 24-695\nDepartment: Mechanical Engineering\nNumber of Units: 1\nPrerequisites: None\nInstructors: Melissa Brown\nRooms: HOA 160\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 24-695 Academic and Professional Development for Mechanical Engineering Masters Student>\n-----\nBrown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia Tsvetkov, Zachary Lipton, Zico Kolter\n-----\n\n### Response ###\n\nUser: What is Ralf Brown's professional title?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"B24 Baker-Porter Hall",
    "index":2,
    "Q":"Where is Richard Stern's office?",
    "A":"B24 Baker-Porter Hall",
    "category":"directory",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Affiliated Faculty | Carnegie Mellon University | Richard Stern.txt"
        },
        "page_content":"Name: Richard Stern\nTitle: Professor\nEmail rms@cs.cmu.edu\nPhone: 412-268-2535\nOffice: B24 Baker-Porter Hall\nInterests:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-491 Digital Signal Processing.txt"
        },
        "page_content":"<start course metadata for 18-491 Digital Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Digital Signal Processing\nCourse Number: 18-491\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 18-290\nInstructors: Richard Stern\nRooms: SH 234\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-491 Digital Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-691 Digital Signal Processing.txt"
        },
        "page_content":"<start course metadata for 18-691 Digital Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Digital Signal Processing\nCourse Number: 18-691\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 18-290\nInstructors: Richard Stern\nRooms: SH 234\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-691 Digital Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 57-613 Independent Study in Research.txt"
        },
        "page_content":"<start course metadata for 57-613 Independent Study in Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Independent Study in Research\nCourse Number: 57-613\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA, Richard Stern\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-613 Independent Study in Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 57-970 Music and Technology Seminar.txt"
        },
        "page_content":"<start course metadata for 57-970 Music and Technology Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Music and Technology Seminar\nCourse Number: 57-970\nDepartment: Music\nNumber of Units: 1\nPrerequisites: None\nInstructors: Riccardo Schulz, Richard Stern\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-970 Music and Technology Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 18-792 Advanced Digital Signal Processing.txt"
        },
        "page_content":"<start course metadata for 18-792 Advanced Digital Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Advanced Digital Signal Processing\nCourse Number: 18-792\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: (36-225 or 36-218 or 36-219 or 21-325) and (18-491 or 18-691)\nInstructors: Richard Stern\nRooms: WEH 4625\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-792 Advanced Digital Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-920 Independent Study_ Breadth.txt"
        },
        "page_content":"Brown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia Tsvetkov, Zachary Lipton, Zico Kolter",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 57-572 Music and Technology Project.txt"
        },
        "page_content":"<start course metadata for 57-572 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: Music and Technology Project\nCourse Number: 57-572\nDepartment: Music\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA, Jesse Stiles, Riccardo Schulz, Richard Stern, Thomas Sullivan\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-572 Music and Technology Project>\n\n<start course description for 57-572 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Description: TBA\n<\/end course description for 57-572 Music and Technology Project>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 57-571 Music and Technology Project.txt"
        },
        "page_content":"<start course metadata for 57-571 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: Music and Technology Project\nCourse Number: 57-571\nDepartment: Music\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA, Jesse Stiles, Riccardo Schulz, Richard Stern, Thomas Sullivan\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-571 Music and Technology Project>\n\n<start course description for 57-571 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Description: TBA\n<\/end course description for 57-571 Music and Technology Project>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 57-613 Independent Study in Research.txt"
        },
        "page_content":"<start course metadata for 57-613 Independent Study in Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Independent Study in Research\nCourse Number: 57-613\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Alexa Woloshyn, Andres Cardenes, Instructor TBA, Katherine Pukinskis, Richard Randall, Richard Stern\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-613 Independent Study in Research>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Affiliated Faculty | Carnegie Mellon University | Richard Stern.txt"
        },
        "page_content":"Name: Richard Stern\nTitle: Professor\nEmail rms@cs.cmu.edu\nPhone: 412-268-2535\nOffice: B24 Baker-Porter Hall\nInterests:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-491 Digital Signal Processing.txt"
        },
        "page_content":"<start course metadata for 18-491 Digital Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Digital Signal Processing\nCourse Number: 18-491\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 18-290\nInstructors: Richard Stern\nRooms: SH 234\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-491 Digital Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-691 Digital Signal Processing.txt"
        },
        "page_content":"<start course metadata for 18-691 Digital Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Digital Signal Processing\nCourse Number: 18-691\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 18-290\nInstructors: Richard Stern\nRooms: SH 234\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-691 Digital Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 57-613 Independent Study in Research.txt"
        },
        "page_content":"<start course metadata for 57-613 Independent Study in Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Independent Study in Research\nCourse Number: 57-613\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA, Richard Stern\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-613 Independent Study in Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 57-970 Music and Technology Seminar.txt"
        },
        "page_content":"<start course metadata for 57-970 Music and Technology Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Music and Technology Seminar\nCourse Number: 57-970\nDepartment: Music\nNumber of Units: 1\nPrerequisites: None\nInstructors: Riccardo Schulz, Richard Stern\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-970 Music and Technology Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 18-792 Advanced Digital Signal Processing.txt"
        },
        "page_content":"<start course metadata for 18-792 Advanced Digital Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Advanced Digital Signal Processing\nCourse Number: 18-792\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: (36-225 or 36-218 or 36-219 or 21-325) and (18-491 or 18-691)\nInstructors: Richard Stern\nRooms: WEH 4625\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-792 Advanced Digital Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-920 Independent Study_ Breadth.txt"
        },
        "page_content":"Brown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia Tsvetkov, Zachary Lipton, Zico Kolter",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 57-572 Music and Technology Project.txt"
        },
        "page_content":"<start course metadata for 57-572 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: Music and Technology Project\nCourse Number: 57-572\nDepartment: Music\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA, Jesse Stiles, Riccardo Schulz, Richard Stern, Thomas Sullivan\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-572 Music and Technology Project>\n\n<start course description for 57-572 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Description: TBA\n<\/end course description for 57-572 Music and Technology Project>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 57-571 Music and Technology Project.txt"
        },
        "page_content":"<start course metadata for 57-571 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: Music and Technology Project\nCourse Number: 57-571\nDepartment: Music\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA, Jesse Stiles, Riccardo Schulz, Richard Stern, Thomas Sullivan\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-571 Music and Technology Project>\n\n<start course description for 57-571 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Description: TBA\n<\/end course description for 57-571 Music and Technology Project>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 57-613 Independent Study in Research.txt"
        },
        "page_content":"<start course metadata for 57-613 Independent Study in Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Independent Study in Research\nCourse Number: 57-613\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Alexa Woloshyn, Andres Cardenes, Instructor TBA, Katherine Pukinskis, Richard Randall, Richard Stern\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-613 Independent Study in Research>",
        "type":"Document"
      }
    ],
    "model_output":"\nRichard Stern's office is located in B24 Baker-Porter Hall.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Where is Richard Stern's office?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nName: Richard Stern\nTitle: Professor\nEmail rms@cs.cmu.edu\nPhone: 412-268-2535\nOffice: B24 Baker-Porter Hall\nInterests:\n-----\n<start course metadata for 18-491 Digital Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Digital Signal Processing\nCourse Number: 18-491\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 18-290\nInstructors: Richard Stern\nRooms: SH 234\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-491 Digital Signal Processing>\n-----\n<start course metadata for 18-691 Digital Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Digital Signal Processing\nCourse Number: 18-691\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 18-290\nInstructors: Richard Stern\nRooms: SH 234\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-691 Digital Signal Processing>\n-----\n<start course metadata for 57-613 Independent Study in Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Independent Study in Research\nCourse Number: 57-613\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA, Richard Stern\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-613 Independent Study in Research>\n-----\n<start course metadata for 57-970 Music and Technology Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Music and Technology Seminar\nCourse Number: 57-970\nDepartment: Music\nNumber of Units: 1\nPrerequisites: None\nInstructors: Riccardo Schulz, Richard Stern\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-970 Music and Technology Seminar>\n-----\n<start course metadata for 18-792 Advanced Digital Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Advanced Digital Signal Processing\nCourse Number: 18-792\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: (36-225 or 36-218 or 36-219 or 21-325) and (18-491 or 18-691)\nInstructors: Richard Stern\nRooms: WEH 4625\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-792 Advanced Digital Signal Processing>\n-----\nBrown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia Tsvetkov, Zachary Lipton, Zico Kolter\n-----\n<start course metadata for 57-572 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: Music and Technology Project\nCourse Number: 57-572\nDepartment: Music\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA, Jesse Stiles, Riccardo Schulz, Richard Stern, Thomas Sullivan\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-572 Music and Technology Project>\n\n<start course description for 57-572 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Description: TBA\n<\/end course description for 57-572 Music and Technology Project>\n-----\n<start course metadata for 57-571 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: Music and Technology Project\nCourse Number: 57-571\nDepartment: Music\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA, Jesse Stiles, Riccardo Schulz, Richard Stern, Thomas Sullivan\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-571 Music and Technology Project>\n\n<start course description for 57-571 Music and Technology Project>\nSemester: Fall 2023 (aka F23)\nCourse Description: TBA\n<\/end course description for 57-571 Music and Technology Project>\n-----\n<start course metadata for 57-613 Independent Study in Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Independent Study in Research\nCourse Number: 57-613\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Alexa Woloshyn, Andres Cardenes, Instructor TBA, Katherine Pukinskis, Richard Randall, Richard Stern\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-613 Independent Study in Research>\n-----\n\n### Response ###\n\nUser: Where is Richard Stern's office?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"The University of Pittsburgh",
    "index":3,
    "Q":"At what non-CMU university does Malihe Alikhani work?",
    "A":"University of Pittsburgh",
    "category":"directory",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Adjunct Faculty | Carnegie Mellon University | Malihe Alikhani.txt"
        },
        "page_content":"Name: Malihe Alikhani\nTitle: Assistant Professor at the University of Pittsburgh\nEmail malihe@pitt.edu\nPhone: \nOffice: \nInterests:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | Learning to Generate Equitable Text in Dialogue from Biased Training Data.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Learning to Generate Equitable Text in Dialogue from Biased Training Data\nauthors: Anthony Sicilia, Malihe Alikhani\nyear: 2023\ntldr: This work provides formal definitions of equity in text generation, and proves formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms forimproving human- likeness (on augmented data).",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | Multilingual Content Moderation: A Case Study on Reddit.txt"
        },
        "page_content":"publication venue: Conference of the European Chapter of the Association for Computational Linguistics\ntitle: Multilingual Content Moderation: A Case Study on Reddit\nauthors: Meng Ye, Karan Sikka, Katherine Atwell, Sabit Hassan, Ajay Divakaran, Malihe Alikhani\nyear: 2023\ntldr: This work proposes to study the challenges of content moderation by introducing a multilingual dataset of 1.8 Million Reddit comments spanning 56 subreddits in English, German, Spanish and French and performs extensive experimental analysis to highlight the underlying challenges and suggest related research problems.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | A corpus of Persian literary text.txt"
        },
        "page_content":"publication venue: Language Resources and Evaluation\ntitle: A corpus of Persian literary text\nauthors: Shahab Raji, Malihe Alikhani, Gerard de Melo, Matthew Stone\nyear: 2023\ntldr: The corpus, the tools, and experiments described in this paper can be used not only for digital humanities studies of Persian literature but also for processing Persian texts in general, as well as in other broader cross-linguistic applications.\nabstract: None",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | Findings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23).txt"
        },
        "page_content":"publication venue: Conference on Machine Translation\ntitle: Findings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23)\nauthors: Mathias M\u00fcller, Malihe Alikhani, Eleftherios Avramidis, Richard Bowden, Annelies Braffort, Necati Cihan Camg\u00f6z, Sarah Ebling, Cristina Espa\u00f1a-Bonet, A. G\u00f6hring, Roman Grundkiewicz, Mert Inan, Zifan Jiang, Oscar Koller, Amit Moryossef, Annette Rios, D. Shterionov, Sandra Sidler-Miserez, Katja Tissi, Davy Van Landuyt\nyear: 2023",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 13.txt"
        },
        "page_content":"http:\/\/www.cmu.edu\/oie\/  \nCarnegie Mellon hosts international graduate and undergraduate students who come from \nmore than 90 countries. The Office of International Education (OIE ) is the liaison to the \nUniversity for all non-immigrant students and scholars, as well the repository for study \nabroad opportunities and advisement. OIE provides many services including: advising on \npersonal, immigration, study abroad, academic, and social and acculturation issues; presenting programs of interest such as international career workshops, tax workshops, and cross-",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | Learning Multimodal Cues of Children\u2019s Uncertainty.txt"
        },
        "page_content":"publication venue: SIGDIAL Conferences\ntitle: Learning Multimodal Cues of Children\u2019s Uncertainty\nauthors: Qi Cheng, Mert Inan, Rahma Mbarki, Grace Grmek, Theresa Choi, Yiming Sun, Kimele Persaud, Jenny Wang, Malihe Alikhani\nyear: 2023\ntldr: A multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant is presented, which improves upon a baseline multimodAL transformer model and has broad implications for gesture understanding and generation.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias\nauthors: Sabit Hassan, Malihe Alikhani\nyear: 2023\ntldr: A novel adaptive clustering-based active learning algorithm that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate, D-CALM, which showcases robustness against different measures of information gain and can significantly reduce unwanted model bias.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 9.txt"
        },
        "page_content":"them at gsa@cmu.edu  to get involved, stop by their office in the Cohon University Center \nRoom 304 or become a representative for your department.  \nA.1.8 Office of International Education (OIE)  \nhttps:\/\/www.cmu.edu\/oie\/   \nCarnegie Mellon hosts international graduate and undergraduate students who come from more than 90 countries. The Office of International Education (OIE) is the liaison to the \nUniversity for all non -immigrant students and scholars, as well the repository for study abroad \nopportunities. OIE provides many services including: advising on personal, immigration, study",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 6.txt"
        },
        "page_content":"feedback to improve the graduate student experience at CMU. Feel free to contact them at \ngsa@cmu.edu\n to get involved, stop by their office in the Cohon University Center Room 304 or \nbecome a representative for your department.  \nA.1.8 Office of International Education (OIE)  \nhttps:\/\/www.cmu.e du\/oie\/   \nCarnegie Mellon hosts international graduate and undergraduate students who come from more than 90 countries. The Office of International Education (OIE) is the liaison to the University for \nall non -immigrant students and scholars, as well the repository for study abroad opportunities.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Adjunct Faculty | Carnegie Mellon University | Malihe Alikhani.txt"
        },
        "page_content":"Name: Malihe Alikhani\nTitle: Assistant Professor at the University of Pittsburgh\nEmail malihe@pitt.edu\nPhone: \nOffice: \nInterests:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | Learning to Generate Equitable Text in Dialogue from Biased Training Data.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Learning to Generate Equitable Text in Dialogue from Biased Training Data\nauthors: Anthony Sicilia, Malihe Alikhani\nyear: 2023\ntldr: This work provides formal definitions of equity in text generation, and proves formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms forimproving human- likeness (on augmented data).",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | Multilingual Content Moderation: A Case Study on Reddit.txt"
        },
        "page_content":"publication venue: Conference of the European Chapter of the Association for Computational Linguistics\ntitle: Multilingual Content Moderation: A Case Study on Reddit\nauthors: Meng Ye, Karan Sikka, Katherine Atwell, Sabit Hassan, Ajay Divakaran, Malihe Alikhani\nyear: 2023\ntldr: This work proposes to study the challenges of content moderation by introducing a multilingual dataset of 1.8 Million Reddit comments spanning 56 subreddits in English, German, Spanish and French and performs extensive experimental analysis to highlight the underlying challenges and suggest related research problems.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | A corpus of Persian literary text.txt"
        },
        "page_content":"publication venue: Language Resources and Evaluation\ntitle: A corpus of Persian literary text\nauthors: Shahab Raji, Malihe Alikhani, Gerard de Melo, Matthew Stone\nyear: 2023\ntldr: The corpus, the tools, and experiments described in this paper can be used not only for digital humanities studies of Persian literature but also for processing Persian texts in general, as well as in other broader cross-linguistic applications.\nabstract: None",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | Findings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23).txt"
        },
        "page_content":"publication venue: Conference on Machine Translation\ntitle: Findings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23)\nauthors: Mathias M\u00fcller, Malihe Alikhani, Eleftherios Avramidis, Richard Bowden, Annelies Braffort, Necati Cihan Camg\u00f6z, Sarah Ebling, Cristina Espa\u00f1a-Bonet, A. G\u00f6hring, Roman Grundkiewicz, Mert Inan, Zifan Jiang, Oscar Koller, Amit Moryossef, Annette Rios, D. Shterionov, Sandra Sidler-Miserez, Katja Tissi, Davy Van Landuyt\nyear: 2023",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 13.txt"
        },
        "page_content":"http:\/\/www.cmu.edu\/oie\/  \nCarnegie Mellon hosts international graduate and undergraduate students who come from \nmore than 90 countries. The Office of International Education (OIE ) is the liaison to the \nUniversity for all non-immigrant students and scholars, as well the repository for study \nabroad opportunities and advisement. OIE provides many services including: advising on \npersonal, immigration, study abroad, academic, and social and acculturation issues; presenting programs of interest such as international career workshops, tax workshops, and cross-",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | Learning Multimodal Cues of Children\u2019s Uncertainty.txt"
        },
        "page_content":"publication venue: SIGDIAL Conferences\ntitle: Learning Multimodal Cues of Children\u2019s Uncertainty\nauthors: Qi Cheng, Mert Inan, Rahma Mbarki, Grace Grmek, Theresa Choi, Yiming Sun, Kimele Persaud, Jenny Wang, Malihe Alikhani\nyear: 2023\ntldr: A multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant is presented, which improves upon a baseline multimodAL transformer model and has broad implications for gesture understanding and generation.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias\nauthors: Sabit Hassan, Malihe Alikhani\nyear: 2023\ntldr: A novel adaptive clustering-based active learning algorithm that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate, D-CALM, which showcases robustness against different measures of information gain and can significantly reduce unwanted model bias.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 9.txt"
        },
        "page_content":"them at gsa@cmu.edu  to get involved, stop by their office in the Cohon University Center \nRoom 304 or become a representative for your department.  \nA.1.8 Office of International Education (OIE)  \nhttps:\/\/www.cmu.edu\/oie\/   \nCarnegie Mellon hosts international graduate and undergraduate students who come from more than 90 countries. The Office of International Education (OIE) is the liaison to the \nUniversity for all non -immigrant students and scholars, as well the repository for study abroad \nopportunities. OIE provides many services including: advising on personal, immigration, study",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 6.txt"
        },
        "page_content":"feedback to improve the graduate student experience at CMU. Feel free to contact them at \ngsa@cmu.edu\n to get involved, stop by their office in the Cohon University Center Room 304 or \nbecome a representative for your department.  \nA.1.8 Office of International Education (OIE)  \nhttps:\/\/www.cmu.e du\/oie\/   \nCarnegie Mellon hosts international graduate and undergraduate students who come from more than 90 countries. The Office of International Education (OIE) is the liaison to the University for \nall non -immigrant students and scholars, as well the repository for study abroad opportunities.",
        "type":"Document"
      }
    ],
    "model_output":"\nMalihe Alikhani works at the University of Pittsburgh.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"At what non-CMU university does Malihe Alikhani work?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nName: Malihe Alikhani\nTitle: Assistant Professor at the University of Pittsburgh\nEmail malihe@pitt.edu\nPhone: \nOffice: \nInterests:\n-----\npublication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Learning to Generate Equitable Text in Dialogue from Biased Training Data\nauthors: Anthony Sicilia, Malihe Alikhani\nyear: 2023\ntldr: This work provides formal definitions of equity in text generation, and proves formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms forimproving human- likeness (on augmented data).\n-----\npublication venue: Conference of the European Chapter of the Association for Computational Linguistics\ntitle: Multilingual Content Moderation: A Case Study on Reddit\nauthors: Meng Ye, Karan Sikka, Katherine Atwell, Sabit Hassan, Ajay Divakaran, Malihe Alikhani\nyear: 2023\ntldr: This work proposes to study the challenges of content moderation by introducing a multilingual dataset of 1.8 Million Reddit comments spanning 56 subreddits in English, German, Spanish and French and performs extensive experimental analysis to highlight the underlying challenges and suggest related research problems.\n-----\npublication venue: Language Resources and Evaluation\ntitle: A corpus of Persian literary text\nauthors: Shahab Raji, Malihe Alikhani, Gerard de Melo, Matthew Stone\nyear: 2023\ntldr: The corpus, the tools, and experiments described in this paper can be used not only for digital humanities studies of Persian literature but also for processing Persian texts in general, as well as in other broader cross-linguistic applications.\nabstract: None\n-----\npublication venue: Conference on Machine Translation\ntitle: Findings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23)\nauthors: Mathias M\u00fcller, Malihe Alikhani, Eleftherios Avramidis, Richard Bowden, Annelies Braffort, Necati Cihan Camg\u00f6z, Sarah Ebling, Cristina Espa\u00f1a-Bonet, A. G\u00f6hring, Roman Grundkiewicz, Mert Inan, Zifan Jiang, Oscar Koller, Amit Moryossef, Annette Rios, D. Shterionov, Sandra Sidler-Miserez, Katja Tissi, Davy Van Landuyt\nyear: 2023\n-----\nhttp:\/\/www.cmu.edu\/oie\/  \nCarnegie Mellon hosts international graduate and undergraduate students who come from \nmore than 90 countries. The Office of International Education (OIE ) is the liaison to the \nUniversity for all non-immigrant students and scholars, as well the repository for study \nabroad opportunities and advisement. OIE provides many services including: advising on \npersonal, immigration, study abroad, academic, and social and acculturation issues; presenting programs of interest such as international career workshops, tax workshops, and cross-\n-----\npublication venue: SIGDIAL Conferences\ntitle: Learning Multimodal Cues of Children\u2019s Uncertainty\nauthors: Qi Cheng, Mert Inan, Rahma Mbarki, Grace Grmek, Theresa Choi, Yiming Sun, Kimele Persaud, Jenny Wang, Malihe Alikhani\nyear: 2023\ntldr: A multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant is presented, which improves upon a baseline multimodAL transformer model and has broad implications for gesture understanding and generation.\n-----\npublication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias\nauthors: Sabit Hassan, Malihe Alikhani\nyear: 2023\ntldr: A novel adaptive clustering-based active learning algorithm that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate, D-CALM, which showcases robustness against different measures of information gain and can significantly reduce unwanted model bias.\n-----\nthem at gsa@cmu.edu  to get involved, stop by their office in the Cohon University Center \nRoom 304 or become a representative for your department.  \nA.1.8 Office of International Education (OIE)  \nhttps:\/\/www.cmu.edu\/oie\/   \nCarnegie Mellon hosts international graduate and undergraduate students who come from more than 90 countries. The Office of International Education (OIE) is the liaison to the \nUniversity for all non -immigrant students and scholars, as well the repository for study abroad \nopportunities. OIE provides many services including: advising on personal, immigration, study\n-----\nfeedback to improve the graduate student experience at CMU. Feel free to contact them at \ngsa@cmu.edu\n to get involved, stop by their office in the Cohon University Center Room 304 or \nbecome a representative for your department.  \nA.1.8 Office of International Education (OIE)  \nhttps:\/\/www.cmu.e du\/oie\/   \nCarnegie Mellon hosts international graduate and undergraduate students who come from more than 90 countries. The Office of International Education (OIE) is the liaison to the University for \nall non -immigrant students and scholars, as well the repository for study abroad opportunities.\n-----\n\n### Response ###\n\nUser: At what non-CMU university does Malihe Alikhani work?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"The University of California, San Diego",
    "index":4,
    "Q":"At what non-CMU university does Taylor Berg-Kirkpatrick work?",
    "A":"University of California, San Diego",
    "category":"directory",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Adjunct Faculty | Carnegie Mellon University | Taylor Berg-Kirkpatrick.txt"
        },
        "page_content":"Name: Taylor Berg-Kirkpatrick\nTitle: Assistant Professor, University of California, San Diego\nEmail tberg@cs.cmu.edu\nPhone: \nOffice: 6403 Gates & Hillman Centers\nInterests:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Jointly modeling products and resource pages for task-oriented recommendation.txt"
        },
        "page_content":"publication venue: The Web Conference\ntitle: Jointly modeling products and resource pages for task-oriented recommendation\nauthors: B. Duncan, S. Kallumadi, Taylor Berg-Kirkpatrick, Julian McAuley\nyear: 2023\ntldr: This paper jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users, and extends a state-of-the-art system to incorporate this new intent data, and shows a significant improvement in the ability of the system to recommend products.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models.txt"
        },
        "page_content":"publication venue: IEEE Workshop on Applications of Signal Processing to Audio and Acoustics\ntitle: CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models\nauthors: Hao-Wen Dong, Xiaoyu Liu, Jordi Pons, Gautam Bhattacharya, Santiago Pascual, J. Serr\u00e0, Taylor Berg-Kirkpatrick, Julian McAuley\nyear: 2023\ntldr: This work proposes to learn the desired text-audio correspondence by leveraging the visual modality as a bridge in videos and pretrained language-vision models, and shows competitive performance against a state-of-the-art image-to-audio synthesis model in a subjective listening test.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | ClimaBench: A Benchmark Dataset For Climate Change Text Understanding in English.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: ClimaBench: A Benchmark Dataset For Climate Change Text Understanding in English\nauthors: Tanmay Laud, Daniel M. Spokoyny, Thomas W. Corringham, Taylor Berg-Kirkpatrick\nyear: 2023\ntldr: Climate Change Benchmark (ClimaBench) is introduced, a benchmark collection of existing disparate datasets for evaluating model performance across a diverse set of CC NLU tasks systematically and an analysis of several generic and CC-oriented models answering whether tuning on domain text offers any improvements across these tasks.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Contrastive Attention Networks for Attribution of Early Modern Print.txt"
        },
        "page_content":"publication venue: AAAI Conference on Artificial Intelligence\ntitle: Contrastive Attention Networks for Attribution of Early Modern Print\nauthors: Nikolai Vogler, Kartik Goyal, Kishore PV Reddy, Elizaveta Pertseva, Sam Lemley, Christopher N. Warren, M. GSell, Taylor Berg-Kirkpatrick\nyear: 2023\ntldr: The method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts and demonstrates potential to extend the extant historical research about the origins and content of these books.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Smaller Language Models are Better Black-box Machine-Generated Text Detectors.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Smaller Language Models are Better Black-box Machine-Generated Text Detectors\nauthors: Fatemehsadat Mireshghallah, Justus Mattern, Sicun Gao, R. Shokri, Taylor Berg-Kirkpatrick\nyear: 2023\ntldr: Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction.txt"
        },
        "page_content":"publication venue: International Society for Music Information Retrieval Conference\ntitle: Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction\nauthors: Keren Shao, K. Chen, Taylor Berg-Kirkpatrick, S. Dubnov\nyear: 2023\ntldr: This paper proposes an input feature modification and a training objective modification based on two assumptions of harmonics in the spectrograms of audio data decay rapidly along the frequency axis to enhance the model's sensitivity on the trailing harmonics.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Universal Source Separation with Weakly Labelled Data.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Universal Source Separation with Weakly Labelled Data\nauthors: Qiuqiang Kong, K. Chen, Haohe Liu, Xingjian Du, Taylor Berg-Kirkpatrick, S. Dubnov, MarkD . Plumbley\nyear: 2023\ntldr: A hierarchical USS strategy to automatically detect and separate sound classes from the AudioSet ontology is proposed, which is successful in separating a wide variety of sound classes, including sound event separation, music source separation, and speech enhancement.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Membership Inference Attacks against Language Models via Neighbourhood Comparison.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Membership Inference Attacks against Language Models via Neighbourhood Comparison\nauthors: Justus Mattern, Fatemehsadat Mireshghallah, Zhijing Jin, B. Scholkopf, Mrinmaya Sachan, Taylor Berg-Kirkpatrick\nyear: 2023",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-920 Independent Study_ Breadth.txt"
        },
        "page_content":"Brown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia Tsvetkov, Zachary Lipton, Zico Kolter",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Adjunct Faculty | Carnegie Mellon University | Taylor Berg-Kirkpatrick.txt"
        },
        "page_content":"Name: Taylor Berg-Kirkpatrick\nTitle: Assistant Professor, University of California, San Diego\nEmail tberg@cs.cmu.edu\nPhone: \nOffice: 6403 Gates & Hillman Centers\nInterests:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Jointly modeling products and resource pages for task-oriented recommendation.txt"
        },
        "page_content":"publication venue: The Web Conference\ntitle: Jointly modeling products and resource pages for task-oriented recommendation\nauthors: B. Duncan, S. Kallumadi, Taylor Berg-Kirkpatrick, Julian McAuley\nyear: 2023\ntldr: This paper jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users, and extends a state-of-the-art system to incorporate this new intent data, and shows a significant improvement in the ability of the system to recommend products.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models.txt"
        },
        "page_content":"publication venue: IEEE Workshop on Applications of Signal Processing to Audio and Acoustics\ntitle: CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models\nauthors: Hao-Wen Dong, Xiaoyu Liu, Jordi Pons, Gautam Bhattacharya, Santiago Pascual, J. Serr\u00e0, Taylor Berg-Kirkpatrick, Julian McAuley\nyear: 2023\ntldr: This work proposes to learn the desired text-audio correspondence by leveraging the visual modality as a bridge in videos and pretrained language-vision models, and shows competitive performance against a state-of-the-art image-to-audio synthesis model in a subjective listening test.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | ClimaBench: A Benchmark Dataset For Climate Change Text Understanding in English.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: ClimaBench: A Benchmark Dataset For Climate Change Text Understanding in English\nauthors: Tanmay Laud, Daniel M. Spokoyny, Thomas W. Corringham, Taylor Berg-Kirkpatrick\nyear: 2023\ntldr: Climate Change Benchmark (ClimaBench) is introduced, a benchmark collection of existing disparate datasets for evaluating model performance across a diverse set of CC NLU tasks systematically and an analysis of several generic and CC-oriented models answering whether tuning on domain text offers any improvements across these tasks.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Contrastive Attention Networks for Attribution of Early Modern Print.txt"
        },
        "page_content":"publication venue: AAAI Conference on Artificial Intelligence\ntitle: Contrastive Attention Networks for Attribution of Early Modern Print\nauthors: Nikolai Vogler, Kartik Goyal, Kishore PV Reddy, Elizaveta Pertseva, Sam Lemley, Christopher N. Warren, M. GSell, Taylor Berg-Kirkpatrick\nyear: 2023\ntldr: The method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts and demonstrates potential to extend the extant historical research about the origins and content of these books.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Smaller Language Models are Better Black-box Machine-Generated Text Detectors.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Smaller Language Models are Better Black-box Machine-Generated Text Detectors\nauthors: Fatemehsadat Mireshghallah, Justus Mattern, Sicun Gao, R. Shokri, Taylor Berg-Kirkpatrick\nyear: 2023\ntldr: Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction.txt"
        },
        "page_content":"publication venue: International Society for Music Information Retrieval Conference\ntitle: Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction\nauthors: Keren Shao, K. Chen, Taylor Berg-Kirkpatrick, S. Dubnov\nyear: 2023\ntldr: This paper proposes an input feature modification and a training objective modification based on two assumptions of harmonics in the spectrograms of audio data decay rapidly along the frequency axis to enhance the model's sensitivity on the trailing harmonics.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Universal Source Separation with Weakly Labelled Data.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Universal Source Separation with Weakly Labelled Data\nauthors: Qiuqiang Kong, K. Chen, Haohe Liu, Xingjian Du, Taylor Berg-Kirkpatrick, S. Dubnov, MarkD . Plumbley\nyear: 2023\ntldr: A hierarchical USS strategy to automatically detect and separate sound classes from the AudioSet ontology is proposed, which is successful in separating a wide variety of sound classes, including sound event separation, music source separation, and speech enhancement.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Membership Inference Attacks against Language Models via Neighbourhood Comparison.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Membership Inference Attacks against Language Models via Neighbourhood Comparison\nauthors: Justus Mattern, Fatemehsadat Mireshghallah, Zhijing Jin, B. Scholkopf, Mrinmaya Sachan, Taylor Berg-Kirkpatrick\nyear: 2023",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-920 Independent Study_ Breadth.txt"
        },
        "page_content":"Brown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia Tsvetkov, Zachary Lipton, Zico Kolter",
        "type":"Document"
      }
    ],
    "model_output":"\nTaylor Berg-Kirkpatrick works at the University of California, San Diego.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"At what non-CMU university does Taylor Berg-Kirkpatrick work?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nName: Taylor Berg-Kirkpatrick\nTitle: Assistant Professor, University of California, San Diego\nEmail tberg@cs.cmu.edu\nPhone: \nOffice: 6403 Gates & Hillman Centers\nInterests:\n-----\npublication venue: The Web Conference\ntitle: Jointly modeling products and resource pages for task-oriented recommendation\nauthors: B. Duncan, S. Kallumadi, Taylor Berg-Kirkpatrick, Julian McAuley\nyear: 2023\ntldr: This paper jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users, and extends a state-of-the-art system to incorporate this new intent data, and shows a significant improvement in the ability of the system to recommend products.\n-----\npublication venue: IEEE Workshop on Applications of Signal Processing to Audio and Acoustics\ntitle: CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models\nauthors: Hao-Wen Dong, Xiaoyu Liu, Jordi Pons, Gautam Bhattacharya, Santiago Pascual, J. Serr\u00e0, Taylor Berg-Kirkpatrick, Julian McAuley\nyear: 2023\ntldr: This work proposes to learn the desired text-audio correspondence by leveraging the visual modality as a bridge in videos and pretrained language-vision models, and shows competitive performance against a state-of-the-art image-to-audio synthesis model in a subjective listening test.\n-----\npublication venue: arXiv.org\ntitle: ClimaBench: A Benchmark Dataset For Climate Change Text Understanding in English\nauthors: Tanmay Laud, Daniel M. Spokoyny, Thomas W. Corringham, Taylor Berg-Kirkpatrick\nyear: 2023\ntldr: Climate Change Benchmark (ClimaBench) is introduced, a benchmark collection of existing disparate datasets for evaluating model performance across a diverse set of CC NLU tasks systematically and an analysis of several generic and CC-oriented models answering whether tuning on domain text offers any improvements across these tasks.\n-----\npublication venue: AAAI Conference on Artificial Intelligence\ntitle: Contrastive Attention Networks for Attribution of Early Modern Print\nauthors: Nikolai Vogler, Kartik Goyal, Kishore PV Reddy, Elizaveta Pertseva, Sam Lemley, Christopher N. Warren, M. GSell, Taylor Berg-Kirkpatrick\nyear: 2023\ntldr: The method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts and demonstrates potential to extend the extant historical research about the origins and content of these books.\n-----\npublication venue: arXiv.org\ntitle: Smaller Language Models are Better Black-box Machine-Generated Text Detectors\nauthors: Fatemehsadat Mireshghallah, Justus Mattern, Sicun Gao, R. Shokri, Taylor Berg-Kirkpatrick\nyear: 2023\ntldr: Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.\n-----\npublication venue: International Society for Music Information Retrieval Conference\ntitle: Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction\nauthors: Keren Shao, K. Chen, Taylor Berg-Kirkpatrick, S. Dubnov\nyear: 2023\ntldr: This paper proposes an input feature modification and a training objective modification based on two assumptions of harmonics in the spectrograms of audio data decay rapidly along the frequency axis to enhance the model's sensitivity on the trailing harmonics.\n-----\npublication venue: arXiv.org\ntitle: Universal Source Separation with Weakly Labelled Data\nauthors: Qiuqiang Kong, K. Chen, Haohe Liu, Xingjian Du, Taylor Berg-Kirkpatrick, S. Dubnov, MarkD . Plumbley\nyear: 2023\ntldr: A hierarchical USS strategy to automatically detect and separate sound classes from the AudioSet ontology is proposed, which is successful in separating a wide variety of sound classes, including sound event separation, music source separation, and speech enhancement.\n-----\npublication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Membership Inference Attacks against Language Models via Neighbourhood Comparison\nauthors: Justus Mattern, Fatemehsadat Mireshghallah, Zhijing Jin, B. Scholkopf, Mrinmaya Sachan, Taylor Berg-Kirkpatrick\nyear: 2023\n-----\nBrown, Richard Stern, Robert Frederking, Ronald Rosenfeld, Ruslan Salakhutdinov, Scott Fahlman, Shinji Watanabe, Stacey Young, Stephen Smith, Taylor Berg-Kirkpatrick, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Yonatan Bisk, Yulia Tsvetkov, Zachary Lipton, Zico Kolter\n-----\n\n### Response ###\n\nUser: At what non-CMU university does Taylor Berg-Kirkpatrick work?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Shuyan Zhou",
    "index":5,
    "Q":"Who is the first author of the paper entitled \"WebArena: A Realistic Web Environment for Building Autonomous Agents,\" published in 2023?",
    "A":"Shuyan Zhou",
    "category":"papers",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daniel Fried | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Tom Mitchell | Publication | Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nauthors: Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, J. Sinapov\nyear: 2023\ntldr: This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Jointly modeling products and resource pages for task-oriented recommendation.txt"
        },
        "page_content":"publication venue: The Web Conference\ntitle: Jointly modeling products and resource pages for task-oriented recommendation\nauthors: B. Duncan, S. Kallumadi, Taylor Berg-Kirkpatrick, Julian McAuley\nyear: 2023\ntldr: This paper jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users, and extends a state-of-the-art system to incorporate this new intent data, and shows a significant improvement in the ability of the system to recommend products.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jamie Callan | Publication | Multi-Objective Improvement of Android Applications.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Multi-Objective Improvement of Android Applications\nauthors: Jamie Callan, J. Petke\nyear: 2023\ntldr: This work proposes a practical approach and the first open-source tool, GIDroid, for multi-objective automated improvement of Android apps, and uses Genetic improvement, a search-based technique that navigates the space of software variants to find improved software.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"abstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daniel Fried | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"abstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daniel Fried | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Tom Mitchell | Publication | Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nauthors: Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, J. Sinapov\nyear: 2023\ntldr: This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Taylor Berg-Kirkpatrick | Publication | Jointly modeling products and resource pages for task-oriented recommendation.txt"
        },
        "page_content":"publication venue: The Web Conference\ntitle: Jointly modeling products and resource pages for task-oriented recommendation\nauthors: B. Duncan, S. Kallumadi, Taylor Berg-Kirkpatrick, Julian McAuley\nyear: 2023\ntldr: This paper jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users, and extends a state-of-the-art system to incorporate this new intent data, and shows a significant improvement in the ability of the system to recommend products.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jamie Callan | Publication | Multi-Objective Improvement of Android Applications.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Multi-Objective Improvement of Android Applications\nauthors: Jamie Callan, J. Petke\nyear: 2023\ntldr: This work proposes a practical approach and the first open-source tool, GIDroid, for multi-objective automated improvement of Android apps, and uses Genetic improvement, a search-based technique that navigates the space of software variants to find improved software.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"abstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daniel Fried | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"abstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our",
        "type":"Document"
      }
    ],
    "model_output":"\nThe first author of the paper entitled \"WebArena: A Realistic Web Environment for Building Autonomous Agents,\" published in 2023, is Shuyan Zhou.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is the first author of the paper entitled \"WebArena: A Realistic Web Environment for Building Autonomous Agents,\" published in 2023?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\npublication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.\n-----\npublication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.\n-----\npublication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.\n-----\npublication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.\n-----\npublication venue: arXiv.org\ntitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nauthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nyear: 2023\ntldr: A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.\n-----\npublication venue: arXiv.org\ntitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nauthors: Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, J. Sinapov\nyear: 2023\ntldr: This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.\n-----\npublication venue: The Web Conference\ntitle: Jointly modeling products and resource pages for task-oriented recommendation\nauthors: B. Duncan, S. Kallumadi, Taylor Berg-Kirkpatrick, Julian McAuley\nyear: 2023\ntldr: This paper jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users, and extends a state-of-the-art system to incorporate this new intent data, and shows a significant improvement in the ability of the system to recommend products.\n-----\npublication venue: arXiv.org\ntitle: Multi-Objective Improvement of Android Applications\nauthors: Jamie Callan, J. Petke\nyear: 2023\ntldr: This work proposes a practical approach and the first open-source tool, GIDroid, for multi-objective automated improvement of Android apps, and uses Genetic improvement, a search-based technique that navigates the space of software variants to find improved software.\n-----\nabstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our\n-----\nabstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our\n-----\n\n### Response ###\n\nUser: Who is the first author of the paper entitled \"WebArena: A Realistic Web Environment for Building Autonomous Agents,\" published in 2023?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.5,
    "recall":0.5,
    "precision":0.5,
    "A_hat":"S. Longpre",
    "index":6,
    "Q":"Who is the first author of the paper entitled \"A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\"?",
    "A":"Shayne Longpre",
    "category":"papers",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daphne Ippolito | Publication | A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\nauthors: S. Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David M. Mimno, Daphne Ippolito\nyear: 2023\ntldr: These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which are hoped to help support more informed data-centric decisions in LM development.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daphne Ippolito | Publication | A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity.txt"
        },
        "page_content":"abstract: Pretraining is the preliminary and fundamental step in developing capable language models (LM). Despite this, pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. To address this, we pretrain 28 1.5B parameter decoder-only models, training on data curated (1) at different times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daphne Ippolito | Publication | A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity.txt"
        },
        "page_content":"with different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. Our findings indicate there does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daphne Ippolito | Publication | Extracting Training Data from Diffusion Models.txt"
        },
        "page_content":"publication venue: USENIX Security Symposium\ntitle: Extracting Training Data from Diffusion Models\nauthors: Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tram\u00e8r, B. Balle, Daphne Ippolito, Eric Wallace\nyear: 2023\ntldr: The results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | Learning to Generate Equitable Text in Dialogue from Biased Training Data.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Learning to Generate Equitable Text in Dialogue from Biased Training Data\nauthors: Anthony Sicilia, Malihe Alikhani\nyear: 2023\ntldr: This work provides formal definitions of equity in text generation, and proves formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms forimproving human- likeness (on augmented data).",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Louis-Philippe Morency | Publication | Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions\nauthors: Himanshu Thakur, Atishay Jain, Praneetha Vaddamanu, P. Liang, Louis-Philippe Morency\nyear: 2023\ntldr: This paper empirically shows that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced, and argues that the few-shot de-biasing approach is highly feasible and practical.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code\nauthors: Shuyan Zhou, Uri Alon, Sumit Agarwal, Graham Neubig\nyear: 2023\ntldr: It is found that generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed, than all existing metrics.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daphne Ippolito | Publication | A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity.txt"
        },
        "page_content":"there does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion of heterogeneous data sources, like books and web, is broadly beneficial and warrants greater prioritization. These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which we hope will help support more informed data-centric decisions in LM development.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions\nauthors: Vijay Viswanathan, Luyu Gao, Tongshuang Sherry Wu, Pengfei Liu, Graham Neubig\nyear: 2023\ntldr: This work operationalizes the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs, and builds the DataFinder Dataset, a larger automatically-constructed training set and a smaller expert-annotated evaluation set.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Emma Strubell | Publication | Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training\nauthors: Zhisong Zhang, Emma Strubell, E. Hovy\nyear: 2023\ntldr: This work proposes a pragmatic method that reduces the annotation cost for structured label spaces using active learning by adopting an error estimator to adaptively decide the partial selection ratio according to the current model's capability.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daphne Ippolito | Publication | A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\nauthors: S. Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David M. Mimno, Daphne Ippolito\nyear: 2023\ntldr: These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which are hoped to help support more informed data-centric decisions in LM development.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daphne Ippolito | Publication | A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity.txt"
        },
        "page_content":"abstract: Pretraining is the preliminary and fundamental step in developing capable language models (LM). Despite this, pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. To address this, we pretrain 28 1.5B parameter decoder-only models, training on data curated (1) at different times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daphne Ippolito | Publication | A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity.txt"
        },
        "page_content":"with different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. Our findings indicate there does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daphne Ippolito | Publication | Extracting Training Data from Diffusion Models.txt"
        },
        "page_content":"publication venue: USENIX Security Symposium\ntitle: Extracting Training Data from Diffusion Models\nauthors: Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tram\u00e8r, B. Balle, Daphne Ippolito, Eric Wallace\nyear: 2023\ntldr: The results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Malihe Alikhani | Publication | Learning to Generate Equitable Text in Dialogue from Biased Training Data.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Learning to Generate Equitable Text in Dialogue from Biased Training Data\nauthors: Anthony Sicilia, Malihe Alikhani\nyear: 2023\ntldr: This work provides formal definitions of equity in text generation, and proves formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms forimproving human- likeness (on augmented data).",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Louis-Philippe Morency | Publication | Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions\nauthors: Himanshu Thakur, Atishay Jain, Praneetha Vaddamanu, P. Liang, Louis-Philippe Morency\nyear: 2023\ntldr: This paper empirically shows that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced, and argues that the few-shot de-biasing approach is highly feasible and practical.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code\nauthors: Shuyan Zhou, Uri Alon, Sumit Agarwal, Graham Neubig\nyear: 2023\ntldr: It is found that generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed, than all existing metrics.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Daphne Ippolito | Publication | A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity.txt"
        },
        "page_content":"there does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion of heterogeneous data sources, like books and web, is broadly beneficial and warrants greater prioritization. These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which we hope will help support more informed data-centric decisions in LM development.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions\nauthors: Vijay Viswanathan, Luyu Gao, Tongshuang Sherry Wu, Pengfei Liu, Graham Neubig\nyear: 2023\ntldr: This work operationalizes the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs, and builds the DataFinder Dataset, a larger automatically-constructed training set and a smaller expert-annotated evaluation set.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Emma Strubell | Publication | Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training\nauthors: Zhisong Zhang, Emma Strubell, E. Hovy\nyear: 2023\ntldr: This work proposes a pragmatic method that reduces the annotation cost for structured label spaces using active learning by adopting an error estimator to adaptively decide the partial selection ratio according to the current model's capability.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe first author of the paper entitled \"A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\" is S. Longpre.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is the first author of the paper entitled \"A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\"?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\npublication venue: arXiv.org\ntitle: A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\nauthors: S. Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David M. Mimno, Daphne Ippolito\nyear: 2023\ntldr: These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which are hoped to help support more informed data-centric decisions in LM development.\n-----\nabstract: Pretraining is the preliminary and fundamental step in developing capable language models (LM). Despite this, pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. To address this, we pretrain 28 1.5B parameter decoder-only models, training on data curated (1) at different times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the\n-----\nwith different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. Our findings indicate there does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion\n-----\npublication venue: USENIX Security Symposium\ntitle: Extracting Training Data from Diffusion Models\nauthors: Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tram\u00e8r, B. Balle, Daphne Ippolito, Eric Wallace\nyear: 2023\ntldr: The results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.\n-----\npublication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Learning to Generate Equitable Text in Dialogue from Biased Training Data\nauthors: Anthony Sicilia, Malihe Alikhani\nyear: 2023\ntldr: This work provides formal definitions of equity in text generation, and proves formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms forimproving human- likeness (on augmented data).\n-----\npublication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions\nauthors: Himanshu Thakur, Atishay Jain, Praneetha Vaddamanu, P. Liang, Louis-Philippe Morency\nyear: 2023\ntldr: This paper empirically shows that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced, and argues that the few-shot de-biasing approach is highly feasible and practical.\n-----\npublication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code\nauthors: Shuyan Zhou, Uri Alon, Sumit Agarwal, Graham Neubig\nyear: 2023\ntldr: It is found that generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed, than all existing metrics.\n-----\nthere does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion of heterogeneous data sources, like books and web, is broadly beneficial and warrants greater prioritization. These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which we hope will help support more informed data-centric decisions in LM development.\n-----\npublication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions\nauthors: Vijay Viswanathan, Luyu Gao, Tongshuang Sherry Wu, Pengfei Liu, Graham Neubig\nyear: 2023\ntldr: This work operationalizes the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs, and builds the DataFinder Dataset, a larger automatically-constructed training set and a smaller expert-annotated evaluation set.\n-----\npublication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training\nauthors: Zhisong Zhang, Emma Strubell, E. Hovy\nyear: 2023\ntldr: This work proposes a pragmatic method that reduces the annotation cost for structured label spaces using active learning by adopting an error estimator to adaptively decide the partial selection ratio according to the current model's capability.\n-----\n\n### Response ###\n\nUser: Who is the first author of the paper entitled \"A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\"?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Zhengbao Jiang",
    "index":7,
    "Q":"Who is the first author of the paper entitled \"Active Retrieval Augmented Generation\"?",
    "A":"Zhengbao Jiang",
    "category":"papers",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Active Retrieval Augmented Generation\nauthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nyear: 2023\ntldr: This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jamie Callan | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Active Retrieval Augmented Generation\nauthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nyear: 2023\ntldr: This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jamie Callan | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"abstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jamie Callan | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"abstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Lu Jiang | Publication | SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting\nauthors: Emmy Liu, Aditi Chaudhary, Graham Neubig\nyear: 2023\ntldr: To improve translation of natural idioms, this work introduces two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Alexander Rudnicky | Publication | Learning to Ask Questions for Zero-shot Dialogue State Tracking.txt"
        },
        "page_content":"publication venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\ntitle: Learning to Ask Questions for Zero-shot Dialogue State Tracking\nauthors: Diogo Tavares, David Semedo, Alexander I. Rudnicky, Jo\u00e3o Magalh\u00e3es\nyear: 2023\ntldr: This work presents a method for performing zero-shot Dialogue State Tracking by casting the task as a learning-to-ask-questions framework that outperforms template-based question generation and shows that QG methods need to be aligned with the same grammatical person used in the dialogue.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Active Retrieval Augmented Generation\nauthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nyear: 2023\ntldr: This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jamie Callan | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Active Retrieval Augmented Generation\nauthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nyear: 2023\ntldr: This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jamie Callan | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"abstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jamie Callan | Publication | Active Retrieval Augmented Generation.txt"
        },
        "page_content":"abstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Lu Jiang | Publication | SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting\nauthors: Emmy Liu, Aditi Chaudhary, Graham Neubig\nyear: 2023\ntldr: To improve translation of natural idioms, this work introduces two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Alexander Rudnicky | Publication | Learning to Ask Questions for Zero-shot Dialogue State Tracking.txt"
        },
        "page_content":"publication venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\ntitle: Learning to Ask Questions for Zero-shot Dialogue State Tracking\nauthors: Diogo Tavares, David Semedo, Alexander I. Rudnicky, Jo\u00e3o Magalh\u00e3es\nyear: 2023\ntldr: This work presents a method for performing zero-shot Dialogue State Tracking by casting the task as a learning-to-ask-questions framework that outperforms template-based question generation and shows that QG methods need to be aligned with the same grammatical person used in the dialogue.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe first author of the paper entitled \"Active Retrieval Augmented Generation\" is Zhengbao Jiang.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is the first author of the paper entitled \"Active Retrieval Augmented Generation\"?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\npublication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Active Retrieval Augmented Generation\nauthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nyear: 2023\ntldr: This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.\n-----\npublication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Active Retrieval Augmented Generation\nauthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nyear: 2023\ntldr: This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.\n-----\nbased on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it\n-----\nbased on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it\n-----\nabstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval\n-----\nabstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval\n-----\npublication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.\n-----\npublication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.\n-----\npublication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting\nauthors: Emmy Liu, Aditi Chaudhary, Graham Neubig\nyear: 2023\ntldr: To improve translation of natural idioms, this work introduces two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models.\n-----\npublication venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\ntitle: Learning to Ask Questions for Zero-shot Dialogue State Tracking\nauthors: Diogo Tavares, David Semedo, Alexander I. Rudnicky, Jo\u00e3o Magalh\u00e3es\nyear: 2023\ntldr: This work presents a method for performing zero-shot Dialogue State Tracking by casting the task as a learning-to-ask-questions framework that outperforms template-based question generation and shows that QG methods need to be aligned with the same grammatical person used in the dialogue.\n-----\n\n### Response ###\n\nUser: Who is the first author of the paper entitled \"Active Retrieval Augmented Generation\"?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.0,
    "recall":0.0,
    "precision":0.0,
    "A_hat":"Graham Neubig",
    "index":8,
    "Q":"Who is the CMU faculty member who is an author on the paper entitled \"Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\"?",
    "A":"Maarten Sap",
    "category":"papers",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\nauthors: Natalie Shapira, Mosh Levy, S. Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz\nyear: 2023\ntldr: It is found that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust, indicating reliance on shallow heuristics rather than robust ToM abilities.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | Can Large Language Models Infer Causation from Correlation?.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Can Large Language Models Infer Causation from Correlation?\nauthors: Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona T. Diab, B. Scholkopf\nyear: 2023\ntldr: This work proposes the first benchmark dataset to test the pure causal inference skills of large language models (LLMs), and formulates a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Computational Language Acquisition with Theory of Mind.txt"
        },
        "page_content":"publication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Computational Language Acquisition with Theory of Mind.txt"
        },
        "page_content":"publication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation.txt"
        },
        "page_content":"publication venue: Conference on Machine Translation\ntitle: The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation\nauthors: Patrick Fernandes, Daniel Deutsch, M. Finkelstein, Parker Riley, Andr\u00e9 F. T. Martins, Graham Neubig, Ankush Garg, J. Clark, Markus Freitag, Orhan Firat\nyear: 2023\ntldr: This paper proposes AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations, and finds that it improves performance compared to just prompting for scores.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/David Mortensen | Publication | Construction Grammar Provides Unique Insight into Neural Language Models.txt"
        },
        "page_content":"publication venue: 0\ntitle: Construction Grammar Provides Unique Insight into Neural Language Models\nauthors: Leonie Weissweiler, Taiqi He, Naoki Otani, David R. Mortensen, L. Levin, Hinrich Sch\u00fctze\nyear: 2023\ntldr: The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Scott Fahlman.txt"
        },
        "page_content":"Name: Scott Fahlman\nTitle: Research Professor Emeritus\nEmail sef@cs.cmu.edu\nPhone: 412-268-2575\nOffice: 6417 Gates & Hillman Centers\nInterests: AI, Knowledge Representation and Reasoning, Natural Language Understanding",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Tom Mitchell | Publication | The Roles of Symbols in Neural-based AI: They are Not What You Think!.txt"
        },
        "page_content":"publication venue: International Workshop on Neural-Symbolic Learning and Reasoning\ntitle: The Roles of Symbols in Neural-based AI: They are Not What You Think!\nyear: 2023\nauthors: D. Silver, Tom M. Mitchell",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Emma Strubell | Publication | Understanding the Effect of Model Compression on Social Bias in Large Language Models.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Understanding the Effect of Model Compression on Social Bias in Large Language Models\nauthors: Gustavo Gon\u00e7alves, Emma Strubell\nyear: 2023\ntldr: A carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs finds that longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation\nauthors: Patrick Fernandes, Aman Madaan, Emmy Liu, Ant\u00f3nio Farinhas, Pedro Henrique Martins, Amanda Bertsch, Jos\u00e9 G. C. de Souza, Shuyan Zhou, Tongshuang Sherry Wu, Graham Neubig, Andr\u00e9 F. T. Martins\nyear: 2023\ntldr: An overview of the recent research that has leveraged human feedback to improve natural language generation and the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention is provided.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\nauthors: Natalie Shapira, Mosh Levy, S. Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz\nyear: 2023\ntldr: It is found that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust, indicating reliance on shallow heuristics rather than robust ToM abilities.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | Can Large Language Models Infer Causation from Correlation?.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Can Large Language Models Infer Causation from Correlation?\nauthors: Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona T. Diab, B. Scholkopf\nyear: 2023\ntldr: This work proposes the first benchmark dataset to test the pure causal inference skills of large language models (LLMs), and formulates a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Computational Language Acquisition with Theory of Mind.txt"
        },
        "page_content":"publication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Computational Language Acquisition with Theory of Mind.txt"
        },
        "page_content":"publication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation.txt"
        },
        "page_content":"publication venue: Conference on Machine Translation\ntitle: The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation\nauthors: Patrick Fernandes, Daniel Deutsch, M. Finkelstein, Parker Riley, Andr\u00e9 F. T. Martins, Graham Neubig, Ankush Garg, J. Clark, Markus Freitag, Orhan Firat\nyear: 2023\ntldr: This paper proposes AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations, and finds that it improves performance compared to just prompting for scores.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/David Mortensen | Publication | Construction Grammar Provides Unique Insight into Neural Language Models.txt"
        },
        "page_content":"publication venue: 0\ntitle: Construction Grammar Provides Unique Insight into Neural Language Models\nauthors: Leonie Weissweiler, Taiqi He, Naoki Otani, David R. Mortensen, L. Levin, Hinrich Sch\u00fctze\nyear: 2023\ntldr: The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Scott Fahlman.txt"
        },
        "page_content":"Name: Scott Fahlman\nTitle: Research Professor Emeritus\nEmail sef@cs.cmu.edu\nPhone: 412-268-2575\nOffice: 6417 Gates & Hillman Centers\nInterests: AI, Knowledge Representation and Reasoning, Natural Language Understanding",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Tom Mitchell | Publication | The Roles of Symbols in Neural-based AI: They are Not What You Think!.txt"
        },
        "page_content":"publication venue: International Workshop on Neural-Symbolic Learning and Reasoning\ntitle: The Roles of Symbols in Neural-based AI: They are Not What You Think!\nyear: 2023\nauthors: D. Silver, Tom M. Mitchell",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Emma Strubell | Publication | Understanding the Effect of Model Compression on Social Bias in Large Language Models.txt"
        },
        "page_content":"publication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Understanding the Effect of Model Compression on Social Bias in Large Language Models\nauthors: Gustavo Gon\u00e7alves, Emma Strubell\nyear: 2023\ntldr: A carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs finds that longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation\nauthors: Patrick Fernandes, Aman Madaan, Emmy Liu, Ant\u00f3nio Farinhas, Pedro Henrique Martins, Amanda Bertsch, Jos\u00e9 G. C. de Souza, Shuyan Zhou, Tongshuang Sherry Wu, Graham Neubig, Andr\u00e9 F. T. Martins\nyear: 2023\ntldr: An overview of the recent research that has leveraged human feedback to improve natural language generation and the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention is provided.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe CMU faculty member who is an author on the paper entitled \"Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\" is Graham Neubig.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is the CMU faculty member who is an author on the paper entitled \"Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\"?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\npublication venue: arXiv.org\ntitle: Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\nauthors: Natalie Shapira, Mosh Levy, S. Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz\nyear: 2023\ntldr: It is found that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust, indicating reliance on shallow heuristics rather than robust ToM abilities.\n-----\npublication venue: arXiv.org\ntitle: Can Large Language Models Infer Causation from Correlation?\nauthors: Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona T. Diab, B. Scholkopf\nyear: 2023\ntldr: This work proposes the first benchmark dataset to test the pure causal inference skills of large language models (LLMs), and formulates a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables.\n-----\npublication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\n-----\npublication venue: International Conference on Learning Representations\ntitle: Computational Language Acquisition with Theory of Mind\nauthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nyear: 2023\ntldr: It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\n-----\npublication venue: Conference on Machine Translation\ntitle: The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation\nauthors: Patrick Fernandes, Daniel Deutsch, M. Finkelstein, Parker Riley, Andr\u00e9 F. T. Martins, Graham Neubig, Ankush Garg, J. Clark, Markus Freitag, Orhan Firat\nyear: 2023\ntldr: This paper proposes AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations, and finds that it improves performance compared to just prompting for scores.\n-----\npublication venue: 0\ntitle: Construction Grammar Provides Unique Insight into Neural Language Models\nauthors: Leonie Weissweiler, Taiqi He, Naoki Otani, David R. Mortensen, L. Levin, Hinrich Sch\u00fctze\nyear: 2023\ntldr: The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.\n-----\nName: Scott Fahlman\nTitle: Research Professor Emeritus\nEmail sef@cs.cmu.edu\nPhone: 412-268-2575\nOffice: 6417 Gates & Hillman Centers\nInterests: AI, Knowledge Representation and Reasoning, Natural Language Understanding\n-----\npublication venue: International Workshop on Neural-Symbolic Learning and Reasoning\ntitle: The Roles of Symbols in Neural-based AI: They are Not What You Think!\nyear: 2023\nauthors: D. Silver, Tom M. Mitchell\n-----\npublication venue: Conference on Empirical Methods in Natural Language Processing\ntitle: Understanding the Effect of Model Compression on Social Bias in Large Language Models\nauthors: Gustavo Gon\u00e7alves, Emma Strubell\nyear: 2023\ntldr: A carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs finds that longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.\n-----\npublication venue: arXiv.org\ntitle: Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation\nauthors: Patrick Fernandes, Aman Madaan, Emmy Liu, Ant\u00f3nio Farinhas, Pedro Henrique Martins, Amanda Bertsch, Jos\u00e9 G. C. de Souza, Shuyan Zhou, Tongshuang Sherry Wu, Graham Neubig, Andr\u00e9 F. T. Martins\nyear: 2023\ntldr: An overview of the recent research that has leveraged human feedback to improve natural language generation and the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention is provided.\n-----\n\n### Response ###\n\nUser: Who is the CMU faculty member who is an author on the paper entitled \"Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\"?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.0,
    "recall":0.0,
    "precision":0.0,
    "A_hat":"J. Sinapov",
    "index":9,
    "Q":"Which CMU faculty member is an author on the paper entitled \"MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\"?",
    "A":"Yonatan Bisk",
    "category":"papers",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nauthors: Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, J. Sinapov\nyear: 2023\ntldr: This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"abstract: A holistic understanding of object properties across diverse sensory modalities (e.g., visual, audio, and haptic) is essential for tasks ranging from object categorization to complex manipulation. Drawing inspiration from cognitive science studies that emphasize the significance of multi-sensory integration in human perception, we introduce MOSAIC (Multi-modal Object property learning with Self-Attention and Integrated Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"10 exploratory behaviors, we demonstrate the versatility of MOSAIC in two task families: object categorization and object-fetching tasks. Our results underscore the efficacy of MOSAIC's unified representations, showing competitive performance in category recognition through a simple linear probe setup and excelling in the fetch object task under zero-shot transfer conditions. This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems. We have released the code, datasets, and additional results: https:\/\/github.com\/gtatiya\/MOSAIC.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"with Self-Attention and Integrated Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge that many fundamental object properties extend beyond the visual domain to encompass attributes like texture, mass distribution, or sounds, which significantly influence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from the extensive pre-trained Contrastive Language-Image Pre-training (CLIP) model, aligning these representations not only across",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"influence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from the extensive pre-trained Contrastive Language-Image Pre-training (CLIP) model, aligning these representations not only across vision but also haptic and auditory sensory modalities. Through extensive experiments on a dataset where a humanoid robot interacts with 100 objects across 10 exploratory behaviors, we demonstrate the versatility of MOSAIC in two task families: object categorization and object-fetching tasks. Our results underscore the efficacy of MOSAIC's unified representations, showing competitive performance in",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Louis-Philippe Morency | Publication | Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models.txt"
        },
        "page_content":"publication venue: International Conference on Multimodal Interaction\ntitle: Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models\nauthors: A. Vail, J. Girard, Lauren M. Bylsma, Jay Fournier, Holly A. Swartz, Jeffrey F. Cohn, Louis-Philippe Morency\nyear: 2023",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Louis-Philippe Morency | Publication | Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models.txt"
        },
        "page_content":"authors: A. Vail, J. Girard, Lauren M. Bylsma, Jay Fournier, Holly A. Swartz, Jeffrey F. Cohn, Louis-Philippe Morency\nyear: 2023\ntldr: This work presents a novel approach to learning multimodal and interpersonal representations of behavior dynamics during one-on-one interaction enabled by the introduction of a multiview extension of latent change score models that demonstrates improved performance over conventional approaches that rely upon summary statistics or correlational metrics.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"in research. Indeed, by itself, the Robotics Institute is the largest university robotics research group in the world, with more than 500 people and more than 100 ongoing research projects. A half-century ago, Perlis, Simon and Newell outlined a vision for computer science. The School of Computer Science at CMU remains committed to continuing and extending their vision in the context of big data and connected computing in the 21st century.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Louis-Philippe Morency | Publication | Factorized Contrastive Learning: Going Beyond Multi-view Redundancy.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Factorized Contrastive Learning: Going Beyond Multi-view Redundancy\nauthors: P. Liang, Zihao Deng, Martin Q. Ma, James Y. Zou, Louis-Philippe Morency, R. Salakhutdinov\nyear: 2023\ntldr: FactorCL is a new multimodal representation learning method to go beyond multi-view redundancy and captures both shared and unique information and achieves state-of-the-art results on six benchmarks.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | Nonverbal Communication through Expressive Objects.txt"
        },
        "page_content":"publication venue: Communications of the ACM\ntitle: Nonverbal Communication through Expressive Objects\nauthors: Stephanie Valencia, Mark Steidl, Michael L. Rivera, Cynthia L. Bennett, Jeffrey P. Bigham, H. Admoni\nyear: 2023\ntldr: This work works closely with an AAC user to understand how motion through a physical expressive object can support their communication and presents the process and resulting lessons on the designed object and the co-design process.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nauthors: Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, J. Sinapov\nyear: 2023\ntldr: This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"abstract: A holistic understanding of object properties across diverse sensory modalities (e.g., visual, audio, and haptic) is essential for tasks ranging from object categorization to complex manipulation. Drawing inspiration from cognitive science studies that emphasize the significance of multi-sensory integration in human perception, we introduce MOSAIC (Multi-modal Object property learning with Self-Attention and Integrated Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"10 exploratory behaviors, we demonstrate the versatility of MOSAIC in two task families: object categorization and object-fetching tasks. Our results underscore the efficacy of MOSAIC's unified representations, showing competitive performance in category recognition through a simple linear probe setup and excelling in the fetch object task under zero-shot transfer conditions. This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems. We have released the code, datasets, and additional results: https:\/\/github.com\/gtatiya\/MOSAIC.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"with Self-Attention and Integrated Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge that many fundamental object properties extend beyond the visual domain to encompass attributes like texture, mass distribution, or sounds, which significantly influence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from the extensive pre-trained Contrastive Language-Image Pre-training (CLIP) model, aligning these representations not only across",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception.txt"
        },
        "page_content":"influence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from the extensive pre-trained Contrastive Language-Image Pre-training (CLIP) model, aligning these representations not only across vision but also haptic and auditory sensory modalities. Through extensive experiments on a dataset where a humanoid robot interacts with 100 objects across 10 exploratory behaviors, we demonstrate the versatility of MOSAIC in two task families: object categorization and object-fetching tasks. Our results underscore the efficacy of MOSAIC's unified representations, showing competitive performance in",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Louis-Philippe Morency | Publication | Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models.txt"
        },
        "page_content":"publication venue: International Conference on Multimodal Interaction\ntitle: Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models\nauthors: A. Vail, J. Girard, Lauren M. Bylsma, Jay Fournier, Holly A. Swartz, Jeffrey F. Cohn, Louis-Philippe Morency\nyear: 2023",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Louis-Philippe Morency | Publication | Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models.txt"
        },
        "page_content":"authors: A. Vail, J. Girard, Lauren M. Bylsma, Jay Fournier, Holly A. Swartz, Jeffrey F. Cohn, Louis-Philippe Morency\nyear: 2023\ntldr: This work presents a novel approach to learning multimodal and interpersonal representations of behavior dynamics during one-on-one interaction enabled by the introduction of a multiview extension of latent change score models that demonstrates improved performance over conventional approaches that rely upon summary statistics or correlational metrics.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"in research. Indeed, by itself, the Robotics Institute is the largest university robotics research group in the world, with more than 500 people and more than 100 ongoing research projects. A half-century ago, Perlis, Simon and Newell outlined a vision for computer science. The School of Computer Science at CMU remains committed to continuing and extending their vision in the context of big data and connected computing in the 21st century.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Louis-Philippe Morency | Publication | Factorized Contrastive Learning: Going Beyond Multi-view Redundancy.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Factorized Contrastive Learning: Going Beyond Multi-view Redundancy\nauthors: P. Liang, Zihao Deng, Martin Q. Ma, James Y. Zou, Louis-Philippe Morency, R. Salakhutdinov\nyear: 2023\ntldr: FactorCL is a new multimodal representation learning method to go beyond multi-view redundancy and captures both shared and unique information and achieves state-of-the-art results on six benchmarks.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | Nonverbal Communication through Expressive Objects.txt"
        },
        "page_content":"publication venue: Communications of the ACM\ntitle: Nonverbal Communication through Expressive Objects\nauthors: Stephanie Valencia, Mark Steidl, Michael L. Rivera, Cynthia L. Bennett, Jeffrey P. Bigham, H. Admoni\nyear: 2023\ntldr: This work works closely with an AAC user to understand how motion through a physical expressive object can support their communication and presents the process and resulting lessons on the designed object and the co-design process.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe CMU faculty member who is an author on the paper entitled \"MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\" is:\n\n* J. Sinapov",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Which CMU faculty member is an author on the paper entitled \"MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\"?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\npublication venue: arXiv.org\ntitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nauthors: Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, J. Sinapov\nyear: 2023\ntldr: This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.\n-----\nabstract: A holistic understanding of object properties across diverse sensory modalities (e.g., visual, audio, and haptic) is essential for tasks ranging from object categorization to complex manipulation. Drawing inspiration from cognitive science studies that emphasize the significance of multi-sensory integration in human perception, we introduce MOSAIC (Multi-modal Object property learning with Self-Attention and Integrated Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge\n-----\n10 exploratory behaviors, we demonstrate the versatility of MOSAIC in two task families: object categorization and object-fetching tasks. Our results underscore the efficacy of MOSAIC's unified representations, showing competitive performance in category recognition through a simple linear probe setup and excelling in the fetch object task under zero-shot transfer conditions. This work pioneers the application of CLIP-based sensory grounding in robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems. We have released the code, datasets, and additional results: https:\/\/github.com\/gtatiya\/MOSAIC.\n-----\nwith Self-Attention and Integrated Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge that many fundamental object properties extend beyond the visual domain to encompass attributes like texture, mass distribution, or sounds, which significantly influence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from the extensive pre-trained Contrastive Language-Image Pre-training (CLIP) model, aligning these representations not only across\n-----\ninfluence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from the extensive pre-trained Contrastive Language-Image Pre-training (CLIP) model, aligning these representations not only across vision but also haptic and auditory sensory modalities. Through extensive experiments on a dataset where a humanoid robot interacts with 100 objects across 10 exploratory behaviors, we demonstrate the versatility of MOSAIC in two task families: object categorization and object-fetching tasks. Our results underscore the efficacy of MOSAIC's unified representations, showing competitive performance in\n-----\npublication venue: International Conference on Multimodal Interaction\ntitle: Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models\nauthors: A. Vail, J. Girard, Lauren M. Bylsma, Jay Fournier, Holly A. Swartz, Jeffrey F. Cohn, Louis-Philippe Morency\nyear: 2023\n-----\nauthors: A. Vail, J. Girard, Lauren M. Bylsma, Jay Fournier, Holly A. Swartz, Jeffrey F. Cohn, Louis-Philippe Morency\nyear: 2023\ntldr: This work presents a novel approach to learning multimodal and interpersonal representations of behavior dynamics during one-on-one interaction enabled by the introduction of a multiview extension of latent change score models that demonstrates improved performance over conventional approaches that rely upon summary statistics or correlational metrics.\n-----\nin research. Indeed, by itself, the Robotics Institute is the largest university robotics research group in the world, with more than 500 people and more than 100 ongoing research projects. A half-century ago, Perlis, Simon and Newell outlined a vision for computer science. The School of Computer Science at CMU remains committed to continuing and extending their vision in the context of big data and connected computing in the 21st century.\n-----\npublication venue: arXiv.org\ntitle: Factorized Contrastive Learning: Going Beyond Multi-view Redundancy\nauthors: P. Liang, Zihao Deng, Martin Q. Ma, James Y. Zou, Louis-Philippe Morency, R. Salakhutdinov\nyear: 2023\ntldr: FactorCL is a new multimodal representation learning method to go beyond multi-view redundancy and captures both shared and unique information and achieves state-of-the-art results on six benchmarks.\n-----\npublication venue: Communications of the ACM\ntitle: Nonverbal Communication through Expressive Objects\nauthors: Stephanie Valencia, Mark Steidl, Michael L. Rivera, Cynthia L. Bennett, Jeffrey P. Bigham, H. Admoni\nyear: 2023\ntldr: This work works closely with an AAC user to understand how motion through a physical expressive object can support their communication and presents the process and resulting lessons on the designed object and the co-design process.\n-----\n\n### Response ###\n\nUser: Which CMU faculty member is an author on the paper entitled \"MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\"?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Machine Learning, Multimodal Computing and Interaction, Privacy, Speech Processing, Spoken Interfaces and Dialogue Processing",
    "index":10,
    "Q":"What are Bhiksha Ramakrishnan's research areas? List them in alphabetical order, separated by comma.",
    "A":"Machine Learning, Multimodal Computing and Interaction, Speech Processing, Spoken Interfaces and Dialogue Processing, Privacy",
    "category":"directory",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Bhiksha Ramakrishnan.txt"
        },
        "page_content":"Name: Bhiksha Ramakrishnan\nTitle: Professor\nEmail bhiksha@cs.cmu.edu\nPhone: 412-268-9826\nOffice: 6705 Gates & Hillman Centers\nInterests: Machine Learning, Multimodal Computing and Interaction, Speech Processing, Spoken Interfaces and Dialogue Processing, Privacy",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 90-945 Independent Study.txt"
        },
        "page_content":"<start course metadata for 90-945 Independent Study>\nSemester: Spring 2024 (aka S24)\nCourse Name: Independent Study\nCourse Number: 90-945\nDepartment: Public Policy & Mgt:Sch of Pub Pol & Mgt\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 90-945 Independent Study>\n\n<start course description for 90-945 Independent Study>\nSemester: Spring 2024 (aka S24)\nCourse Description: to be determined\n<\/end course description for 90-945 Independent Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 18-797 Machine Learning for Signal Processing.txt"
        },
        "page_content":"<start course metadata for 18-797 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 18-797\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: B23 212; CMU REMOTE; DH A302\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-797 Machine Learning for Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 95-902 Independent Study.txt"
        },
        "page_content":"<start course metadata for 95-902 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Name: Independent Study\nCourse Number: 95-902\nDepartment: Information Systems:Sch of IS & Mgt\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Janusz Szczypula\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 95-902 Independent Study>\n\n<start course description for 95-902 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: None\n<\/end course description for 95-902 Independent Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-925 Independent Study_ Area.txt"
        },
        "page_content":"Number of Units: N\/A\nPrerequisites: None\nInstructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Anthony Tomasic, Bhiksha Ramakrishnan, Carolyn Rose, Christopher Langmead, Eduard Hovy, Eric Nyberg, Eric Xing, Eugene Fink, Florian Metze, Graham Neubig, Instructor TBA, Jack Mostow, Jamie Callan, Justine Cassell, Katia Sycara, Kenneth Koedinger, Lorraine Levin, Louis-Philippe Morency, Madhavi Ganapathiraju, Marcel Just, Maxine Eskenazi, Ralf Brown, Rita Singh, Robert Frederking, Ronald Rosenfeld, Scott Fahlman, Stacey Young, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Ziv Bar-Joseph\nRooms: DNM DNM",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-860 Quantum Computing, Cryptography and Machine Learning Lab.txt"
        },
        "page_content":"<start course metadata for 11-860 Quantum Computing, Cryptography and Machine Learning Lab>\nSemester: Spring 2024 (aka S24)\nCourse Name: Quantum Computing, Cryptography and Machine Learning Lab\nCourse Number: 11-860\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Daniel Justice, Rita Singh\nRooms: DH 1211\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-860 Quantum Computing, Cryptography and Machine Learning Lab>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-685 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-685 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-685\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-685 Introduction to Deep Learning>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-785 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-785 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-785\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-785 Introduction to Deep Learning>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-755 Machine Learning for Signal Processing.txt"
        },
        "page_content":"<start course metadata for 11-755 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 11-755\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: CMU REMOTE; DH A302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-755 Machine Learning for Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-685 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-685 Introduction to Deep Learning>\nSemester: Fall 2023 (aka F23)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-685\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-685 Introduction to Deep Learning>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Bhiksha Ramakrishnan.txt"
        },
        "page_content":"Name: Bhiksha Ramakrishnan\nTitle: Professor\nEmail bhiksha@cs.cmu.edu\nPhone: 412-268-9826\nOffice: 6705 Gates & Hillman Centers\nInterests: Machine Learning, Multimodal Computing and Interaction, Speech Processing, Spoken Interfaces and Dialogue Processing, Privacy",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 90-945 Independent Study.txt"
        },
        "page_content":"<start course metadata for 90-945 Independent Study>\nSemester: Spring 2024 (aka S24)\nCourse Name: Independent Study\nCourse Number: 90-945\nDepartment: Public Policy & Mgt:Sch of Pub Pol & Mgt\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 90-945 Independent Study>\n\n<start course description for 90-945 Independent Study>\nSemester: Spring 2024 (aka S24)\nCourse Description: to be determined\n<\/end course description for 90-945 Independent Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 18-797 Machine Learning for Signal Processing.txt"
        },
        "page_content":"<start course metadata for 18-797 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 18-797\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: B23 212; CMU REMOTE; DH A302\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-797 Machine Learning for Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 95-902 Independent Study.txt"
        },
        "page_content":"<start course metadata for 95-902 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Name: Independent Study\nCourse Number: 95-902\nDepartment: Information Systems:Sch of IS & Mgt\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Janusz Szczypula\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 95-902 Independent Study>\n\n<start course description for 95-902 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: None\n<\/end course description for 95-902 Independent Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-925 Independent Study_ Area.txt"
        },
        "page_content":"Number of Units: N\/A\nPrerequisites: None\nInstructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Anthony Tomasic, Bhiksha Ramakrishnan, Carolyn Rose, Christopher Langmead, Eduard Hovy, Eric Nyberg, Eric Xing, Eugene Fink, Florian Metze, Graham Neubig, Instructor TBA, Jack Mostow, Jamie Callan, Justine Cassell, Katia Sycara, Kenneth Koedinger, Lorraine Levin, Louis-Philippe Morency, Madhavi Ganapathiraju, Marcel Just, Maxine Eskenazi, Ralf Brown, Rita Singh, Robert Frederking, Ronald Rosenfeld, Scott Fahlman, Stacey Young, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Ziv Bar-Joseph\nRooms: DNM DNM",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-860 Quantum Computing, Cryptography and Machine Learning Lab.txt"
        },
        "page_content":"<start course metadata for 11-860 Quantum Computing, Cryptography and Machine Learning Lab>\nSemester: Spring 2024 (aka S24)\nCourse Name: Quantum Computing, Cryptography and Machine Learning Lab\nCourse Number: 11-860\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Daniel Justice, Rita Singh\nRooms: DH 1211\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-860 Quantum Computing, Cryptography and Machine Learning Lab>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-685 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-685 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-685\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-685 Introduction to Deep Learning>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-785 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-785 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-785\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-785 Introduction to Deep Learning>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-755 Machine Learning for Signal Processing.txt"
        },
        "page_content":"<start course metadata for 11-755 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 11-755\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: CMU REMOTE; DH A302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-755 Machine Learning for Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-685 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-685 Introduction to Deep Learning>\nSemester: Fall 2023 (aka F23)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-685\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-685 Introduction to Deep Learning>",
        "type":"Document"
      }
    ],
    "model_output":"\nBhiksha Ramakrishnan's research areas are:\n\n* Machine Learning\n* Multimodal Computing and Interaction\n* Speech Processing\n* Spoken Interfaces and Dialogue Processing\n* Privacy\n\nThese are listed in alphabetical order, separated by commas.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"What are Bhiksha Ramakrishnan's research areas? List them in alphabetical order, separated by comma.\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nName: Bhiksha Ramakrishnan\nTitle: Professor\nEmail bhiksha@cs.cmu.edu\nPhone: 412-268-9826\nOffice: 6705 Gates & Hillman Centers\nInterests: Machine Learning, Multimodal Computing and Interaction, Speech Processing, Spoken Interfaces and Dialogue Processing, Privacy\n-----\n<start course metadata for 90-945 Independent Study>\nSemester: Spring 2024 (aka S24)\nCourse Name: Independent Study\nCourse Number: 90-945\nDepartment: Public Policy & Mgt:Sch of Pub Pol & Mgt\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 90-945 Independent Study>\n\n<start course description for 90-945 Independent Study>\nSemester: Spring 2024 (aka S24)\nCourse Description: to be determined\n<\/end course description for 90-945 Independent Study>\n-----\n<start course metadata for 18-797 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 18-797\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: B23 212; CMU REMOTE; DH A302\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-797 Machine Learning for Signal Processing>\n-----\n<start course metadata for 95-902 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Name: Independent Study\nCourse Number: 95-902\nDepartment: Information Systems:Sch of IS & Mgt\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Janusz Szczypula\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 95-902 Independent Study>\n\n<start course description for 95-902 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: None\n<\/end course description for 95-902 Independent Study>\n-----\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Alexander Hauptmann, Alexander Rudnicky, Alexander Waibel, Anthony Tomasic, Bhiksha Ramakrishnan, Carolyn Rose, Christopher Langmead, Eduard Hovy, Eric Nyberg, Eric Xing, Eugene Fink, Florian Metze, Graham Neubig, Instructor TBA, Jack Mostow, Jamie Callan, Justine Cassell, Katia Sycara, Kenneth Koedinger, Lorraine Levin, Louis-Philippe Morency, Madhavi Ganapathiraju, Marcel Just, Maxine Eskenazi, Ralf Brown, Rita Singh, Robert Frederking, Ronald Rosenfeld, Scott Fahlman, Stacey Young, Teruko Mitamura, Tom Mitchell, William Cohen, Yiming Yang, Ziv Bar-Joseph\nRooms: DNM DNM\n-----\n<start course metadata for 11-860 Quantum Computing, Cryptography and Machine Learning Lab>\nSemester: Spring 2024 (aka S24)\nCourse Name: Quantum Computing, Cryptography and Machine Learning Lab\nCourse Number: 11-860\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Daniel Justice, Rita Singh\nRooms: DH 1211\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-860 Quantum Computing, Cryptography and Machine Learning Lab>\n-----\n<start course metadata for 11-685 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-685\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-685 Introduction to Deep Learning>\n-----\n<start course metadata for 11-785 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-785\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-785 Introduction to Deep Learning>\n-----\n<start course metadata for 11-755 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 11-755\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: CMU REMOTE; DH A302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-755 Machine Learning for Signal Processing>\n-----\n<start course metadata for 11-685 Introduction to Deep Learning>\nSemester: Fall 2023 (aka F23)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-685\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-685 Introduction to Deep Learning>\n-----\n\n### Response ###\n\nUser: What are Bhiksha Ramakrishnan's research areas? List them in alphabetical order, separated by comma.\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.7619047619,
    "recall":0.8888888889,
    "precision":0.6666666667,
    "A_hat":"Computational Social Science, Conversational AI, Discourse and Pragmatics, Fairness and Ethics in Language Technology, Intelligent Agents, Machine Learning, Natural Language Processing, Spoken Language Processing",
    "index":11,
    "Q":"What are Maarten Sap's research areas? List them in alphabetical order, separated by comma.",
    "A":"Fairness and Ethics in Language Technology, Computational Social Science, Discourse and Pragmatics, Conversational AI, Intelligent Agents, and Dialogue",
    "category":"directory",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Maarten Sap.txt"
        },
        "page_content":"Name: Maarten Sap\nTitle: Assistant Professor\nEmail msap2@andrew.cmu.edu\nPhone: \nOffice: \nInterests: Fairness and Ethics in Language Technology, Computational Social Science, Discourse and Pragmatics, Conversational AI, Intelligent Agents, and Dialogue",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-830 Ethics, Social Biases, and Positive Impact in Language Technologies.txt"
        },
        "page_content":"<start course metadata for 11-830 Ethics, Social Biases, and Positive Impact in Language Technologies>\nSemester: Spring 2024 (aka S24)\nCourse Name: Ethics, Social Biases, and Positive Impact in Language Technologies\nCourse Number: 11-830\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Maarten Sap\nRooms: POS 153\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-830 Ethics, Social Biases, and Positive Impact in Language Technologies>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-631 Data Science Seminar.txt"
        },
        "page_content":"<start course metadata for 11-631 Data Science Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Seminar\nCourse Number: 11-631\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Emma Strubell, Maarten Sap\nRooms: BH A36; GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-631 Data Science Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | Riveter: Measuring Power and Social Dynamics Between Entities.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Riveter: Measuring Power and Social Dynamics Between Entities\nauthors: Maria Antoniak, Anjalie Field, Jimin Mun, Melanie Walsh, Lauren F. Klein, Maarten Sap\nyear: 2023\ntldr: Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research by organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | NLPositionality: Characterizing Design Biases of Datasets and Models.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: NLPositionality: Characterizing Design Biases of Datasets and Models\nauthors: Sebastin Santy, Jenny T Liang, Ronan Le Bras, Katharina Reinecke, Maarten Sap\nyear: 2023\ntldr: NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models, is introduced and it is found that dataset and models align predominantly with Western, White, college-educated, and younger populations.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nauthors: Akhila Yerukola, Xuhui Zhou, Maarten Sap\nyear: 2023\ntldr: A new composite contextual evaluation metric is introduced that combines similarity to the original sentence with contextual cohesiveness and highlights the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models\nauthors: Julia Mendelsohn, Ronan Le Bras, Yejin Choi, Maarten Sap\nyear: 2023",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | Improving Language Models with Advantage-based Offline Policy Gradients.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Improving Language Models with Advantage-based Offline Policy Gradients\nauthors: Ashutosh Baheti, Ximing Lu, Faeze Brahman, Ronan Le Bras, Maarten Sap, Mark O. Riedl\nyear: 2023\ntldr: Advantage-Leftover Lunch RL (A-LoL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data that assumes the entire LM output sequence as a single action, and allows incorporating sequence-level classifiers or human-designed scoring functions as rewards.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 0.txt"
        },
        "page_content":"consisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language \nprocessing, machine learning, and computational biology.  Many MLT graduates continue on to PhD programs in the LTI or other leading universities.  Other graduates  go on to work in the \ncomputer industry, many at major corporate research laboratories.  \nThere are significant differences between CMU's different departments and degree programs in philosophical approach, procedures, policies , and regulations. Each department issues a",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements\nauthors: Xuhui Zhou, Haojie Zhu, Akhila Yerukola, Thomas Davidson, Jena D. Hwang, Swabha Swayamdipta, Maarten Sap\nyear: 2023\ntldr: COBRA frames are introduced, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context, and the importance and feasibility of contextualized NLP by modeling social factors are highlighted.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Maarten Sap.txt"
        },
        "page_content":"Name: Maarten Sap\nTitle: Assistant Professor\nEmail msap2@andrew.cmu.edu\nPhone: \nOffice: \nInterests: Fairness and Ethics in Language Technology, Computational Social Science, Discourse and Pragmatics, Conversational AI, Intelligent Agents, and Dialogue",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-830 Ethics, Social Biases, and Positive Impact in Language Technologies.txt"
        },
        "page_content":"<start course metadata for 11-830 Ethics, Social Biases, and Positive Impact in Language Technologies>\nSemester: Spring 2024 (aka S24)\nCourse Name: Ethics, Social Biases, and Positive Impact in Language Technologies\nCourse Number: 11-830\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Maarten Sap\nRooms: POS 153\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-830 Ethics, Social Biases, and Positive Impact in Language Technologies>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-631 Data Science Seminar.txt"
        },
        "page_content":"<start course metadata for 11-631 Data Science Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Seminar\nCourse Number: 11-631\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Emma Strubell, Maarten Sap\nRooms: BH A36; GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-631 Data Science Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | Riveter: Measuring Power and Social Dynamics Between Entities.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Riveter: Measuring Power and Social Dynamics Between Entities\nauthors: Maria Antoniak, Anjalie Field, Jimin Mun, Melanie Walsh, Lauren F. Klein, Maarten Sap\nyear: 2023\ntldr: Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research by organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | NLPositionality: Characterizing Design Biases of Datasets and Models.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: NLPositionality: Characterizing Design Biases of Datasets and Models\nauthors: Sebastin Santy, Jenny T Liang, Ronan Le Bras, Katharina Reinecke, Maarten Sap\nyear: 2023\ntldr: NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models, is introduced and it is found that dataset and models align predominantly with Western, White, college-educated, and younger populations.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nauthors: Akhila Yerukola, Xuhui Zhou, Maarten Sap\nyear: 2023\ntldr: A new composite contextual evaluation metric is introduced that combines similarity to the original sentence with contextual cohesiveness and highlights the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models\nauthors: Julia Mendelsohn, Ronan Le Bras, Yejin Choi, Maarten Sap\nyear: 2023",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | Improving Language Models with Advantage-based Offline Policy Gradients.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Improving Language Models with Advantage-based Offline Policy Gradients\nauthors: Ashutosh Baheti, Ximing Lu, Faeze Brahman, Ronan Le Bras, Maarten Sap, Mark O. Riedl\nyear: 2023\ntldr: Advantage-Leftover Lunch RL (A-LoL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data that assumes the entire LM output sequence as a single action, and allows incorporating sequence-level classifiers or human-designed scoring functions as rewards.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 0.txt"
        },
        "page_content":"consisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language \nprocessing, machine learning, and computational biology.  Many MLT graduates continue on to PhD programs in the LTI or other leading universities.  Other graduates  go on to work in the \ncomputer industry, many at major corporate research laboratories.  \nThere are significant differences between CMU's different departments and degree programs in philosophical approach, procedures, policies , and regulations. Each department issues a",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Maarten Sap | Publication | COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements\nauthors: Xuhui Zhou, Haojie Zhu, Akhila Yerukola, Thomas Davidson, Jena D. Hwang, Swabha Swayamdipta, Maarten Sap\nyear: 2023\ntldr: COBRA frames are introduced, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context, and the importance and feasibility of contextualized NLP by modeling social factors are highlighted.",
        "type":"Document"
      }
    ],
    "model_output":"\nMaarten Sap's research areas are:\n\n* Computational Social Science\n* Conversational AI\n* Discourse and Pragmatics\n* Fairness and Ethics in Language Technology\n* Intelligent Agents\n* Machine Learning\n* Natural Language Processing\n* Spoken Language Processing\n\nNote: These research areas are mentioned in the provided context documents, and are relevant to Maarten Sap's work in the Language",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"What are Maarten Sap's research areas? List them in alphabetical order, separated by comma.\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nName: Maarten Sap\nTitle: Assistant Professor\nEmail msap2@andrew.cmu.edu\nPhone: \nOffice: \nInterests: Fairness and Ethics in Language Technology, Computational Social Science, Discourse and Pragmatics, Conversational AI, Intelligent Agents, and Dialogue\n-----\n<start course metadata for 11-830 Ethics, Social Biases, and Positive Impact in Language Technologies>\nSemester: Spring 2024 (aka S24)\nCourse Name: Ethics, Social Biases, and Positive Impact in Language Technologies\nCourse Number: 11-830\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Maarten Sap\nRooms: POS 153\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-830 Ethics, Social Biases, and Positive Impact in Language Technologies>\n-----\n<start course metadata for 11-631 Data Science Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Seminar\nCourse Number: 11-631\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Emma Strubell, Maarten Sap\nRooms: BH A36; GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-631 Data Science Seminar>\n-----\npublication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: Riveter: Measuring Power and Social Dynamics Between Entities\nauthors: Maria Antoniak, Anjalie Field, Jimin Mun, Melanie Walsh, Lauren F. Klein, Maarten Sap\nyear: 2023\ntldr: Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research by organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions.\n-----\npublication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: NLPositionality: Characterizing Design Biases of Datasets and Models\nauthors: Sebastin Santy, Jenny T Liang, Ronan Le Bras, Katharina Reinecke, Maarten Sap\nyear: 2023\ntldr: NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models, is introduced and it is found that dataset and models align predominantly with Western, White, college-educated, and younger populations.\n-----\npublication venue: arXiv.org\ntitle: Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nauthors: Akhila Yerukola, Xuhui Zhou, Maarten Sap\nyear: 2023\ntldr: A new composite contextual evaluation metric is introduced that combines similarity to the original sentence with contextual cohesiveness and highlights the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.\n-----\npublication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models\nauthors: Julia Mendelsohn, Ronan Le Bras, Yejin Choi, Maarten Sap\nyear: 2023\n-----\npublication venue: arXiv.org\ntitle: Improving Language Models with Advantage-based Offline Policy Gradients\nauthors: Ashutosh Baheti, Ximing Lu, Faeze Brahman, Ronan Le Bras, Maarten Sap, Mark O. Riedl\nyear: 2023\ntldr: Advantage-Leftover Lunch RL (A-LoL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data that assumes the entire LM output sequence as a single action, and allows incorporating sequence-level classifiers or human-designed scoring functions as rewards.\n-----\nconsisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language \nprocessing, machine learning, and computational biology.  Many MLT graduates continue on to PhD programs in the LTI or other leading universities.  Other graduates  go on to work in the \ncomputer industry, many at major corporate research laboratories.  \nThere are significant differences between CMU's different departments and degree programs in philosophical approach, procedures, policies , and regulations. Each department issues a\n-----\npublication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements\nauthors: Xuhui Zhou, Haojie Zhu, Akhila Yerukola, Thomas Davidson, Jena D. Hwang, Swabha Swayamdipta, Maarten Sap\nyear: 2023\ntldr: COBRA frames are introduced, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context, and the importance and feasibility of contextualized NLP by modeling social factors are highlighted.\n-----\n\n### Response ###\n\nUser: What are Maarten Sap's research areas? List them in alphabetical order, separated by comma.\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Jason Wu",
    "index":12,
    "Q":"Who is the first author of the paper called \"WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics\"?",
    "A":"Jason Wu",
    "category":"papers",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics.txt"
        },
        "page_content":"publication venue: International Conference on Human Factors in Computing Systems\ntitle: WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics\nauthors: Jason Wu, Siyan Wang, Siman Shen, Yi-Hao Peng, Jeffrey Nichols, Jeffrey P. Bigham\nyear: 2023\ntldr: This work crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata, and analyzed the composition of WebUI to show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics.txt"
        },
        "page_content":"WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling. We applied several strategies for incorporating semantics found in web pages to increase the performance of visual UI understanding models in the mobile domain, where less labeled data is available: (i) element detection, (ii) screen classification and (iii) screen similarity.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics.txt"
        },
        "page_content":"abstract: Modeling user interfaces (UIs) from visual information allows systems to make inferences about the functionality and semantics needed to support use cases in accessibility, app automation, and testing. Current datasets for training machine learning models are limited in size due to the costly and time-consuming process of manually collecting and annotating UIs. We crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy, most examples meet basic criteria for visual",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | Screen Correspondence: Mapping Interchangeable Elements between UIs.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Screen Correspondence: Mapping Interchangeable Elements between UIs\nauthors: Jason Wu, Amanda Swearngin, Xiaoyi Zhang, Jeffrey Nichols, Jeffrey P. Bigham\nyear: 2023\ntldr: This paper describes and implements a model that incorporates element semantics, appearance, and text to support correspondence computation without requiring any labeled examples, and shows that this approach improves upon baselines by incorporating multi-modal properties of UIs.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | Never-ending Learning of User Interfaces.txt"
        },
        "page_content":"publication venue: ACM Symposium on User Interface Software and Technology\ntitle: Never-ending Learning of User Interfaces\nauthors: Jason Wu, Rebecca Krosnick, E. Schoop, Amanda Swearngin, Jeffrey P. Bigham, Jeffrey Nichols\nyear: 2023\ntldr: The Never-ending UI Learner is presented, an app crawler that automatically installs real apps from a mobile app store and crawls them to infer semantic properties of UIs by interacting with UI elements, discovering new and challenging training examples to learn from, and continually updating machine learning models designed to predict these semantics.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Lu Jiang | Publication | Learning Disentangled Prompts for Compositional Image Synthesis.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Learning Disentangled Prompts for Compositional Image Synthesis\nauthors: Kihyuk Sohn, Albert Eaton Shaw, Yuan Hao, Han Zhang, Luisa F. Polan\u00eda, Huiwen Chang, Lu Jiang, Irfan Essa\nyear: 2023\ntldr: This work proposes a novel source class distilled visual prompt that learns disentangled prompts of semantic and domain from a few images, and shows that this method can help improve zero-shot domain adaptation classification accuracy.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Lu Jiang | Publication | SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jamie Callan | Publication | CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms.txt"
        },
        "page_content":"publication venue: International Conference on the Theory of Information Retrieval\ntitle: CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nauthors: Zhen Fan, Luyu Gao, Jamie Callan\nyear: 2023\ntldr: This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF), reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact- match-based system.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics.txt"
        },
        "page_content":"publication venue: International Conference on Human Factors in Computing Systems\ntitle: WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics\nauthors: Jason Wu, Siyan Wang, Siman Shen, Yi-Hao Peng, Jeffrey Nichols, Jeffrey P. Bigham\nyear: 2023\ntldr: This work crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata, and analyzed the composition of WebUI to show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics.txt"
        },
        "page_content":"WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling. We applied several strategies for incorporating semantics found in web pages to increase the performance of visual UI understanding models in the mobile domain, where less labeled data is available: (i) element detection, (ii) screen classification and (iii) screen similarity.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics.txt"
        },
        "page_content":"abstract: Modeling user interfaces (UIs) from visual information allows systems to make inferences about the functionality and semantics needed to support use cases in accessibility, app automation, and testing. Current datasets for training machine learning models are limited in size due to the costly and time-consuming process of manually collecting and annotating UIs. We crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy, most examples meet basic criteria for visual",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | Screen Correspondence: Mapping Interchangeable Elements between UIs.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Screen Correspondence: Mapping Interchangeable Elements between UIs\nauthors: Jason Wu, Amanda Swearngin, Xiaoyi Zhang, Jeffrey Nichols, Jeffrey P. Bigham\nyear: 2023\ntldr: This paper describes and implements a model that incorporates element semantics, appearance, and text to support correspondence computation without requiring any labeled examples, and shows that this approach improves upon baselines by incorporating multi-modal properties of UIs.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jeffrey Bigham | Publication | Never-ending Learning of User Interfaces.txt"
        },
        "page_content":"publication venue: ACM Symposium on User Interface Software and Technology\ntitle: Never-ending Learning of User Interfaces\nauthors: Jason Wu, Rebecca Krosnick, E. Schoop, Amanda Swearngin, Jeffrey P. Bigham, Jeffrey Nichols\nyear: 2023\ntldr: The Never-ending UI Learner is presented, an app crawler that automatically installs real apps from a mobile app store and crawls them to infer semantic properties of UIs by interacting with UI elements, discovering new and challenging training examples to learn from, and continually updating machine learning models designed to predict these semantics.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Lu Jiang | Publication | Learning Disentangled Prompts for Compositional Image Synthesis.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Learning Disentangled Prompts for Compositional Image Synthesis\nauthors: Kihyuk Sohn, Albert Eaton Shaw, Yuan Hao, Han Zhang, Luisa F. Polan\u00eda, Huiwen Chang, Lu Jiang, Irfan Essa\nyear: 2023\ntldr: This work proposes a novel source class distilled visual prompt that learns disentangled prompts of semantic and domain from a few images, and shows that this method can help improve zero-shot domain adaptation classification accuracy.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Lu Jiang | Publication | SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Jamie Callan | Publication | CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms.txt"
        },
        "page_content":"publication venue: International Conference on the Theory of Information Retrieval\ntitle: CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nauthors: Zhen Fan, Luyu Gao, Jamie Callan\nyear: 2023\ntldr: This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF), reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact- match-based system.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | WebArena: A Realistic Web Environment for Building Autonomous Agents.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe first author of the paper called \"WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics\" is Jason Wu.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is the first author of the paper called \"WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics\"?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\npublication venue: International Conference on Human Factors in Computing Systems\ntitle: WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics\nauthors: Jason Wu, Siyan Wang, Siman Shen, Yi-Hao Peng, Jeffrey Nichols, Jeffrey P. Bigham\nyear: 2023\ntldr: This work crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata, and analyzed the composition of WebUI to show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling.\n-----\nWebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling. We applied several strategies for incorporating semantics found in web pages to increase the performance of visual UI understanding models in the mobile domain, where less labeled data is available: (i) element detection, (ii) screen classification and (iii) screen similarity.\n-----\nabstract: Modeling user interfaces (UIs) from visual information allows systems to make inferences about the functionality and semantics needed to support use cases in accessibility, app automation, and testing. Current datasets for training machine learning models are limited in size due to the costly and time-consuming process of manually collecting and annotating UIs. We crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy, most examples meet basic criteria for visual\n-----\npublication venue: arXiv.org\ntitle: Screen Correspondence: Mapping Interchangeable Elements between UIs\nauthors: Jason Wu, Amanda Swearngin, Xiaoyi Zhang, Jeffrey Nichols, Jeffrey P. Bigham\nyear: 2023\ntldr: This paper describes and implements a model that incorporates element semantics, appearance, and text to support correspondence computation without requiring any labeled examples, and shows that this approach improves upon baselines by incorporating multi-modal properties of UIs.\n-----\npublication venue: ACM Symposium on User Interface Software and Technology\ntitle: Never-ending Learning of User Interfaces\nauthors: Jason Wu, Rebecca Krosnick, E. Schoop, Amanda Swearngin, Jeffrey P. Bigham, Jeffrey Nichols\nyear: 2023\ntldr: The Never-ending UI Learner is presented, an app crawler that automatically installs real apps from a mobile app store and crawls them to infer semantic properties of UIs by interacting with UI elements, discovering new and challenging training examples to learn from, and continually updating machine learning models designed to predict these semantics.\n-----\npublication venue: arXiv.org\ntitle: Learning Disentangled Prompts for Compositional Image Synthesis\nauthors: Kihyuk Sohn, Albert Eaton Shaw, Yuan Hao, Han Zhang, Luisa F. Polan\u00eda, Huiwen Chang, Lu Jiang, Irfan Essa\nyear: 2023\ntldr: This work proposes a novel source class distilled visual prompt that learns disentangled prompts of semantic and domain from a few images, and shows that this method can help improve zero-shot domain adaptation classification accuracy.\n-----\npublication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.\n-----\npublication venue: arXiv.org\ntitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nauthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nyear: 2023\ntldr: This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.\n-----\npublication venue: International Conference on the Theory of Information Retrieval\ntitle: CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nauthors: Zhen Fan, Luyu Gao, Jamie Callan\nyear: 2023\ntldr: This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF), reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact- match-based system.\n-----\npublication venue: arXiv.org\ntitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nauthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nyear: 2023\ntldr: This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.\n-----\n\n### Response ###\n\nUser: Who is the first author of the paper called \"WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics\"?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Badr AlKhamissi",
    "index":13,
    "Q":"Who is the first author of the paper called \"OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\"?",
    "A":"Badr AlKhamissi",
    "category":"papers",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.txt"
        },
        "page_content":"title: OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\nauthors: Badr AlKhamissi, Siddharth Verma, Ping Yu, Zhijing Jin, Asli Celikyilmaz, Mona T. Diab\nyear: 2023\ntldr: It is revealed that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart, and a slight yet consistent increase in classification accuracy as the authors incorporate explanations during prompting and finetuning.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.txt"
        },
        "page_content":"abstract: We conduct a thorough investigation into the reasoning capabilities of Large Language Models (LLMs), focusing specifically on the Open Pretrained Transformers (OPT) models as a representative of such models. Our study entails finetuning three different sizes of OPT on a carefully curated reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned without explanations, and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the Super-NaturalInstructions benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.txt"
        },
        "page_content":"and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the Super-NaturalInstructions benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation.txt"
        },
        "page_content":"publication venue: Conference on Machine Translation\ntitle: The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation\nauthors: Patrick Fernandes, Daniel Deutsch, M. Finkelstein, Parker Riley, Andr\u00e9 F. T. Martins, Graham Neubig, Ankush Garg, J. Clark, Markus Freitag, Orhan Firat\nyear: 2023\ntldr: This paper proposes AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations, and finds that it improves performance compared to just prompting for scores.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | ALERT: Adapt Language Models to Reasoning Tasks.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: ALERT: Adapt Language Models to Reasoning Tasks\nyear: 2023\ntldr: The extensive empirical analysis shows that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage, but also finds that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization problems.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.txt"
        },
        "page_content":"on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart. Moreover, we observe a slight yet consistent increase in classification accuracy as we incorporate explanations during prompting and finetuning, respectively. Finally, we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.txt"
        },
        "page_content":"we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative effects.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation.txt"
        },
        "page_content":"gap by proposing AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations. We start by evaluating recent LLMs, such as PaLM and PaLM-2, through simple score prediction prompting, and we study the impact of labeled data through in-context learning and finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that it improves performance compared to just prompting for scores (with particularly large gains for larger models) while providing interpretability through error spans that align with human",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | Can Large Language Models Infer Causation from Correlation?.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Can Large Language Models Infer Causation from Correlation?\nauthors: Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona T. Diab, B. Scholkopf\nyear: 2023\ntldr: This work proposes the first benchmark dataset to test the pure causal inference skills of large language models (LLMs), and formulates a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Reasoning about the Unseen for Efficient Outdoor Object Navigation.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Reasoning about the Unseen for Efficient Outdoor Object Navigation\nauthors: Quanting Xie, Tianyi Zhang, Kedi Xu, M. Johnson-Roberson, Yonatan Bisk\nyear: 2023\ntldr: A new task OUTDOOR is introduced, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain are introduced.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.txt"
        },
        "page_content":"title: OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\nauthors: Badr AlKhamissi, Siddharth Verma, Ping Yu, Zhijing Jin, Asli Celikyilmaz, Mona T. Diab\nyear: 2023\ntldr: It is revealed that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart, and a slight yet consistent increase in classification accuracy as the authors incorporate explanations during prompting and finetuning.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.txt"
        },
        "page_content":"abstract: We conduct a thorough investigation into the reasoning capabilities of Large Language Models (LLMs), focusing specifically on the Open Pretrained Transformers (OPT) models as a representative of such models. Our study entails finetuning three different sizes of OPT on a carefully curated reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned without explanations, and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the Super-NaturalInstructions benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.txt"
        },
        "page_content":"and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the Super-NaturalInstructions benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation.txt"
        },
        "page_content":"publication venue: Conference on Machine Translation\ntitle: The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation\nauthors: Patrick Fernandes, Daniel Deutsch, M. Finkelstein, Parker Riley, Andr\u00e9 F. T. Martins, Graham Neubig, Ankush Garg, J. Clark, Markus Freitag, Orhan Firat\nyear: 2023\ntldr: This paper proposes AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations, and finds that it improves performance compared to just prompting for scores.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | ALERT: Adapt Language Models to Reasoning Tasks.txt"
        },
        "page_content":"publication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: ALERT: Adapt Language Models to Reasoning Tasks\nyear: 2023\ntldr: The extensive empirical analysis shows that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage, but also finds that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization problems.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.txt"
        },
        "page_content":"on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart. Moreover, we observe a slight yet consistent increase in classification accuracy as we incorporate explanations during prompting and finetuning, respectively. Finally, we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models.txt"
        },
        "page_content":"we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative effects.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation.txt"
        },
        "page_content":"gap by proposing AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations. We start by evaluating recent LLMs, such as PaLM and PaLM-2, through simple score prediction prompting, and we study the impact of labeled data through in-context learning and finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that it improves performance compared to just prompting for scores (with particularly large gains for larger models) while providing interpretability through error spans that align with human",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Mona Diab | Publication | Can Large Language Models Infer Causation from Correlation?.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Can Large Language Models Infer Causation from Correlation?\nauthors: Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona T. Diab, B. Scholkopf\nyear: 2023\ntldr: This work proposes the first benchmark dataset to test the pure causal inference skills of large language models (LLMs), and formulates a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Yonatan Bisk | Publication | Reasoning about the Unseen for Efficient Outdoor Object Navigation.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Reasoning about the Unseen for Efficient Outdoor Object Navigation\nauthors: Quanting Xie, Tianyi Zhang, Kedi Xu, M. Johnson-Roberson, Yonatan Bisk\nyear: 2023\ntldr: A new task OUTDOOR is introduced, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain are introduced.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe first author of the paper called \"OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\" is Badr AlKhamissi.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is the first author of the paper called \"OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\"?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\ntitle: OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\nauthors: Badr AlKhamissi, Siddharth Verma, Ping Yu, Zhijing Jin, Asli Celikyilmaz, Mona T. Diab\nyear: 2023\ntldr: It is revealed that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart, and a slight yet consistent increase in classification accuracy as the authors incorporate explanations during prompting and finetuning.\n-----\nabstract: We conduct a thorough investigation into the reasoning capabilities of Large Language Models (LLMs), focusing specifically on the Open Pretrained Transformers (OPT) models as a representative of such models. Our study entails finetuning three different sizes of OPT on a carefully curated reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned without explanations, and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the Super-NaturalInstructions benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive\n-----\nand OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the Super-NaturalInstructions benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart.\n-----\npublication venue: Conference on Machine Translation\ntitle: The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation\nauthors: Patrick Fernandes, Daniel Deutsch, M. Finkelstein, Parker Riley, Andr\u00e9 F. T. Martins, Graham Neubig, Ankush Garg, J. Clark, Markus Freitag, Orhan Firat\nyear: 2023\ntldr: This paper proposes AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations, and finds that it improves performance compared to just prompting for scores.\n-----\npublication venue: Annual Meeting of the Association for Computational Linguistics\ntitle: ALERT: Adapt Language Models to Reasoning Tasks\nyear: 2023\ntldr: The extensive empirical analysis shows that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage, but also finds that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization problems.\n-----\non different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart. Moreover, we observe a slight yet consistent increase in classification accuracy as we incorporate explanations during prompting and finetuning, respectively. Finally, we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative\n-----\nwe offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative effects.\n-----\ngap by proposing AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations. We start by evaluating recent LLMs, such as PaLM and PaLM-2, through simple score prediction prompting, and we study the impact of labeled data through in-context learning and finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that it improves performance compared to just prompting for scores (with particularly large gains for larger models) while providing interpretability through error spans that align with human\n-----\npublication venue: arXiv.org\ntitle: Can Large Language Models Infer Causation from Correlation?\nauthors: Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona T. Diab, B. Scholkopf\nyear: 2023\ntldr: This work proposes the first benchmark dataset to test the pure causal inference skills of large language models (LLMs), and formulates a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables.\n-----\npublication venue: arXiv.org\ntitle: Reasoning about the Unseen for Efficient Outdoor Object Navigation\nauthors: Quanting Xie, Tianyi Zhang, Kedi Xu, M. Johnson-Roberson, Yonatan Bisk\nyear: 2023\ntldr: A new task OUTDOOR is introduced, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain are introduced.\n-----\n\n### Response ###\n\nUser: Who is the first author of the paper called \"OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\"?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Amanda Bertsch",
    "index":14,
    "Q":"Who is the first author of the paper called \"Unlimiformer: Long-Range Transformers with Unlimited Length Input\"?",
    "A":"Amanda Bertsch",
    "category":"papers",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Unlimiformer: Long-Range Transformers with Unlimited Length Input\nauthors: Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley\nyear: 2023\ntldr: This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Matt Gormley | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Unlimiformer: Long-Range Transformers with Unlimited Length Input\nauthors: Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley\nyear: 2023\ntldr: This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"abstract: Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Matt Gormley | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"abstract: Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https:\/\/github.com\/abertsch72\/unlimiformer .",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Matt Gormley | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https:\/\/github.com\/abertsch72\/unlimiformer .",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Lu Jiang | Publication | Muse: Text-To-Image Generation via Masked Generative Transformers.txt"
        },
        "page_content":"publication venue: International Conference on Machine Learning\ntitle: Muse: Text-To-Image Generation via Masked Generative Transformers\nauthors: Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, Jos\u00e9 Lezama, Lu Jiang, Ming Yang, K. Murphy, W. Freeman, Michael Rubinstein, Yuanzhen Li, Dilip Krishnan\nyear: 2023\ntldr: None",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Eric Nyberg | Publication | Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA.txt"
        },
        "page_content":"publication venue: Workshop on Document-grounded Dialogue and Conversational Question Answering\ntitle: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nauthors: Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg\nyear: 2023\ntldr: This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Matt Gormley | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Unlimiformer: Long-Range Transformers with Unlimited Length Input\nauthors: Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley\nyear: 2023\ntldr: This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Matt Gormley | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"publication venue: arXiv.org\ntitle: Unlimiformer: Long-Range Transformers with Unlimited Length Input\nauthors: Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley\nyear: 2023\ntldr: This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"abstract: Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Matt Gormley | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"abstract: Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https:\/\/github.com\/abertsch72\/unlimiformer .",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Matt Gormley | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https:\/\/github.com\/abertsch72\/unlimiformer .",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Lu Jiang | Publication | Muse: Text-To-Image Generation via Masked Generative Transformers.txt"
        },
        "page_content":"publication venue: International Conference on Machine Learning\ntitle: Muse: Text-To-Image Generation via Masked Generative Transformers\nauthors: Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, Jos\u00e9 Lezama, Lu Jiang, Ming Yang, K. Murphy, W. Freeman, Michael Rubinstein, Yuanzhen Li, Dilip Krishnan\nyear: 2023\ntldr: None",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Eric Nyberg | Publication | Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA.txt"
        },
        "page_content":"publication venue: Workshop on Document-grounded Dialogue and Conversational Question Answering\ntitle: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nauthors: Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg\nyear: 2023\ntldr: This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Graham Neubig | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/papers\/Matt Gormley | Publication | Unlimiformer: Long-Range Transformers with Unlimited Length Input.txt"
        },
        "page_content":"are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without",
        "type":"Document"
      }
    ],
    "model_output":"\nThe first author of the paper called \"Unlimiformer: Long-Range Transformers with Unlimited Length Input\" is Amanda Bertsch.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is the first author of the paper called \"Unlimiformer: Long-Range Transformers with Unlimited Length Input\"?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\npublication venue: arXiv.org\ntitle: Unlimiformer: Long-Range Transformers with Unlimited Length Input\nauthors: Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley\nyear: 2023\ntldr: This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.\n-----\npublication venue: arXiv.org\ntitle: Unlimiformer: Long-Range Transformers with Unlimited Length Input\nauthors: Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley\nyear: 2023\ntldr: This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.\n-----\nabstract: Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer\n-----\nabstract: Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer\n-----\nit can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https:\/\/github.com\/abertsch72\/unlimiformer .\n-----\nit can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https:\/\/github.com\/abertsch72\/unlimiformer .\n-----\npublication venue: International Conference on Machine Learning\ntitle: Muse: Text-To-Image Generation via Masked Generative Transformers\nauthors: Huiwen Chang, Han Zhang, Jarred Barber, AJ Maschinot, Jos\u00e9 Lezama, Lu Jiang, Ming Yang, K. Murphy, W. Freeman, Michael Rubinstein, Yuanzhen Li, Dilip Krishnan\nyear: 2023\ntldr: None\n-----\npublication venue: Workshop on Document-grounded Dialogue and Conversational Question Answering\ntitle: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nauthors: Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg\nyear: 2023\ntldr: This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.\n-----\nare the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without\n-----\nare the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without\n-----\n\n### Response ###\n\nUser: Who is the first author of the paper called \"Unlimiformer: Long-Range Transformers with Unlimited Length Input\"?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Lorraine Levin",
    "index":15,
    "Q":"Who taught the course \"Human Language for Artificial Intelligence\" in fall 2023?",
    "A":"Lorraine Levin",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-624 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course metadata for 11-624 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human Language for Artificial Intelligence\nCourse Number: 11-624\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Lorraine Levin\nRooms: WEH 5409\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-624 Human Language for Artificial Intelligence>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-724 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course metadata for 11-724 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human Language for Artificial Intelligence\nCourse Number: 11-724\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Lorraine Levin\nRooms: WEH 5409\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-724 Human Language for Artificial Intelligence>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-324 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course metadata for 11-324 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human Language for Artificial Intelligence\nCourse Number: 11-324\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Lorraine Levin\nRooms: WEH 5409\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-324 Human Language for Artificial Intelligence>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-324 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course description for 11-324 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-624 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course description for 11-624 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-724 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course description for 11-724 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 85-213 Human information processing and artificial intelligence.txt"
        },
        "page_content":"<start course metadata for 85-213 Human information processing and artificial intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human information processing and artificial intelligence\nCourse Number: 85-213\nDepartment: Psychology\nNumber of Units: 9\nPrerequisites: 15-122 or 15-150\nInstructors: John Anderson\nRooms: GHC 4301\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 85-213 Human information processing and artificial intelligence>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 05-617 Design of Artificial Intelligence Products.txt"
        },
        "page_content":"<start course metadata for 05-617 Design of Artificial Intelligence Products>\nSemester: Fall 2023 (aka F23)\nCourse Name: Design of Artificial Intelligence Products\nCourse Number: 05-617\nDepartment: Human-Computer Interaction\nNumber of Units: 12\nPrerequisites: None\nInstructors: Daniel Saffer, John Zimmerman, Nikolas Martelaro, Raelin Musuraca\nRooms: 4SC 104\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 05-617 Design of Artificial Intelligence Products>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 05-317 Design of Artificial Intelligence Products.txt"
        },
        "page_content":"<start course metadata for 05-317 Design of Artificial Intelligence Products>\nSemester: Fall 2023 (aka F23)\nCourse Name: Design of Artificial Intelligence Products\nCourse Number: 05-317\nDepartment: Human-Computer Interaction\nNumber of Units: 12\nPrerequisites: None\nInstructors: Daniel Saffer, John Zimmerman, Nikolas Martelaro, Raelin Musuraca\nRooms: 4SC 104\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 05-317 Design of Artificial Intelligence Products>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 85-213 Human information processing and artificial intelligence.txt"
        },
        "page_content":"<start course description for 85-213 Human information processing and artificial intelligence>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-624 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course metadata for 11-624 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human Language for Artificial Intelligence\nCourse Number: 11-624\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Lorraine Levin\nRooms: WEH 5409\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-624 Human Language for Artificial Intelligence>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-724 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course metadata for 11-724 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human Language for Artificial Intelligence\nCourse Number: 11-724\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Lorraine Levin\nRooms: WEH 5409\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-724 Human Language for Artificial Intelligence>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-324 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course metadata for 11-324 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human Language for Artificial Intelligence\nCourse Number: 11-324\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Lorraine Levin\nRooms: WEH 5409\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-324 Human Language for Artificial Intelligence>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-324 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course description for 11-324 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-624 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course description for 11-624 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-724 Human Language for Artificial Intelligence.txt"
        },
        "page_content":"<start course description for 11-724 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 85-213 Human information processing and artificial intelligence.txt"
        },
        "page_content":"<start course metadata for 85-213 Human information processing and artificial intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human information processing and artificial intelligence\nCourse Number: 85-213\nDepartment: Psychology\nNumber of Units: 9\nPrerequisites: 15-122 or 15-150\nInstructors: John Anderson\nRooms: GHC 4301\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 85-213 Human information processing and artificial intelligence>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 05-617 Design of Artificial Intelligence Products.txt"
        },
        "page_content":"<start course metadata for 05-617 Design of Artificial Intelligence Products>\nSemester: Fall 2023 (aka F23)\nCourse Name: Design of Artificial Intelligence Products\nCourse Number: 05-617\nDepartment: Human-Computer Interaction\nNumber of Units: 12\nPrerequisites: None\nInstructors: Daniel Saffer, John Zimmerman, Nikolas Martelaro, Raelin Musuraca\nRooms: 4SC 104\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 05-617 Design of Artificial Intelligence Products>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 05-317 Design of Artificial Intelligence Products.txt"
        },
        "page_content":"<start course metadata for 05-317 Design of Artificial Intelligence Products>\nSemester: Fall 2023 (aka F23)\nCourse Name: Design of Artificial Intelligence Products\nCourse Number: 05-317\nDepartment: Human-Computer Interaction\nNumber of Units: 12\nPrerequisites: None\nInstructors: Daniel Saffer, John Zimmerman, Nikolas Martelaro, Raelin Musuraca\nRooms: 4SC 104\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 05-317 Design of Artificial Intelligence Products>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 85-213 Human information processing and artificial intelligence.txt"
        },
        "page_content":"<start course description for 85-213 Human information processing and artificial intelligence>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      }
    ],
    "model_output":"\nLorraine Levin taught the course \"Human Language for Artificial Intelligence\" in fall 2023.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who taught the course \"Human Language for Artificial Intelligence\" in fall 2023?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-624 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human Language for Artificial Intelligence\nCourse Number: 11-624\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Lorraine Levin\nRooms: WEH 5409\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-624 Human Language for Artificial Intelligence>\n-----\n<start course metadata for 11-724 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human Language for Artificial Intelligence\nCourse Number: 11-724\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Lorraine Levin\nRooms: WEH 5409\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-724 Human Language for Artificial Intelligence>\n-----\n<start course metadata for 11-324 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human Language for Artificial Intelligence\nCourse Number: 11-324\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Lorraine Levin\nRooms: WEH 5409\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-324 Human Language for Artificial Intelligence>\n-----\n<start course description for 11-324 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\n-----\n<start course description for 11-624 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\n-----\n<start course description for 11-724 Human Language for Artificial Intelligence>\nSemester: Fall 2023 (aka F23)\n-----\n<start course metadata for 85-213 Human information processing and artificial intelligence>\nSemester: Fall 2023 (aka F23)\nCourse Name: Human information processing and artificial intelligence\nCourse Number: 85-213\nDepartment: Psychology\nNumber of Units: 9\nPrerequisites: 15-122 or 15-150\nInstructors: John Anderson\nRooms: GHC 4301\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 85-213 Human information processing and artificial intelligence>\n-----\n<start course metadata for 05-617 Design of Artificial Intelligence Products>\nSemester: Fall 2023 (aka F23)\nCourse Name: Design of Artificial Intelligence Products\nCourse Number: 05-617\nDepartment: Human-Computer Interaction\nNumber of Units: 12\nPrerequisites: None\nInstructors: Daniel Saffer, John Zimmerman, Nikolas Martelaro, Raelin Musuraca\nRooms: 4SC 104\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 05-617 Design of Artificial Intelligence Products>\n-----\n<start course metadata for 05-317 Design of Artificial Intelligence Products>\nSemester: Fall 2023 (aka F23)\nCourse Name: Design of Artificial Intelligence Products\nCourse Number: 05-317\nDepartment: Human-Computer Interaction\nNumber of Units: 12\nPrerequisites: None\nInstructors: Daniel Saffer, John Zimmerman, Nikolas Martelaro, Raelin Musuraca\nRooms: 4SC 104\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 05-317 Design of Artificial Intelligence Products>\n-----\n<start course description for 85-213 Human information processing and artificial intelligence>\nSemester: Fall 2023 (aka F23)\n-----\n\n### Response ###\n\nUser: Who taught the course \"Human Language for Artificial Intelligence\" in fall 2023?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Emma Strubell, Maarten Sap",
    "index":16,
    "Q":"Who taught the \"Data Science Seminar\" in fall 2023? Give the names of the faculty members in alphabetical order by their first name, separated by comma.",
    "A":"Emma Strubell, Maarten Sap",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-631 Data Science Seminar.txt"
        },
        "page_content":"<start course metadata for 11-631 Data Science Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Seminar\nCourse Number: 11-631\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Emma Strubell, Maarten Sap\nRooms: BH A36; GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-631 Data Science Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 36-996 Statistics Departmental Seminar.txt"
        },
        "page_content":"<start course metadata for 36-996 Statistics Departmental Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Statistics Departmental Seminar\nCourse Number: 36-996\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Rebecca Nugent\nRooms: POS 153\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-996 Statistics Departmental Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 36-901 Pre-Research Seminar.txt"
        },
        "page_content":"<start course metadata for 36-901 Pre-Research Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Name: Pre-Research Seminar\nCourse Number: 36-901\nDepartment: Statistics and Data Science\nNumber of Units: 6\nPrerequisites: None\nInstructors: Larry Wasserman\nRooms: BH 232M\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-901 Pre-Research Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 36-995 Reading and Research.txt"
        },
        "page_content":"<start course metadata for 36-995 Reading and Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alessandro Rinaldo, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 36-995 Reading and Research.txt"
        },
        "page_content":"<start course metadata for 36-995 Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Arun Kuchibhotla, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Joel Greenhouse, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Rebecca Nugent, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes, Zachary Branson",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 36-996 Statistics Departmental Seminar.txt"
        },
        "page_content":"<start course metadata for 36-996 Statistics Departmental Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Name: Statistics Departmental Seminar\nCourse Number: 36-996\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Rebecca Nugent\nRooms: GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-996 Statistics Departmental Seminar>\n\n<start course description for 36-996 Statistics Departmental Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Description: None\n<\/end course description for 36-996 Statistics Departmental Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 47-843 Foundations of Data Science.txt"
        },
        "page_content":"<start course metadata for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Data Science\nCourse Number: 47-843\nDepartment: Business Administration\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ravindran Kannan\nRooms: TEP 5219\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-843 Foundations of Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 36-200 Reasoning with Data.txt"
        },
        "page_content":"<start course metadata for 36-200 Reasoning with Data>\nSemester: Fall 2023 (aka F23)\nCourse Name: Reasoning with Data\nCourse Number: 36-200\nDepartment: Statistics and Data Science\nNumber of Units: 9\nPrerequisites: None\nInstructors: Gordon Weinberg, Philipp Burckhardt, Rebecca Nugent\nRooms: MI AUD\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-200 Reasoning with Data>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 95-862 Current Topics in Privacy Seminar.txt"
        },
        "page_content":"<start course metadata for 95-862 Current Topics in Privacy Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Current Topics in Privacy Seminar\nCourse Number: 95-862\nDepartment: Information Systems:Sch of IS & Mgt\nNumber of Units: 3\nPrerequisites: None\nInstructors: Hana Habib, Norman Sadeh\nRooms: HBH 1002\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 95-862 Current Topics in Privacy Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-635 Data Science Capstone Research.txt"
        },
        "page_content":"<start course metadata for 11-635 Data Science Capstone Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Capstone Research\nCourse Number: 11-635\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg\nRooms: TEP 1403\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-635 Data Science Capstone Research>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-631 Data Science Seminar.txt"
        },
        "page_content":"<start course metadata for 11-631 Data Science Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Seminar\nCourse Number: 11-631\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Emma Strubell, Maarten Sap\nRooms: BH A36; GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-631 Data Science Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 36-996 Statistics Departmental Seminar.txt"
        },
        "page_content":"<start course metadata for 36-996 Statistics Departmental Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Statistics Departmental Seminar\nCourse Number: 36-996\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Rebecca Nugent\nRooms: POS 153\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-996 Statistics Departmental Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 36-901 Pre-Research Seminar.txt"
        },
        "page_content":"<start course metadata for 36-901 Pre-Research Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Name: Pre-Research Seminar\nCourse Number: 36-901\nDepartment: Statistics and Data Science\nNumber of Units: 6\nPrerequisites: None\nInstructors: Larry Wasserman\nRooms: BH 232M\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-901 Pre-Research Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 36-995 Reading and Research.txt"
        },
        "page_content":"<start course metadata for 36-995 Reading and Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alessandro Rinaldo, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 36-995 Reading and Research.txt"
        },
        "page_content":"<start course metadata for 36-995 Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Arun Kuchibhotla, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Joel Greenhouse, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Rebecca Nugent, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes, Zachary Branson",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 36-996 Statistics Departmental Seminar.txt"
        },
        "page_content":"<start course metadata for 36-996 Statistics Departmental Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Name: Statistics Departmental Seminar\nCourse Number: 36-996\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Rebecca Nugent\nRooms: GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-996 Statistics Departmental Seminar>\n\n<start course description for 36-996 Statistics Departmental Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Description: None\n<\/end course description for 36-996 Statistics Departmental Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 47-843 Foundations of Data Science.txt"
        },
        "page_content":"<start course metadata for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Data Science\nCourse Number: 47-843\nDepartment: Business Administration\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ravindran Kannan\nRooms: TEP 5219\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-843 Foundations of Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 36-200 Reasoning with Data.txt"
        },
        "page_content":"<start course metadata for 36-200 Reasoning with Data>\nSemester: Fall 2023 (aka F23)\nCourse Name: Reasoning with Data\nCourse Number: 36-200\nDepartment: Statistics and Data Science\nNumber of Units: 9\nPrerequisites: None\nInstructors: Gordon Weinberg, Philipp Burckhardt, Rebecca Nugent\nRooms: MI AUD\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-200 Reasoning with Data>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 95-862 Current Topics in Privacy Seminar.txt"
        },
        "page_content":"<start course metadata for 95-862 Current Topics in Privacy Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Current Topics in Privacy Seminar\nCourse Number: 95-862\nDepartment: Information Systems:Sch of IS & Mgt\nNumber of Units: 3\nPrerequisites: None\nInstructors: Hana Habib, Norman Sadeh\nRooms: HBH 1002\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 95-862 Current Topics in Privacy Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-635 Data Science Capstone Research.txt"
        },
        "page_content":"<start course metadata for 11-635 Data Science Capstone Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Capstone Research\nCourse Number: 11-635\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg\nRooms: TEP 1403\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-635 Data Science Capstone Research>",
        "type":"Document"
      }
    ],
    "model_output":"Emma Strubell, Maarten Sap.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who taught the \"Data Science Seminar\" in fall 2023? Give the names of the faculty members in alphabetical order by their first name, separated by comma.\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-631 Data Science Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Seminar\nCourse Number: 11-631\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Emma Strubell, Maarten Sap\nRooms: BH A36; GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-631 Data Science Seminar>\n-----\n<start course metadata for 36-996 Statistics Departmental Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Statistics Departmental Seminar\nCourse Number: 36-996\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Rebecca Nugent\nRooms: POS 153\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-996 Statistics Departmental Seminar>\n-----\n<start course metadata for 36-901 Pre-Research Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Name: Pre-Research Seminar\nCourse Number: 36-901\nDepartment: Statistics and Data Science\nNumber of Units: 6\nPrerequisites: None\nInstructors: Larry Wasserman\nRooms: BH 232M\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-901 Pre-Research Seminar>\n-----\n<start course metadata for 36-995 Reading and Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alessandro Rinaldo, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n-----\n<start course metadata for 36-995 Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Arun Kuchibhotla, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Joel Greenhouse, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Rebecca Nugent, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes, Zachary Branson\n-----\n<start course metadata for 36-996 Statistics Departmental Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Name: Statistics Departmental Seminar\nCourse Number: 36-996\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Rebecca Nugent\nRooms: GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-996 Statistics Departmental Seminar>\n\n<start course description for 36-996 Statistics Departmental Seminar>\nSemester: Spring 2024 (aka S24)\nCourse Description: None\n<\/end course description for 36-996 Statistics Departmental Seminar>\n-----\n<start course metadata for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Data Science\nCourse Number: 47-843\nDepartment: Business Administration\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ravindran Kannan\nRooms: TEP 5219\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-843 Foundations of Data Science>\n-----\n<start course metadata for 36-200 Reasoning with Data>\nSemester: Fall 2023 (aka F23)\nCourse Name: Reasoning with Data\nCourse Number: 36-200\nDepartment: Statistics and Data Science\nNumber of Units: 9\nPrerequisites: None\nInstructors: Gordon Weinberg, Philipp Burckhardt, Rebecca Nugent\nRooms: MI AUD\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-200 Reasoning with Data>\n-----\n<start course metadata for 95-862 Current Topics in Privacy Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: Current Topics in Privacy Seminar\nCourse Number: 95-862\nDepartment: Information Systems:Sch of IS & Mgt\nNumber of Units: 3\nPrerequisites: None\nInstructors: Hana Habib, Norman Sadeh\nRooms: HBH 1002\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 95-862 Current Topics in Privacy Seminar>\n-----\n<start course metadata for 11-635 Data Science Capstone Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Capstone Research\nCourse Number: 11-635\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg\nRooms: TEP 1403\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-635 Data Science Capstone Research>\n-----\n\n### Response ###\n\nUser: Who taught the \"Data Science Seminar\" in fall 2023? Give the names of the faculty members in alphabetical order by their first name, separated by comma.\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Carolyn Rose",
    "index":17,
    "Q":"Who taught the course called \"Foundations of Computational Data Science\" in fall 2023? Give the answer without diacritics.",
    "A":"Carolyn Rose",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 47-843 Foundations of Data Science.txt"
        },
        "page_content":"<start course metadata for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Data Science\nCourse Number: 47-843\nDepartment: Business Administration\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ravindran Kannan\nRooms: TEP 5219\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-843 Foundations of Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Annette Han, Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-672 Foundations of Computational Data Science II.txt"
        },
        "page_content":"<start course metadata for 11-672 Foundations of Computational Data Science II>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science II\nCourse Number: 11-672\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: 11-671\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-672 Foundations of Computational Data Science II>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course description for 11-637 Foundations of Computational Data Science>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-671 Foundations of Computational Data I.txt"
        },
        "page_content":"<start course metadata for 11-671 Foundations of Computational Data I>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data I\nCourse Number: 11-671\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-671 Foundations of Computational Data I>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 36-731 Foundations of Causal Inference.txt"
        },
        "page_content":"<start course metadata for 36-731 Foundations of Causal Inference>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Causal Inference\nCourse Number: 36-731\nDepartment: Statistics and Data Science\nNumber of Units: 6\nPrerequisites: None\nInstructors: Edward Kennedy\nRooms: GHC 4102\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-731 Foundations of Causal Inference>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 47-843 Foundations of Data Science.txt"
        },
        "page_content":"<start course description for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 10-607 Computational Foundations for Machine Learning.txt"
        },
        "page_content":"<start course metadata for 10-607 Computational Foundations for Machine Learning>\nSemester: Fall 2023 (aka F23)\nCourse Name: Computational Foundations for Machine Learning\nCourse Number: 10-607\nDepartment: Machine Learning\nNumber of Units: 6\nPrerequisites: None\nInstructors: Bryan Wilder\nRooms: WEH 2302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-607 Computational Foundations for Machine Learning>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 47-843 Foundations of Data Science.txt"
        },
        "page_content":"<start course metadata for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Data Science\nCourse Number: 47-843\nDepartment: Business Administration\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ravindran Kannan\nRooms: TEP 5219\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-843 Foundations of Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Annette Han, Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-672 Foundations of Computational Data Science II.txt"
        },
        "page_content":"<start course metadata for 11-672 Foundations of Computational Data Science II>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science II\nCourse Number: 11-672\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: 11-671\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-672 Foundations of Computational Data Science II>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course description for 11-637 Foundations of Computational Data Science>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-671 Foundations of Computational Data I.txt"
        },
        "page_content":"<start course metadata for 11-671 Foundations of Computational Data I>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data I\nCourse Number: 11-671\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-671 Foundations of Computational Data I>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 36-731 Foundations of Causal Inference.txt"
        },
        "page_content":"<start course metadata for 36-731 Foundations of Causal Inference>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Causal Inference\nCourse Number: 36-731\nDepartment: Statistics and Data Science\nNumber of Units: 6\nPrerequisites: None\nInstructors: Edward Kennedy\nRooms: GHC 4102\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-731 Foundations of Causal Inference>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 47-843 Foundations of Data Science.txt"
        },
        "page_content":"<start course description for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 10-607 Computational Foundations for Machine Learning.txt"
        },
        "page_content":"<start course metadata for 10-607 Computational Foundations for Machine Learning>\nSemester: Fall 2023 (aka F23)\nCourse Name: Computational Foundations for Machine Learning\nCourse Number: 10-607\nDepartment: Machine Learning\nNumber of Units: 6\nPrerequisites: None\nInstructors: Bryan Wilder\nRooms: WEH 2302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-607 Computational Foundations for Machine Learning>",
        "type":"Document"
      }
    ],
    "model_output":"\nThe instructor for the course \"Foundations of Computational Data Science\" in fall 2023 was Carolyn Rose.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who taught the course called \"Foundations of Computational Data Science\" in fall 2023? Give the answer without diacritics.\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>\n-----\n<start course metadata for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Data Science\nCourse Number: 47-843\nDepartment: Business Administration\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ravindran Kannan\nRooms: TEP 5219\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-843 Foundations of Data Science>\n-----\n<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>\n-----\n<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Annette Han, Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>\n-----\n<start course metadata for 11-672 Foundations of Computational Data Science II>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science II\nCourse Number: 11-672\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: 11-671\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-672 Foundations of Computational Data Science II>\n-----\n<start course description for 11-637 Foundations of Computational Data Science>\nSemester: Fall 2023 (aka F23)\n-----\n<start course metadata for 11-671 Foundations of Computational Data I>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data I\nCourse Number: 11-671\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-671 Foundations of Computational Data I>\n-----\n<start course metadata for 36-731 Foundations of Causal Inference>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Causal Inference\nCourse Number: 36-731\nDepartment: Statistics and Data Science\nNumber of Units: 6\nPrerequisites: None\nInstructors: Edward Kennedy\nRooms: GHC 4102\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-731 Foundations of Causal Inference>\n-----\n<start course description for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)\n-----\n<start course metadata for 10-607 Computational Foundations for Machine Learning>\nSemester: Fall 2023 (aka F23)\nCourse Name: Computational Foundations for Machine Learning\nCourse Number: 10-607\nDepartment: Machine Learning\nNumber of Units: 6\nPrerequisites: None\nInstructors: Bryan Wilder\nRooms: WEH 2302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-607 Computational Foundations for Machine Learning>\n-----\n\n### Response ###\n\nUser: Who taught the course called \"Foundations of Computational Data Science\" in fall 2023? Give the answer without diacritics.\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Chenyan Xiong, Daphne Ippolito",
    "index":18,
    "Q":"Who taught the course called \"Large Language Models Methods and Application\" in fall 2023? Give the names of the instructors in alphabetical order by first name, separated by comma.",
    "A":"Chenyan Xiong, Daphne Ippolito",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-667 Large Language Models Methods and Application.txt"
        },
        "page_content":"<start course metadata for 11-667 Large Language Models Methods and Application>\nSemester: Fall 2023 (aka F23)\nCourse Name: Large Language Models Methods and Application\nCourse Number: 11-667\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 10-601 or 10-701 or 11-685 or 11-785 or 11-711\nInstructors: Chenyan Xiong, Daphne Ippolito\nRooms: BH A51\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-667 Large Language Models Methods and Application>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-868 Large Language Model Systems.txt"
        },
        "page_content":"<start course metadata for 11-868 Large Language Model Systems>\nSemester: Spring 2024 (aka S24)\nCourse Name: Large Language Model Systems\nCourse Number: 11-868\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-785 and 11-711\nInstructors: Lei Li\nRooms: POS A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-868 Large Language Model Systems>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-667 Large Language Models Methods and Application.txt"
        },
        "page_content":"<start course description for 11-667 Large Language Models Methods and Application>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 14-825 Special Topics_ Generative AI and Large Language Model.txt"
        },
        "page_content":"<start course metadata for 14-825 Special Topics: Generative AI and Large Language Model>\nSemester: Spring 2024 (aka S24)\nCourse Name: Special Topics: Generative AI and Large Language Model\nCourse Number: 14-825\nDepartment: Information Networking Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Mohamed Farag\nRooms: B23 211; CIC 1201\nLocations: Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 14-825 Special Topics: Generative AI and Large Language Model>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 06-606 Computational Methods for Large Scale Process Design & Analysis.txt"
        },
        "page_content":"<start course metadata for 06-606 Computational Methods for Large Scale Process Design & Analysis>\nSemester: Fall 2023 (aka F23)\nCourse Name: Computational Methods for Large Scale Process Design & Analysis\nCourse Number: 06-606\nDepartment: Chemical Engineering\nNumber of Units: 9\nPrerequisites: 06-262 and 06-361\nInstructors: Lorenz Biegler\nRooms: GHC 4301\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 06-606 Computational Methods for Large Scale Process Design & Analysis>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-824 Subword Modeling.txt"
        },
        "page_content":"<start course metadata for 11-824 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-824\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-824 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-424 Subword Modeling.txt"
        },
        "page_content":"<start course metadata for 11-424 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-424\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-424 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 10-708 Probabilistic Graphical Models.txt"
        },
        "page_content":"<start course metadata for 10-708 Probabilistic Graphical Models>\nSemester: Fall 2023 (aka F23)\nCourse Name: Probabilistic Graphical Models\nCourse Number: 10-708\nDepartment: Machine Learning\nNumber of Units: 12\nPrerequisites: 10-301 or 10-315 or 10-601 or 10-701 or 10-715\nInstructors: Andrej Risteski\nRooms: POS 153\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-708 Probabilistic Graphical Models>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 98-037 Student Taught Courses (StuCo)_  Introduction to 3D Modeling and Rendering.txt"
        },
        "page_content":"<start course metadata for 98-037 Student Taught Courses (StuCo):  Introduction to 3D Modeling and Rendering>\nSemester: Fall 2023 (aka F23)\nCourse Name: Student Taught Courses (StuCo):  Introduction to 3D Modeling and Rendering\nCourse Number: 98-037\nDepartment: StuCo (Student Led Courses)\nNumber of Units: 3\nPrerequisites: None\nInstructors: Seckhen Ariel Andrade Cuellar\nRooms: CMB 2035; CMB 2052\nLocations: Doha, Qatar\n<\/end course metadata for 98-037 Student Taught Courses (StuCo):  Introduction to 3D Modeling and Rendering>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 07-070 Teaching Techniques for Computer Science.txt"
        },
        "page_content":"<start course metadata for 07-070 Teaching Techniques for Computer Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Teaching Techniques for Computer Science\nCourse Number: 07-070\nDepartment: SCS Interdisciplinary\nNumber of Units: 2\nPrerequisites: None\nInstructors: Charles Garrod, Kelly Rivers\nRooms: BH 235B\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 07-070 Teaching Techniques for Computer Science>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-667 Large Language Models Methods and Application.txt"
        },
        "page_content":"<start course metadata for 11-667 Large Language Models Methods and Application>\nSemester: Fall 2023 (aka F23)\nCourse Name: Large Language Models Methods and Application\nCourse Number: 11-667\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 10-601 or 10-701 or 11-685 or 11-785 or 11-711\nInstructors: Chenyan Xiong, Daphne Ippolito\nRooms: BH A51\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-667 Large Language Models Methods and Application>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-868 Large Language Model Systems.txt"
        },
        "page_content":"<start course metadata for 11-868 Large Language Model Systems>\nSemester: Spring 2024 (aka S24)\nCourse Name: Large Language Model Systems\nCourse Number: 11-868\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-785 and 11-711\nInstructors: Lei Li\nRooms: POS A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-868 Large Language Model Systems>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-667 Large Language Models Methods and Application.txt"
        },
        "page_content":"<start course description for 11-667 Large Language Models Methods and Application>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 14-825 Special Topics_ Generative AI and Large Language Model.txt"
        },
        "page_content":"<start course metadata for 14-825 Special Topics: Generative AI and Large Language Model>\nSemester: Spring 2024 (aka S24)\nCourse Name: Special Topics: Generative AI and Large Language Model\nCourse Number: 14-825\nDepartment: Information Networking Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Mohamed Farag\nRooms: B23 211; CIC 1201\nLocations: Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 14-825 Special Topics: Generative AI and Large Language Model>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 06-606 Computational Methods for Large Scale Process Design & Analysis.txt"
        },
        "page_content":"<start course metadata for 06-606 Computational Methods for Large Scale Process Design & Analysis>\nSemester: Fall 2023 (aka F23)\nCourse Name: Computational Methods for Large Scale Process Design & Analysis\nCourse Number: 06-606\nDepartment: Chemical Engineering\nNumber of Units: 9\nPrerequisites: 06-262 and 06-361\nInstructors: Lorenz Biegler\nRooms: GHC 4301\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 06-606 Computational Methods for Large Scale Process Design & Analysis>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-824 Subword Modeling.txt"
        },
        "page_content":"<start course metadata for 11-824 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-824\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-824 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-424 Subword Modeling.txt"
        },
        "page_content":"<start course metadata for 11-424 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-424\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-424 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 10-708 Probabilistic Graphical Models.txt"
        },
        "page_content":"<start course metadata for 10-708 Probabilistic Graphical Models>\nSemester: Fall 2023 (aka F23)\nCourse Name: Probabilistic Graphical Models\nCourse Number: 10-708\nDepartment: Machine Learning\nNumber of Units: 12\nPrerequisites: 10-301 or 10-315 or 10-601 or 10-701 or 10-715\nInstructors: Andrej Risteski\nRooms: POS 153\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-708 Probabilistic Graphical Models>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 98-037 Student Taught Courses (StuCo)_  Introduction to 3D Modeling and Rendering.txt"
        },
        "page_content":"<start course metadata for 98-037 Student Taught Courses (StuCo):  Introduction to 3D Modeling and Rendering>\nSemester: Fall 2023 (aka F23)\nCourse Name: Student Taught Courses (StuCo):  Introduction to 3D Modeling and Rendering\nCourse Number: 98-037\nDepartment: StuCo (Student Led Courses)\nNumber of Units: 3\nPrerequisites: None\nInstructors: Seckhen Ariel Andrade Cuellar\nRooms: CMB 2035; CMB 2052\nLocations: Doha, Qatar\n<\/end course metadata for 98-037 Student Taught Courses (StuCo):  Introduction to 3D Modeling and Rendering>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 07-070 Teaching Techniques for Computer Science.txt"
        },
        "page_content":"<start course metadata for 07-070 Teaching Techniques for Computer Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Teaching Techniques for Computer Science\nCourse Number: 07-070\nDepartment: SCS Interdisciplinary\nNumber of Units: 2\nPrerequisites: None\nInstructors: Charles Garrod, Kelly Rivers\nRooms: BH 235B\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 07-070 Teaching Techniques for Computer Science>",
        "type":"Document"
      }
    ],
    "model_output":"\nChenyan Xiong, Daphne Ippolito",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who taught the course called \"Large Language Models Methods and Application\" in fall 2023? Give the names of the instructors in alphabetical order by first name, separated by comma.\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-667 Large Language Models Methods and Application>\nSemester: Fall 2023 (aka F23)\nCourse Name: Large Language Models Methods and Application\nCourse Number: 11-667\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 10-601 or 10-701 or 11-685 or 11-785 or 11-711\nInstructors: Chenyan Xiong, Daphne Ippolito\nRooms: BH A51\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-667 Large Language Models Methods and Application>\n-----\n<start course metadata for 11-868 Large Language Model Systems>\nSemester: Spring 2024 (aka S24)\nCourse Name: Large Language Model Systems\nCourse Number: 11-868\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-785 and 11-711\nInstructors: Lei Li\nRooms: POS A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-868 Large Language Model Systems>\n-----\n<start course description for 11-667 Large Language Models Methods and Application>\nSemester: Fall 2023 (aka F23)\n-----\n<start course metadata for 14-825 Special Topics: Generative AI and Large Language Model>\nSemester: Spring 2024 (aka S24)\nCourse Name: Special Topics: Generative AI and Large Language Model\nCourse Number: 14-825\nDepartment: Information Networking Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Mohamed Farag\nRooms: B23 211; CIC 1201\nLocations: Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 14-825 Special Topics: Generative AI and Large Language Model>\n-----\n<start course metadata for 06-606 Computational Methods for Large Scale Process Design & Analysis>\nSemester: Fall 2023 (aka F23)\nCourse Name: Computational Methods for Large Scale Process Design & Analysis\nCourse Number: 06-606\nDepartment: Chemical Engineering\nNumber of Units: 9\nPrerequisites: 06-262 and 06-361\nInstructors: Lorenz Biegler\nRooms: GHC 4301\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 06-606 Computational Methods for Large Scale Process Design & Analysis>\n-----\n<start course metadata for 11-824 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-824\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-824 Subword Modeling>\n-----\n<start course metadata for 11-424 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-424\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-424 Subword Modeling>\n-----\n<start course metadata for 10-708 Probabilistic Graphical Models>\nSemester: Fall 2023 (aka F23)\nCourse Name: Probabilistic Graphical Models\nCourse Number: 10-708\nDepartment: Machine Learning\nNumber of Units: 12\nPrerequisites: 10-301 or 10-315 or 10-601 or 10-701 or 10-715\nInstructors: Andrej Risteski\nRooms: POS 153\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-708 Probabilistic Graphical Models>\n-----\n<start course metadata for 98-037 Student Taught Courses (StuCo):  Introduction to 3D Modeling and Rendering>\nSemester: Fall 2023 (aka F23)\nCourse Name: Student Taught Courses (StuCo):  Introduction to 3D Modeling and Rendering\nCourse Number: 98-037\nDepartment: StuCo (Student Led Courses)\nNumber of Units: 3\nPrerequisites: None\nInstructors: Seckhen Ariel Andrade Cuellar\nRooms: CMB 2035; CMB 2052\nLocations: Doha, Qatar\n<\/end course metadata for 98-037 Student Taught Courses (StuCo):  Introduction to 3D Modeling and Rendering>\n-----\n<start course metadata for 07-070 Teaching Techniques for Computer Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Teaching Techniques for Computer Science\nCourse Number: 07-070\nDepartment: SCS Interdisciplinary\nNumber of Units: 2\nPrerequisites: None\nInstructors: Charles Garrod, Kelly Rivers\nRooms: BH 235B\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 07-070 Teaching Techniques for Computer Science>\n-----\n\n### Response ###\n\nUser: Who taught the course called \"Large Language Models Methods and Application\" in fall 2023? Give the names of the instructors in alphabetical order by first name, separated by comma.\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"David Mortensen",
    "index":19,
    "Q":"Who is teaching the course called \"Subword Modeling\" in spring 2024?",
    "A":"David Mortensen",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-824 Subword Modeling.txt"
        },
        "page_content":"<start course metadata for 11-824 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-824\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-824 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-424 Subword Modeling.txt"
        },
        "page_content":"<start course metadata for 11-424 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-424\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-424 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-424 Subword Modeling.txt"
        },
        "page_content":"<start course description for 11-424 Subword Modeling>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-824 Subword Modeling.txt"
        },
        "page_content":"<start course description for 11-824 Subword Modeling>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 33-444 Introduction to Nuclear and Particle Physics.txt"
        },
        "page_content":"Semester: Spring 2024 (aka S24)\nCourse Description: Description of our understanding of nuclei, elementary particles, and quarks, with equal emphasis on the nuclear and particle aspects of sub-atomic matter. We discuss the physics of accelerators, and how particle interactions with matter lead to various kinds of detector instrumentation. Then we discuss methods for measuring sub-atomic structure, symmetries and conservation laws, and the electromagnetic, weak, and strong interactions. We examine the quark model of the mesons and baryons, as well as several models of the atomic nucleus.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 21-380 Introduction to Mathematical Modeling.txt"
        },
        "page_content":"<start course metadata for 21-380 Introduction to Mathematical Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Mathematical Modeling\nCourse Number: 21-380\nDepartment: Mathematical Sciences\nNumber of Units: 9\nPrerequisites: (21-241 or 21-242) and (21-260 or 21-261)\nInstructors: Dylan Altschuler\nRooms: WEH 8220\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 21-380 Introduction to Mathematical Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-424 Subword Modeling.txt"
        },
        "page_content":"<\/end course description for 11-424 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-824 Subword Modeling.txt"
        },
        "page_content":"<\/end course description for 11-824 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-789 Deep Generative Modeling.txt"
        },
        "page_content":"<start course metadata for 18-789 Deep Generative Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Deep Generative Modeling\nCourse Number: 18-789\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 18-661 or 18-461\nInstructors: Beidi Chen, Giulia Fanti\nRooms: HH 1107\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-789 Deep Generative Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 10-708 Probabilistic Graphical Models.txt"
        },
        "page_content":"<start course metadata for 10-708 Probabilistic Graphical Models>\nSemester: Spring 2024 (aka S24)\nCourse Name: Probabilistic Graphical Models\nCourse Number: 10-708\nDepartment: Machine Learning\nNumber of Units: 12\nPrerequisites: 10-301 or 10-315 or 10-601 or 10-701 or 10-715\nInstructors: Albert Gu, Andrej Risteski\nRooms: DH 2210\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-708 Probabilistic Graphical Models>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-824 Subword Modeling.txt"
        },
        "page_content":"<start course metadata for 11-824 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-824\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-824 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-424 Subword Modeling.txt"
        },
        "page_content":"<start course metadata for 11-424 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-424\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-424 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-424 Subword Modeling.txt"
        },
        "page_content":"<start course description for 11-424 Subword Modeling>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-824 Subword Modeling.txt"
        },
        "page_content":"<start course description for 11-824 Subword Modeling>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 33-444 Introduction to Nuclear and Particle Physics.txt"
        },
        "page_content":"Semester: Spring 2024 (aka S24)\nCourse Description: Description of our understanding of nuclei, elementary particles, and quarks, with equal emphasis on the nuclear and particle aspects of sub-atomic matter. We discuss the physics of accelerators, and how particle interactions with matter lead to various kinds of detector instrumentation. Then we discuss methods for measuring sub-atomic structure, symmetries and conservation laws, and the electromagnetic, weak, and strong interactions. We examine the quark model of the mesons and baryons, as well as several models of the atomic nucleus.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 21-380 Introduction to Mathematical Modeling.txt"
        },
        "page_content":"<start course metadata for 21-380 Introduction to Mathematical Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Mathematical Modeling\nCourse Number: 21-380\nDepartment: Mathematical Sciences\nNumber of Units: 9\nPrerequisites: (21-241 or 21-242) and (21-260 or 21-261)\nInstructors: Dylan Altschuler\nRooms: WEH 8220\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 21-380 Introduction to Mathematical Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-424 Subword Modeling.txt"
        },
        "page_content":"<\/end course description for 11-424 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-824 Subword Modeling.txt"
        },
        "page_content":"<\/end course description for 11-824 Subword Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-789 Deep Generative Modeling.txt"
        },
        "page_content":"<start course metadata for 18-789 Deep Generative Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Deep Generative Modeling\nCourse Number: 18-789\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 18-661 or 18-461\nInstructors: Beidi Chen, Giulia Fanti\nRooms: HH 1107\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-789 Deep Generative Modeling>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 10-708 Probabilistic Graphical Models.txt"
        },
        "page_content":"<start course metadata for 10-708 Probabilistic Graphical Models>\nSemester: Spring 2024 (aka S24)\nCourse Name: Probabilistic Graphical Models\nCourse Number: 10-708\nDepartment: Machine Learning\nNumber of Units: 12\nPrerequisites: 10-301 or 10-315 or 10-601 or 10-701 or 10-715\nInstructors: Albert Gu, Andrej Risteski\nRooms: DH 2210\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-708 Probabilistic Graphical Models>",
        "type":"Document"
      }
    ],
    "model_output":"\nThe instructor for the course \"Subword Modeling\" in spring 2024 is David Mortensen.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is teaching the course called \"Subword Modeling\" in spring 2024?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-824 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-824\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-824 Subword Modeling>\n-----\n<start course metadata for 11-424 Subword Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Subword Modeling\nCourse Number: 11-424\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 11-411 or 11-611 or 11-711\nInstructors: David Mortensen\nRooms: PH 100\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-424 Subword Modeling>\n-----\n<start course description for 11-424 Subword Modeling>\nSemester: Spring 2024 (aka S24)\n-----\n<start course description for 11-824 Subword Modeling>\nSemester: Spring 2024 (aka S24)\n-----\nSemester: Spring 2024 (aka S24)\nCourse Description: Description of our understanding of nuclei, elementary particles, and quarks, with equal emphasis on the nuclear and particle aspects of sub-atomic matter. We discuss the physics of accelerators, and how particle interactions with matter lead to various kinds of detector instrumentation. Then we discuss methods for measuring sub-atomic structure, symmetries and conservation laws, and the electromagnetic, weak, and strong interactions. We examine the quark model of the mesons and baryons, as well as several models of the atomic nucleus.\n-----\n<start course metadata for 21-380 Introduction to Mathematical Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Mathematical Modeling\nCourse Number: 21-380\nDepartment: Mathematical Sciences\nNumber of Units: 9\nPrerequisites: (21-241 or 21-242) and (21-260 or 21-261)\nInstructors: Dylan Altschuler\nRooms: WEH 8220\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 21-380 Introduction to Mathematical Modeling>\n-----\n<\/end course description for 11-424 Subword Modeling>\n-----\n<\/end course description for 11-824 Subword Modeling>\n-----\n<start course metadata for 18-789 Deep Generative Modeling>\nSemester: Spring 2024 (aka S24)\nCourse Name: Deep Generative Modeling\nCourse Number: 18-789\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 18-661 or 18-461\nInstructors: Beidi Chen, Giulia Fanti\nRooms: HH 1107\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-789 Deep Generative Modeling>\n-----\n<start course metadata for 10-708 Probabilistic Graphical Models>\nSemester: Spring 2024 (aka S24)\nCourse Name: Probabilistic Graphical Models\nCourse Number: 10-708\nDepartment: Machine Learning\nNumber of Units: 12\nPrerequisites: 10-301 or 10-315 or 10-601 or 10-701 or 10-715\nInstructors: Albert Gu, Andrej Risteski\nRooms: DH 2210\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-708 Probabilistic Graphical Models>\n-----\n\n### Response ###\n\nUser: Who is teaching the course called \"Subword Modeling\" in spring 2024?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Jamie Callan",
    "index":20,
    "Q":"Who is teaching the course \"Search Engines\" in spring 2024?",
    "A":"Jamie Callan",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-442 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-442 Search Engines>\nSemester: Spring 2024 (aka S24)\nCourse Name: Search Engines\nCourse Number: 11-442\nDepartment: Language Technologies Institute\nNumber of Units: 9\nPrerequisites: (15-259 or 21-325 or 36-218 or 36-225) and (15-210) and (15-213) and (21-241)\nInstructors: Jamie Callan\nRooms: GHC 4401\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-442 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-742 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-742 Search Engines>\nSemester: Spring 2024 (aka S24)\nCourse Name: Search Engines\nCourse Number: 11-742\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: GHC 4401\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-742 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-642 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-642 Search Engines>\nSemester: Spring 2024 (aka S24)\nCourse Name: Search Engines\nCourse Number: 11-642\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: GHC 4401\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-642 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-442 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-442 Search Engines>\nSemester: Fall 2023 (aka F23)\nCourse Name: Search Engines\nCourse Number: 11-442\nDepartment: Language Technologies Institute\nNumber of Units: 9\nPrerequisites: (15-259 or 21-325 or 36-218 or 36-225) and (15-210) and (15-213) and (21-241)\nInstructors: Jamie Callan\nRooms: MI 348\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-442 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-642 Search Engines.txt"
        },
        "page_content":"<start course description for 11-642 Search Engines>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-742 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-742 Search Engines>\nSemester: Fall 2023 (aka F23)\nCourse Name: Search Engines\nCourse Number: 11-742\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: MI 348\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-742 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-642 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-642 Search Engines>\nSemester: Fall 2023 (aka F23)\nCourse Name: Search Engines\nCourse Number: 11-642\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: MI 348\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-642 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-442 Search Engines.txt"
        },
        "page_content":"<start course description for 11-442 Search Engines>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-742 Search Engines.txt"
        },
        "page_content":"<start course description for 11-742 Search Engines>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-441 Machine Learning for Text and Graph-based Mining.txt"
        },
        "page_content":"Semester: Fall 2023 (aka F23)\nCourse Description: This course provides a comprehensive introduction to the theory and implementation of algorithms for organizing and searching large text collections. The first half of the course studies text search engines for enterprise and Web environments; the open-source Indri search engine is used as a working example. The second half studies text mining techniques such as clustering, categorization, and information extraction. Programming assignments give hands-on experience with document ranking algorithms, categorizing documents into browsing hierarchies, and related topics.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-442 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-442 Search Engines>\nSemester: Spring 2024 (aka S24)\nCourse Name: Search Engines\nCourse Number: 11-442\nDepartment: Language Technologies Institute\nNumber of Units: 9\nPrerequisites: (15-259 or 21-325 or 36-218 or 36-225) and (15-210) and (15-213) and (21-241)\nInstructors: Jamie Callan\nRooms: GHC 4401\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-442 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-742 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-742 Search Engines>\nSemester: Spring 2024 (aka S24)\nCourse Name: Search Engines\nCourse Number: 11-742\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: GHC 4401\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-742 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-642 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-642 Search Engines>\nSemester: Spring 2024 (aka S24)\nCourse Name: Search Engines\nCourse Number: 11-642\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: GHC 4401\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-642 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-442 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-442 Search Engines>\nSemester: Fall 2023 (aka F23)\nCourse Name: Search Engines\nCourse Number: 11-442\nDepartment: Language Technologies Institute\nNumber of Units: 9\nPrerequisites: (15-259 or 21-325 or 36-218 or 36-225) and (15-210) and (15-213) and (21-241)\nInstructors: Jamie Callan\nRooms: MI 348\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-442 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-642 Search Engines.txt"
        },
        "page_content":"<start course description for 11-642 Search Engines>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-742 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-742 Search Engines>\nSemester: Fall 2023 (aka F23)\nCourse Name: Search Engines\nCourse Number: 11-742\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: MI 348\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-742 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-642 Search Engines.txt"
        },
        "page_content":"<start course metadata for 11-642 Search Engines>\nSemester: Fall 2023 (aka F23)\nCourse Name: Search Engines\nCourse Number: 11-642\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: MI 348\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-642 Search Engines>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-442 Search Engines.txt"
        },
        "page_content":"<start course description for 11-442 Search Engines>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-742 Search Engines.txt"
        },
        "page_content":"<start course description for 11-742 Search Engines>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-441 Machine Learning for Text and Graph-based Mining.txt"
        },
        "page_content":"Semester: Fall 2023 (aka F23)\nCourse Description: This course provides a comprehensive introduction to the theory and implementation of algorithms for organizing and searching large text collections. The first half of the course studies text search engines for enterprise and Web environments; the open-source Indri search engine is used as a working example. The second half studies text mining techniques such as clustering, categorization, and information extraction. Programming assignments give hands-on experience with document ranking algorithms, categorizing documents into browsing hierarchies, and related topics.",
        "type":"Document"
      }
    ],
    "model_output":"\nJamie Callan is teaching the course \"Search Engines\" in spring 2024.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is teaching the course \"Search Engines\" in spring 2024?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-442 Search Engines>\nSemester: Spring 2024 (aka S24)\nCourse Name: Search Engines\nCourse Number: 11-442\nDepartment: Language Technologies Institute\nNumber of Units: 9\nPrerequisites: (15-259 or 21-325 or 36-218 or 36-225) and (15-210) and (15-213) and (21-241)\nInstructors: Jamie Callan\nRooms: GHC 4401\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-442 Search Engines>\n-----\n<start course metadata for 11-742 Search Engines>\nSemester: Spring 2024 (aka S24)\nCourse Name: Search Engines\nCourse Number: 11-742\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: GHC 4401\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-742 Search Engines>\n-----\n<start course metadata for 11-642 Search Engines>\nSemester: Spring 2024 (aka S24)\nCourse Name: Search Engines\nCourse Number: 11-642\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: GHC 4401\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-642 Search Engines>\n-----\n<start course metadata for 11-442 Search Engines>\nSemester: Fall 2023 (aka F23)\nCourse Name: Search Engines\nCourse Number: 11-442\nDepartment: Language Technologies Institute\nNumber of Units: 9\nPrerequisites: (15-259 or 21-325 or 36-218 or 36-225) and (15-210) and (15-213) and (21-241)\nInstructors: Jamie Callan\nRooms: MI 348\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-442 Search Engines>\n-----\n<start course description for 11-642 Search Engines>\nSemester: Spring 2024 (aka S24)\n-----\n<start course metadata for 11-742 Search Engines>\nSemester: Fall 2023 (aka F23)\nCourse Name: Search Engines\nCourse Number: 11-742\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: MI 348\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-742 Search Engines>\n-----\n<start course metadata for 11-642 Search Engines>\nSemester: Fall 2023 (aka F23)\nCourse Name: Search Engines\nCourse Number: 11-642\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: MI 348\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-642 Search Engines>\n-----\n<start course description for 11-442 Search Engines>\nSemester: Spring 2024 (aka S24)\n-----\n<start course description for 11-742 Search Engines>\nSemester: Spring 2024 (aka S24)\n-----\nSemester: Fall 2023 (aka F23)\nCourse Description: This course provides a comprehensive introduction to the theory and implementation of algorithms for organizing and searching large text collections. The first half of the course studies text search engines for enterprise and Web environments; the open-source Indri search engine is used as a working example. The second half studies text mining techniques such as clustering, categorization, and information extraction. Programming assignments give hands-on experience with document ranking algorithms, categorizing documents into browsing hierarchies, and related topics.\n-----\n\n### Response ###\n\nUser: Who is teaching the course \"Search Engines\" in spring 2024?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Shinji Watanabe",
    "index":21,
    "Q":"Who is teaching the course \"Speech Technology for Conversational AI\" in spring 2024?",
    "A":"Shinji Watanabe",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-495 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course metadata for 18-495 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Speech Technology for Conversational AI\nCourse Number: 18-495\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 15-211\nInstructors: Shinji Watanabe\nRooms: GHC 5222\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-495 Speech Technology for Conversational AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-692 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course metadata for 11-692 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Speech Technology for Conversational AI\nCourse Number: 11-692\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 15-210\nInstructors: Shinji Watanabe\nRooms: GHC 5222\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-692 Speech Technology for Conversational AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-492 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course metadata for 11-492 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Speech Technology for Conversational AI\nCourse Number: 11-492\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 15-210\nInstructors: Shinji Watanabe\nRooms: GHC 5222\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-492 Speech Technology for Conversational AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-692 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course description for 11-692 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-492 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course description for 11-492 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-495 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course description for 18-495 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-754 Project Course_ Conversational Systems.txt"
        },
        "page_content":"<start course metadata for 11-754 Project Course: Conversational Systems>\nSemester: Spring 2024 (aka S24)\nCourse Name: Project Course: Conversational Systems\nCourse Number: 11-754\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Alexander Rudnicky\nRooms: BH 154A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-754 Project Course: Conversational Systems>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-692 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<\/end course description for 11-692 Speech Technology for Conversational AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-495 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<\/end course description for 18-495 Speech Technology for Conversational AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-492 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<\/end course description for 11-492 Speech Technology for Conversational AI>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-495 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course metadata for 18-495 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Speech Technology for Conversational AI\nCourse Number: 18-495\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 15-211\nInstructors: Shinji Watanabe\nRooms: GHC 5222\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-495 Speech Technology for Conversational AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-692 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course metadata for 11-692 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Speech Technology for Conversational AI\nCourse Number: 11-692\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 15-210\nInstructors: Shinji Watanabe\nRooms: GHC 5222\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-692 Speech Technology for Conversational AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-492 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course metadata for 11-492 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Speech Technology for Conversational AI\nCourse Number: 11-492\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 15-210\nInstructors: Shinji Watanabe\nRooms: GHC 5222\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-492 Speech Technology for Conversational AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-692 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course description for 11-692 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-492 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course description for 11-492 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-495 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<start course description for 18-495 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-754 Project Course_ Conversational Systems.txt"
        },
        "page_content":"<start course metadata for 11-754 Project Course: Conversational Systems>\nSemester: Spring 2024 (aka S24)\nCourse Name: Project Course: Conversational Systems\nCourse Number: 11-754\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Alexander Rudnicky\nRooms: BH 154A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-754 Project Course: Conversational Systems>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-692 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<\/end course description for 11-692 Speech Technology for Conversational AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-495 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<\/end course description for 18-495 Speech Technology for Conversational AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-492 Speech Technology for Conversational AI.txt"
        },
        "page_content":"<\/end course description for 11-492 Speech Technology for Conversational AI>",
        "type":"Document"
      }
    ],
    "model_output":"\nShinji Watanabe is teaching the course \"Speech Technology for Conversational AI\" in spring 2024.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is teaching the course \"Speech Technology for Conversational AI\" in spring 2024?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 18-495 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Speech Technology for Conversational AI\nCourse Number: 18-495\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: 15-211\nInstructors: Shinji Watanabe\nRooms: GHC 5222\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-495 Speech Technology for Conversational AI>\n-----\n<start course metadata for 11-692 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Speech Technology for Conversational AI\nCourse Number: 11-692\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 15-210\nInstructors: Shinji Watanabe\nRooms: GHC 5222\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-692 Speech Technology for Conversational AI>\n-----\n<start course metadata for 11-492 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Speech Technology for Conversational AI\nCourse Number: 11-492\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 15-210\nInstructors: Shinji Watanabe\nRooms: GHC 5222\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-492 Speech Technology for Conversational AI>\n-----\n<start course description for 11-692 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\n-----\n<start course description for 11-492 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\n-----\n<start course description for 18-495 Speech Technology for Conversational AI>\nSemester: Spring 2024 (aka S24)\n-----\n<start course metadata for 11-754 Project Course: Conversational Systems>\nSemester: Spring 2024 (aka S24)\nCourse Name: Project Course: Conversational Systems\nCourse Number: 11-754\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Alexander Rudnicky\nRooms: BH 154A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-754 Project Course: Conversational Systems>\n-----\n<\/end course description for 11-692 Speech Technology for Conversational AI>\n-----\n<\/end course description for 18-495 Speech Technology for Conversational AI>\n-----\n<\/end course description for 11-492 Speech Technology for Conversational AI>\n-----\n\n### Response ###\n\nUser: Who is teaching the course \"Speech Technology for Conversational AI\" in spring 2024?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Daniel Fried, Sean Welleck",
    "index":22,
    "Q":"Who is teaching the course \"Neural Code Generation\" in spring 2024? Give the instructor names in alphabetical order by first name, separated by comma.",
    "A":"Daniel Fried, Sean Welleck",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-891 Neural Code Generation.txt"
        },
        "page_content":"<start course metadata for 11-891 Neural Code Generation>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Code Generation\nCourse Number: 11-891\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Daniel Fried, Sean Welleck\nRooms: WEH 4625\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-891 Neural Code Generation>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 10-733 Representation and Generation in Neuroscience and AI.txt"
        },
        "page_content":"<start course metadata for 10-733 Representation and Generation in Neuroscience and AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Representation and Generation in Neuroscience and AI\nCourse Number: 10-733\nDepartment: Machine Learning\nNumber of Units: 12\nPrerequisites: 10-301 or 10-315 or 10-601 or 10-701 or 10-715 or 10-707 or 10-417 or 10-617 or 10-414 or 10-714\nInstructors: Leila Wehbe\nRooms: GHC 4102\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-733 Representation and Generation in Neuroscience and AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-891 Neural Code Generation.txt"
        },
        "page_content":"<start course description for 11-891 Neural Code Generation>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 15-386 Neural Computation.txt"
        },
        "page_content":"<start course metadata for 15-386 Neural Computation>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Computation\nCourse Number: 15-386\nDepartment: Computer Science\nNumber of Units: 9\nPrerequisites: (15-112 or 15-122) and (21-122)\nInstructors: Tai-Sing Lee\nRooms: HH B131\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-386 Neural Computation>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 90-739 Systems Synthesis I.txt"
        },
        "page_content":"<start course metadata for 90-739 Systems Synthesis I>\nSemester: Spring 2024 (aka S24)\nCourse Name: Systems Synthesis I\nCourse Number: 90-739\nDepartment: Public Policy & Mgt:Sch of Pub Pol & Mgt\nNumber of Units: 12\nPrerequisites: None\nInstructors: Avinash Collis, Beibei Li, Brett Crawford, Cole Gessner, David Lassman, Denise Lawson, Devon Halley, Edson Severnini, Eli Ben-Michael, Instructor TBA, James Riel, Jonathan Caulkins, Kristen Kurland, LaToya Robinson, Laura Zwicker, Lee Branstetter, Mariana Escallon Barrios, Michael Smith, Silvia Borzutzky, William Gogolak, William Peduto\nRooms: DNM DNM; HBH 1208; HBH 2011",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 15-686 Neural Computation.txt"
        },
        "page_content":"<start course metadata for 15-686 Neural Computation>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Computation\nCourse Number: 15-686\nDepartment: Computer Science\nNumber of Units: 12\nPrerequisites: None\nInstructors: Tai-Sing Lee\nRooms: HH B131\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-686 Neural Computation>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 03-365 Neural Correlates of Learning and Memory.txt"
        },
        "page_content":"<start course metadata for 03-365 Neural Correlates of Learning and Memory>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Correlates of Learning and Memory\nCourse Number: 03-365\nDepartment: Biological Sciences\nNumber of Units: 9\nPrerequisites: 03-161 or 85-219 or 03-240 or 03-320\nInstructors: Natalie McGuier\nRooms: DH 1211\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 03-365 Neural Correlates of Learning and Memory>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-698 Neural Signal Processing.txt"
        },
        "page_content":"<start course metadata for 18-698 Neural Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Signal Processing\nCourse Number: 18-698\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Byron Yu\nRooms: POS A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-698 Neural Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 38-616 Neural Networks & Deep Learning in Science.txt"
        },
        "page_content":"<start course metadata for 38-616 Neural Networks & Deep Learning in Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Networks & Deep Learning in Science\nCourse Number: 38-616\nDepartment: MCS Interdisciplinary\nNumber of Units: 12\nPrerequisites: 38-615\nInstructors: Olexandr Isayev\nRooms: 3SC 110\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 38-616 Neural Networks & Deep Learning in Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 42-632 Neural Signal Processing.txt"
        },
        "page_content":"<start course metadata for 42-632 Neural Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Signal Processing\nCourse Number: 42-632\nDepartment: Biomedical Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Byron Yu\nRooms: POS A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 42-632 Neural Signal Processing>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-891 Neural Code Generation.txt"
        },
        "page_content":"<start course metadata for 11-891 Neural Code Generation>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Code Generation\nCourse Number: 11-891\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Daniel Fried, Sean Welleck\nRooms: WEH 4625\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-891 Neural Code Generation>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 10-733 Representation and Generation in Neuroscience and AI.txt"
        },
        "page_content":"<start course metadata for 10-733 Representation and Generation in Neuroscience and AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Representation and Generation in Neuroscience and AI\nCourse Number: 10-733\nDepartment: Machine Learning\nNumber of Units: 12\nPrerequisites: 10-301 or 10-315 or 10-601 or 10-701 or 10-715 or 10-707 or 10-417 or 10-617 or 10-414 or 10-714\nInstructors: Leila Wehbe\nRooms: GHC 4102\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-733 Representation and Generation in Neuroscience and AI>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-891 Neural Code Generation.txt"
        },
        "page_content":"<start course description for 11-891 Neural Code Generation>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 15-386 Neural Computation.txt"
        },
        "page_content":"<start course metadata for 15-386 Neural Computation>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Computation\nCourse Number: 15-386\nDepartment: Computer Science\nNumber of Units: 9\nPrerequisites: (15-112 or 15-122) and (21-122)\nInstructors: Tai-Sing Lee\nRooms: HH B131\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-386 Neural Computation>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 90-739 Systems Synthesis I.txt"
        },
        "page_content":"<start course metadata for 90-739 Systems Synthesis I>\nSemester: Spring 2024 (aka S24)\nCourse Name: Systems Synthesis I\nCourse Number: 90-739\nDepartment: Public Policy & Mgt:Sch of Pub Pol & Mgt\nNumber of Units: 12\nPrerequisites: None\nInstructors: Avinash Collis, Beibei Li, Brett Crawford, Cole Gessner, David Lassman, Denise Lawson, Devon Halley, Edson Severnini, Eli Ben-Michael, Instructor TBA, James Riel, Jonathan Caulkins, Kristen Kurland, LaToya Robinson, Laura Zwicker, Lee Branstetter, Mariana Escallon Barrios, Michael Smith, Silvia Borzutzky, William Gogolak, William Peduto\nRooms: DNM DNM; HBH 1208; HBH 2011",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 15-686 Neural Computation.txt"
        },
        "page_content":"<start course metadata for 15-686 Neural Computation>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Computation\nCourse Number: 15-686\nDepartment: Computer Science\nNumber of Units: 12\nPrerequisites: None\nInstructors: Tai-Sing Lee\nRooms: HH B131\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-686 Neural Computation>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 03-365 Neural Correlates of Learning and Memory.txt"
        },
        "page_content":"<start course metadata for 03-365 Neural Correlates of Learning and Memory>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Correlates of Learning and Memory\nCourse Number: 03-365\nDepartment: Biological Sciences\nNumber of Units: 9\nPrerequisites: 03-161 or 85-219 or 03-240 or 03-320\nInstructors: Natalie McGuier\nRooms: DH 1211\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 03-365 Neural Correlates of Learning and Memory>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 18-698 Neural Signal Processing.txt"
        },
        "page_content":"<start course metadata for 18-698 Neural Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Signal Processing\nCourse Number: 18-698\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Byron Yu\nRooms: POS A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-698 Neural Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 38-616 Neural Networks & Deep Learning in Science.txt"
        },
        "page_content":"<start course metadata for 38-616 Neural Networks & Deep Learning in Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Networks & Deep Learning in Science\nCourse Number: 38-616\nDepartment: MCS Interdisciplinary\nNumber of Units: 12\nPrerequisites: 38-615\nInstructors: Olexandr Isayev\nRooms: 3SC 110\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 38-616 Neural Networks & Deep Learning in Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 42-632 Neural Signal Processing.txt"
        },
        "page_content":"<start course metadata for 42-632 Neural Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Signal Processing\nCourse Number: 42-632\nDepartment: Biomedical Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Byron Yu\nRooms: POS A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 42-632 Neural Signal Processing>",
        "type":"Document"
      }
    ],
    "model_output":"\nThe instructors teaching the course \"Neural Code Generation\" in spring 2024 are Daniel Fried and Sean Welleck. Therefore, the answer to the question is \"Daniel Fried, Sean Welleck\".",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is teaching the course \"Neural Code Generation\" in spring 2024? Give the instructor names in alphabetical order by first name, separated by comma.\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-891 Neural Code Generation>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Code Generation\nCourse Number: 11-891\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Daniel Fried, Sean Welleck\nRooms: WEH 4625\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-891 Neural Code Generation>\n-----\n<start course metadata for 10-733 Representation and Generation in Neuroscience and AI>\nSemester: Spring 2024 (aka S24)\nCourse Name: Representation and Generation in Neuroscience and AI\nCourse Number: 10-733\nDepartment: Machine Learning\nNumber of Units: 12\nPrerequisites: 10-301 or 10-315 or 10-601 or 10-701 or 10-715 or 10-707 or 10-417 or 10-617 or 10-414 or 10-714\nInstructors: Leila Wehbe\nRooms: GHC 4102\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 10-733 Representation and Generation in Neuroscience and AI>\n-----\n<start course description for 11-891 Neural Code Generation>\nSemester: Spring 2024 (aka S24)\n-----\n<start course metadata for 15-386 Neural Computation>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Computation\nCourse Number: 15-386\nDepartment: Computer Science\nNumber of Units: 9\nPrerequisites: (15-112 or 15-122) and (21-122)\nInstructors: Tai-Sing Lee\nRooms: HH B131\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-386 Neural Computation>\n-----\n<start course metadata for 90-739 Systems Synthesis I>\nSemester: Spring 2024 (aka S24)\nCourse Name: Systems Synthesis I\nCourse Number: 90-739\nDepartment: Public Policy & Mgt:Sch of Pub Pol & Mgt\nNumber of Units: 12\nPrerequisites: None\nInstructors: Avinash Collis, Beibei Li, Brett Crawford, Cole Gessner, David Lassman, Denise Lawson, Devon Halley, Edson Severnini, Eli Ben-Michael, Instructor TBA, James Riel, Jonathan Caulkins, Kristen Kurland, LaToya Robinson, Laura Zwicker, Lee Branstetter, Mariana Escallon Barrios, Michael Smith, Silvia Borzutzky, William Gogolak, William Peduto\nRooms: DNM DNM; HBH 1208; HBH 2011\n-----\n<start course metadata for 15-686 Neural Computation>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Computation\nCourse Number: 15-686\nDepartment: Computer Science\nNumber of Units: 12\nPrerequisites: None\nInstructors: Tai-Sing Lee\nRooms: HH B131\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-686 Neural Computation>\n-----\n<start course metadata for 03-365 Neural Correlates of Learning and Memory>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Correlates of Learning and Memory\nCourse Number: 03-365\nDepartment: Biological Sciences\nNumber of Units: 9\nPrerequisites: 03-161 or 85-219 or 03-240 or 03-320\nInstructors: Natalie McGuier\nRooms: DH 1211\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 03-365 Neural Correlates of Learning and Memory>\n-----\n<start course metadata for 18-698 Neural Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Signal Processing\nCourse Number: 18-698\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Byron Yu\nRooms: POS A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-698 Neural Signal Processing>\n-----\n<start course metadata for 38-616 Neural Networks & Deep Learning in Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Networks & Deep Learning in Science\nCourse Number: 38-616\nDepartment: MCS Interdisciplinary\nNumber of Units: 12\nPrerequisites: 38-615\nInstructors: Olexandr Isayev\nRooms: 3SC 110\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 38-616 Neural Networks & Deep Learning in Science>\n-----\n<start course metadata for 42-632 Neural Signal Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Neural Signal Processing\nCourse Number: 42-632\nDepartment: Biomedical Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Byron Yu\nRooms: POS A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 42-632 Neural Signal Processing>\n-----\n\n### Response ###\n\nUser: Who is teaching the course \"Neural Code Generation\" in spring 2024? Give the instructor names in alphabetical order by first name, separated by comma.\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Eric Nyberg, Teruko Mitamura",
    "index":23,
    "Q":"Who is teaching the course \"Question Answering\" in spring 2024? Give the instructor names in alphabetical order by first name, separated by comma.",
    "A":"Eric Nyberg, Teruko Mitamura",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-797 Question Answering.txt"
        },
        "page_content":"<start course metadata for 11-797 Question Answering>\nSemester: Spring 2024 (aka S24)\nCourse Name: Question Answering\nCourse Number: 11-797\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg, Teruko Mitamura\nRooms: GHC 4102\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-797 Question Answering>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-697 Introduction to Question Answering.txt"
        },
        "page_content":"<start course metadata for 11-697 Introduction to Question Answering>\nSemester: Fall 2023 (aka F23)\nCourse Name: Introduction to Question Answering\nCourse Number: 11-697\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg, Teruko Mitamura\nRooms: PH A18A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-697 Introduction to Question Answering>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-697 Introduction to Question Answering.txt"
        },
        "page_content":"<start course description for 11-697 Introduction to Question Answering>\nSemester: Fall 2023 (aka F23)\nCourse Description: The Introduction to Question Answering course provides a chance for hands-on, in-depth exploration of core algorithmic approaches to question answering (QA) for students who haven't worked on a QA system before.\n<\/end course description for 11-697 Introduction to Question Answering>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 21-599 Undergraduate Reading and Research.txt"
        },
        "page_content":"<start course metadata for 21-599 Undergraduate Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Undergraduate Reading and Research\nCourse Number: 21-599\nDepartment: Mathematical Sciences\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Alan Frieze, Amzi Jeffs, Andrew Newman, Aristotelis Panagiotopoulos, Boris Bukh, David Offner, Elisa Bellah, Ernest Schimmerling, Evan O'Dorney, Giovanni Leoni, Ian Tice, Instructor TBA, Irina Gheorghiciuc, James Cummings, John Mackey, Richard Statman, Robert Pego, Timothy Flaherty, Tomasz Tkocz, William Hrusa\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 36-995 Reading and Research.txt"
        },
        "page_content":"<start course metadata for 36-995 Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Arun Kuchibhotla, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Joel Greenhouse, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Rebecca Nugent, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes, Zachary Branson",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 76-101 Interpretation and Argument.txt"
        },
        "page_content":"<start course metadata for 76-101 Interpretation and Argument>\nSemester: Spring 2024 (aka S24)\nCourse Name: Interpretation and Argument\nCourse Number: 76-101\nDepartment: English\nNumber of Units: 9\nPrerequisites: None\nInstructors: Andrea Comiskey, Chad Szalkowski-Ference, Jamie Watson, Janine Carlock, Jeffrey Squires, Julia Salehzadeh, Julie Pal-Agrawal, Kat Myers, Maria Pia Gomez Laich, Natalia Gatti Dura, Nicole Tanquary, Peter Mayshle, Rochel Gasson, Seth Strickland, Silvia Pessoa, Suzanne Meyer, Thomas Mitchell, Tina Cafasso",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 57-890 Practice Teaching (Secondary).txt"
        },
        "page_content":"<start course metadata for 57-890 Practice Teaching (Secondary)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Practice Teaching (Secondary)\nCourse Number: 57-890\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Adrianne Kelly, Paul Gerlach, Robert Dell\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-890 Practice Teaching (Secondary)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 57-489 Practice Teaching (Elementary).txt"
        },
        "page_content":"<start course metadata for 57-489 Practice Teaching (Elementary)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Practice Teaching (Elementary)\nCourse Number: 57-489\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Adrianne Kelly, Paul Gerlach, Robert Dell, Susan Raponi\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-489 Practice Teaching (Elementary)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 79-800 Readings.txt"
        },
        "page_content":"<start course metadata for 79-800 Readings>\nSemester: Spring 2024 (aka S24)\nCourse Name: Readings\nCourse Number: 79-800\nDepartment: History\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Allyson Creasman, Benno Weiner, Carl Kubler, Christopher Phillips, Donna Harsch, Edda Fields-Black, Edmund Russell, Instructor TBA, Jay Aronson, Joe Trotter, Joel Tarr, John Soluri, Lisa Tetrault, Nico Slate, Paul Eiss, Ricky Law, Scott Sandage, Steven Schlossman, Wendy Goldman\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 79-800 Readings>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 57-889 Practice Teaching (Elementary).txt"
        },
        "page_content":"<start course metadata for 57-889 Practice Teaching (Elementary)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Practice Teaching (Elementary)\nCourse Number: 57-889\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Adrianne Kelly, Paul Gerlach, Robert Dell\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-889 Practice Teaching (Elementary)>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-797 Question Answering.txt"
        },
        "page_content":"<start course metadata for 11-797 Question Answering>\nSemester: Spring 2024 (aka S24)\nCourse Name: Question Answering\nCourse Number: 11-797\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg, Teruko Mitamura\nRooms: GHC 4102\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-797 Question Answering>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-697 Introduction to Question Answering.txt"
        },
        "page_content":"<start course metadata for 11-697 Introduction to Question Answering>\nSemester: Fall 2023 (aka F23)\nCourse Name: Introduction to Question Answering\nCourse Number: 11-697\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg, Teruko Mitamura\nRooms: PH A18A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-697 Introduction to Question Answering>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-697 Introduction to Question Answering.txt"
        },
        "page_content":"<start course description for 11-697 Introduction to Question Answering>\nSemester: Fall 2023 (aka F23)\nCourse Description: The Introduction to Question Answering course provides a chance for hands-on, in-depth exploration of core algorithmic approaches to question answering (QA) for students who haven't worked on a QA system before.\n<\/end course description for 11-697 Introduction to Question Answering>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 21-599 Undergraduate Reading and Research.txt"
        },
        "page_content":"<start course metadata for 21-599 Undergraduate Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Undergraduate Reading and Research\nCourse Number: 21-599\nDepartment: Mathematical Sciences\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Alan Frieze, Amzi Jeffs, Andrew Newman, Aristotelis Panagiotopoulos, Boris Bukh, David Offner, Elisa Bellah, Ernest Schimmerling, Evan O'Dorney, Giovanni Leoni, Ian Tice, Instructor TBA, Irina Gheorghiciuc, James Cummings, John Mackey, Richard Statman, Robert Pego, Timothy Flaherty, Tomasz Tkocz, William Hrusa\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 36-995 Reading and Research.txt"
        },
        "page_content":"<start course metadata for 36-995 Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Arun Kuchibhotla, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Joel Greenhouse, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Rebecca Nugent, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes, Zachary Branson",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 76-101 Interpretation and Argument.txt"
        },
        "page_content":"<start course metadata for 76-101 Interpretation and Argument>\nSemester: Spring 2024 (aka S24)\nCourse Name: Interpretation and Argument\nCourse Number: 76-101\nDepartment: English\nNumber of Units: 9\nPrerequisites: None\nInstructors: Andrea Comiskey, Chad Szalkowski-Ference, Jamie Watson, Janine Carlock, Jeffrey Squires, Julia Salehzadeh, Julie Pal-Agrawal, Kat Myers, Maria Pia Gomez Laich, Natalia Gatti Dura, Nicole Tanquary, Peter Mayshle, Rochel Gasson, Seth Strickland, Silvia Pessoa, Suzanne Meyer, Thomas Mitchell, Tina Cafasso",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 57-890 Practice Teaching (Secondary).txt"
        },
        "page_content":"<start course metadata for 57-890 Practice Teaching (Secondary)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Practice Teaching (Secondary)\nCourse Number: 57-890\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Adrianne Kelly, Paul Gerlach, Robert Dell\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-890 Practice Teaching (Secondary)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 57-489 Practice Teaching (Elementary).txt"
        },
        "page_content":"<start course metadata for 57-489 Practice Teaching (Elementary)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Practice Teaching (Elementary)\nCourse Number: 57-489\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Adrianne Kelly, Paul Gerlach, Robert Dell, Susan Raponi\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-489 Practice Teaching (Elementary)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 79-800 Readings.txt"
        },
        "page_content":"<start course metadata for 79-800 Readings>\nSemester: Spring 2024 (aka S24)\nCourse Name: Readings\nCourse Number: 79-800\nDepartment: History\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Allyson Creasman, Benno Weiner, Carl Kubler, Christopher Phillips, Donna Harsch, Edda Fields-Black, Edmund Russell, Instructor TBA, Jay Aronson, Joe Trotter, Joel Tarr, John Soluri, Lisa Tetrault, Nico Slate, Paul Eiss, Ricky Law, Scott Sandage, Steven Schlossman, Wendy Goldman\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 79-800 Readings>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 57-889 Practice Teaching (Elementary).txt"
        },
        "page_content":"<start course metadata for 57-889 Practice Teaching (Elementary)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Practice Teaching (Elementary)\nCourse Number: 57-889\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Adrianne Kelly, Paul Gerlach, Robert Dell\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-889 Practice Teaching (Elementary)>",
        "type":"Document"
      }
    ],
    "model_output":"Eric Nyberg, Teruko Mitamura",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is teaching the course \"Question Answering\" in spring 2024? Give the instructor names in alphabetical order by first name, separated by comma.\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-797 Question Answering>\nSemester: Spring 2024 (aka S24)\nCourse Name: Question Answering\nCourse Number: 11-797\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg, Teruko Mitamura\nRooms: GHC 4102\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-797 Question Answering>\n-----\n<start course metadata for 11-697 Introduction to Question Answering>\nSemester: Fall 2023 (aka F23)\nCourse Name: Introduction to Question Answering\nCourse Number: 11-697\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg, Teruko Mitamura\nRooms: PH A18A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-697 Introduction to Question Answering>\n-----\n<start course description for 11-697 Introduction to Question Answering>\nSemester: Fall 2023 (aka F23)\nCourse Description: The Introduction to Question Answering course provides a chance for hands-on, in-depth exploration of core algorithmic approaches to question answering (QA) for students who haven't worked on a QA system before.\n<\/end course description for 11-697 Introduction to Question Answering>\n-----\n<start course metadata for 21-599 Undergraduate Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Undergraduate Reading and Research\nCourse Number: 21-599\nDepartment: Mathematical Sciences\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Alan Frieze, Amzi Jeffs, Andrew Newman, Aristotelis Panagiotopoulos, Boris Bukh, David Offner, Elisa Bellah, Ernest Schimmerling, Evan O'Dorney, Giovanni Leoni, Ian Tice, Instructor TBA, Irina Gheorghiciuc, James Cummings, John Mackey, Richard Statman, Robert Pego, Timothy Flaherty, Tomasz Tkocz, William Hrusa\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n-----\n<start course metadata for 36-995 Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Arun Kuchibhotla, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Joel Greenhouse, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Rebecca Nugent, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes, Zachary Branson\n-----\n<start course metadata for 76-101 Interpretation and Argument>\nSemester: Spring 2024 (aka S24)\nCourse Name: Interpretation and Argument\nCourse Number: 76-101\nDepartment: English\nNumber of Units: 9\nPrerequisites: None\nInstructors: Andrea Comiskey, Chad Szalkowski-Ference, Jamie Watson, Janine Carlock, Jeffrey Squires, Julia Salehzadeh, Julie Pal-Agrawal, Kat Myers, Maria Pia Gomez Laich, Natalia Gatti Dura, Nicole Tanquary, Peter Mayshle, Rochel Gasson, Seth Strickland, Silvia Pessoa, Suzanne Meyer, Thomas Mitchell, Tina Cafasso\n-----\n<start course metadata for 57-890 Practice Teaching (Secondary)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Practice Teaching (Secondary)\nCourse Number: 57-890\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Adrianne Kelly, Paul Gerlach, Robert Dell\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-890 Practice Teaching (Secondary)>\n-----\n<start course metadata for 57-489 Practice Teaching (Elementary)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Practice Teaching (Elementary)\nCourse Number: 57-489\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Adrianne Kelly, Paul Gerlach, Robert Dell, Susan Raponi\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-489 Practice Teaching (Elementary)>\n-----\n<start course metadata for 79-800 Readings>\nSemester: Spring 2024 (aka S24)\nCourse Name: Readings\nCourse Number: 79-800\nDepartment: History\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Allyson Creasman, Benno Weiner, Carl Kubler, Christopher Phillips, Donna Harsch, Edda Fields-Black, Edmund Russell, Instructor TBA, Jay Aronson, Joe Trotter, Joel Tarr, John Soluri, Lisa Tetrault, Nico Slate, Paul Eiss, Ricky Law, Scott Sandage, Steven Schlossman, Wendy Goldman\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 79-800 Readings>\n-----\n<start course metadata for 57-889 Practice Teaching (Elementary)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Practice Teaching (Elementary)\nCourse Number: 57-889\nDepartment: Music\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Adrianne Kelly, Paul Gerlach, Robert Dell\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 57-889 Practice Teaching (Elementary)>\n-----\n\n### Response ###\n\nUser: Who is teaching the course \"Question Answering\" in spring 2024? Give the instructor names in alphabetical order by first name, separated by comma.\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Fernando Diaz",
    "index":24,
    "Q":"Who is teaching the course \"Quantitative Evaluation of Language Technologies\" in spring 2024?",
    "A":"Fernando Diaz",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-801 Quantitative evaluation of language technologies.txt"
        },
        "page_content":"<start course metadata for 11-801 Quantitative evaluation of language technologies>\nSemester: Spring 2024 (aka S24)\nCourse Name: Quantitative evaluation of language technologies\nCourse Number: 11-801\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Fernando Diaz\nRooms: WEH 5421\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-801 Quantitative evaluation of language technologies>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-801 Quantitative evaluation of language technologies.txt"
        },
        "page_content":"<start course description for 11-801 Quantitative evaluation of language technologies>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-801 Quantitative evaluation of language technologies.txt"
        },
        "page_content":"<\/end course description for 11-801 Quantitative evaluation of language technologies>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-910 Directed Research.txt"
        },
        "page_content":"<start course metadata for 11-910 Directed Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Directed Research\nCourse Number: 11-910\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan, Robert Frederking\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-910 Directed Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-930 Dissertation Research.txt"
        },
        "page_content":"<start course metadata for 11-930 Dissertation Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Dissertation Research\nCourse Number: 11-930\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-930 Dissertation Research>\n\n<start course description for 11-930 Dissertation Research>\nSemester: Spring 2024 (aka S24)\nCourse Description: This course number is intended for PhD dissertation research after acceptance of a student's PhD thesis proposal.\n<\/end course description for 11-930 Dissertation Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 19-702 Quantitative Methods for Policy Analysis.txt"
        },
        "page_content":"<start course metadata for 19-702 Quantitative Methods for Policy Analysis>\nSemester: Spring 2024 (aka S24)\nCourse Name: Quantitative Methods for Policy Analysis\nCourse Number: 19-702\nDepartment: Engineering & Public Policy\nNumber of Units: 12\nPrerequisites: None\nInstructors: Nicolas Christin\nRooms: BH 237B; BH 255A\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 19-702 Quantitative Methods for Policy Analysis>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 19-702 Quantitative Methods for Policy Analysis.txt"
        },
        "page_content":"<start course description for 19-702 Quantitative Methods for Policy Analysis>\nSemester: Spring 2024 (aka S24)\nCourse Description: Economic framework for identifying and analyzing investment and operation options facing agencies and firms, (both in theory and in practice); economic efficiency, utilization, pricing, and investment; and multi-objective evaluation.\n<\/end course description for 19-702 Quantitative Methods for Policy Analysis>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-411 Natural Language Processing.txt"
        },
        "page_content":"<start course metadata for 11-411 Natural Language Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Natural Language Processing\nCourse Number: 11-411\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 15-122\nInstructors: David Mortensen, Emma Strubell, Kemal Oflazer\nRooms: CMB 2052; POS A35\nLocations: Doha, Qatar; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-411 Natural Language Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-485 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-485 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-485\nDepartment: Language Technologies Institute\nNumber of Units: 9\nPrerequisites: (15-112) and (21-120) and (21-241)\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-485 Introduction to Deep Learning>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 82-881 Research Methods in Second Language Acquisition.txt"
        },
        "page_content":"<start course description for 82-881 Research Methods in Second Language Acquisition>\nSemester: Spring 2024 (aka S24)\nCourse Description: The course introduces students to research methodology as it applies to  language learning and language teaching. It provides an examination of  different approaches currently used in Second Language Acquisition (SLA)  research ranging from experimental studies to survey investigations. The  goal is to develop an ability to critically evaluate, design and implement  sound SLA research.\n<\/end course description for 82-881 Research Methods in Second Language Acquisition>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-801 Quantitative evaluation of language technologies.txt"
        },
        "page_content":"<start course metadata for 11-801 Quantitative evaluation of language technologies>\nSemester: Spring 2024 (aka S24)\nCourse Name: Quantitative evaluation of language technologies\nCourse Number: 11-801\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Fernando Diaz\nRooms: WEH 5421\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-801 Quantitative evaluation of language technologies>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-801 Quantitative evaluation of language technologies.txt"
        },
        "page_content":"<start course description for 11-801 Quantitative evaluation of language technologies>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-801 Quantitative evaluation of language technologies.txt"
        },
        "page_content":"<\/end course description for 11-801 Quantitative evaluation of language technologies>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-910 Directed Research.txt"
        },
        "page_content":"<start course metadata for 11-910 Directed Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Directed Research\nCourse Number: 11-910\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan, Robert Frederking\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-910 Directed Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-930 Dissertation Research.txt"
        },
        "page_content":"<start course metadata for 11-930 Dissertation Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Dissertation Research\nCourse Number: 11-930\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-930 Dissertation Research>\n\n<start course description for 11-930 Dissertation Research>\nSemester: Spring 2024 (aka S24)\nCourse Description: This course number is intended for PhD dissertation research after acceptance of a student's PhD thesis proposal.\n<\/end course description for 11-930 Dissertation Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 19-702 Quantitative Methods for Policy Analysis.txt"
        },
        "page_content":"<start course metadata for 19-702 Quantitative Methods for Policy Analysis>\nSemester: Spring 2024 (aka S24)\nCourse Name: Quantitative Methods for Policy Analysis\nCourse Number: 19-702\nDepartment: Engineering & Public Policy\nNumber of Units: 12\nPrerequisites: None\nInstructors: Nicolas Christin\nRooms: BH 237B; BH 255A\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 19-702 Quantitative Methods for Policy Analysis>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 19-702 Quantitative Methods for Policy Analysis.txt"
        },
        "page_content":"<start course description for 19-702 Quantitative Methods for Policy Analysis>\nSemester: Spring 2024 (aka S24)\nCourse Description: Economic framework for identifying and analyzing investment and operation options facing agencies and firms, (both in theory and in practice); economic efficiency, utilization, pricing, and investment; and multi-objective evaluation.\n<\/end course description for 19-702 Quantitative Methods for Policy Analysis>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-411 Natural Language Processing.txt"
        },
        "page_content":"<start course metadata for 11-411 Natural Language Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Natural Language Processing\nCourse Number: 11-411\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 15-122\nInstructors: David Mortensen, Emma Strubell, Kemal Oflazer\nRooms: CMB 2052; POS A35\nLocations: Doha, Qatar; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-411 Natural Language Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-485 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-485 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-485\nDepartment: Language Technologies Institute\nNumber of Units: 9\nPrerequisites: (15-112) and (21-120) and (21-241)\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-485 Introduction to Deep Learning>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 82-881 Research Methods in Second Language Acquisition.txt"
        },
        "page_content":"<start course description for 82-881 Research Methods in Second Language Acquisition>\nSemester: Spring 2024 (aka S24)\nCourse Description: The course introduces students to research methodology as it applies to  language learning and language teaching. It provides an examination of  different approaches currently used in Second Language Acquisition (SLA)  research ranging from experimental studies to survey investigations. The  goal is to develop an ability to critically evaluate, design and implement  sound SLA research.\n<\/end course description for 82-881 Research Methods in Second Language Acquisition>",
        "type":"Document"
      }
    ],
    "model_output":"\nThe instructor for the course \"Quantitative Evaluation of Language Technologies\" in spring 2024 is Fernando Diaz.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is teaching the course \"Quantitative Evaluation of Language Technologies\" in spring 2024?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-801 Quantitative evaluation of language technologies>\nSemester: Spring 2024 (aka S24)\nCourse Name: Quantitative evaluation of language technologies\nCourse Number: 11-801\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Fernando Diaz\nRooms: WEH 5421\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-801 Quantitative evaluation of language technologies>\n-----\n<start course description for 11-801 Quantitative evaluation of language technologies>\nSemester: Spring 2024 (aka S24)\n-----\n<\/end course description for 11-801 Quantitative evaluation of language technologies>\n-----\n<start course metadata for 11-910 Directed Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Directed Research\nCourse Number: 11-910\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan, Robert Frederking\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-910 Directed Research>\n-----\n<start course metadata for 11-930 Dissertation Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Dissertation Research\nCourse Number: 11-930\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-930 Dissertation Research>\n\n<start course description for 11-930 Dissertation Research>\nSemester: Spring 2024 (aka S24)\nCourse Description: This course number is intended for PhD dissertation research after acceptance of a student's PhD thesis proposal.\n<\/end course description for 11-930 Dissertation Research>\n-----\n<start course metadata for 19-702 Quantitative Methods for Policy Analysis>\nSemester: Spring 2024 (aka S24)\nCourse Name: Quantitative Methods for Policy Analysis\nCourse Number: 19-702\nDepartment: Engineering & Public Policy\nNumber of Units: 12\nPrerequisites: None\nInstructors: Nicolas Christin\nRooms: BH 237B; BH 255A\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 19-702 Quantitative Methods for Policy Analysis>\n-----\n<start course description for 19-702 Quantitative Methods for Policy Analysis>\nSemester: Spring 2024 (aka S24)\nCourse Description: Economic framework for identifying and analyzing investment and operation options facing agencies and firms, (both in theory and in practice); economic efficiency, utilization, pricing, and investment; and multi-objective evaluation.\n<\/end course description for 19-702 Quantitative Methods for Policy Analysis>\n-----\n<start course metadata for 11-411 Natural Language Processing>\nSemester: Spring 2024 (aka S24)\nCourse Name: Natural Language Processing\nCourse Number: 11-411\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: 15-122\nInstructors: David Mortensen, Emma Strubell, Kemal Oflazer\nRooms: CMB 2052; POS A35\nLocations: Doha, Qatar; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-411 Natural Language Processing>\n-----\n<start course metadata for 11-485 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-485\nDepartment: Language Technologies Institute\nNumber of Units: 9\nPrerequisites: (15-112) and (21-120) and (21-241)\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-485 Introduction to Deep Learning>\n-----\n<start course description for 82-881 Research Methods in Second Language Acquisition>\nSemester: Spring 2024 (aka S24)\nCourse Description: The course introduces students to research methodology as it applies to  language learning and language teaching. It provides an examination of  different approaches currently used in Second Language Acquisition (SLA)  research ranging from experimental studies to survey investigations. The  goal is to develop an ability to critically evaluate, design and implement  sound SLA research.\n<\/end course description for 82-881 Research Methods in Second Language Acquisition>\n-----\n\n### Response ###\n\nUser: Who is teaching the course \"Quantitative Evaluation of Language Technologies\" in spring 2024?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Annette Han, Carolyn Rose",
    "index":25,
    "Q":"Who is teaching the course \"Foundations of Computational Data Science\" in summer 2024? Write the answer without diacritics, and list the instructor names in alphabetical order by first name, separated by comma.",
    "A":"Annette Han, Carolyn Rose",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Annette Han, Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-672 Foundations of Computational Data Science II.txt"
        },
        "page_content":"<start course metadata for 11-672 Foundations of Computational Data Science II>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science II\nCourse Number: 11-672\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: 11-671\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-672 Foundations of Computational Data Science II>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-671 Foundations of Computational Data I.txt"
        },
        "page_content":"<start course metadata for 11-671 Foundations of Computational Data I>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data I\nCourse Number: 11-671\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-671 Foundations of Computational Data I>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 47-843 Foundations of Data Science.txt"
        },
        "page_content":"<start course metadata for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Data Science\nCourse Number: 47-843\nDepartment: Business Administration\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ravindran Kannan\nRooms: TEP 5219\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-843 Foundations of Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 02-613 Algorithms and Advanced Data Structures.txt"
        },
        "page_content":"<start course metadata for 02-613 Algorithms and Advanced Data Structures>\nSemester: Spring 2024 (aka S24)\nCourse Name: Algorithms and Advanced Data Structures\nCourse Number: 02-613\nDepartment: Computational Biology\nNumber of Units: 12\nPrerequisites: None\nInstructors: Dan DeBlasio, Hosein Mohimani\nRooms: WEH 7500\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 02-613 Algorithms and Advanced Data Structures>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 02-613 Algorithms and Advanced Data Structures.txt"
        },
        "page_content":"<start course metadata for 02-613 Algorithms and Advanced Data Structures>\nSemester: Fall 2023 (aka F23)\nCourse Name: Algorithms and Advanced Data Structures\nCourse Number: 02-613\nDepartment: Computational Biology\nNumber of Units: 12\nPrerequisites: None\nInstructors: Yun Yu\nRooms: DH 2315\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 02-613 Algorithms and Advanced Data Structures>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 2) 36-200 Reasoning with Data.txt"
        },
        "page_content":"<start course metadata for 36-200 Reasoning with Data>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Name: Reasoning with Data\nCourse Number: 36-200\nDepartment: Statistics and Data Science\nNumber of Units: 9\nPrerequisites: None\nInstructors: Gordon Weinberg\nRooms: BH 140B; BH A36\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-200 Reasoning with Data>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 36-995 Reading and Research.txt"
        },
        "page_content":"<start course metadata for 36-995 Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Arun Kuchibhotla, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Joel Greenhouse, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Rebecca Nugent, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes, Zachary Branson",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Annette Han, Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-637 Foundations of Computational Data Science.txt"
        },
        "page_content":"<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-672 Foundations of Computational Data Science II.txt"
        },
        "page_content":"<start course metadata for 11-672 Foundations of Computational Data Science II>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science II\nCourse Number: 11-672\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: 11-671\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-672 Foundations of Computational Data Science II>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-671 Foundations of Computational Data I.txt"
        },
        "page_content":"<start course metadata for 11-671 Foundations of Computational Data I>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data I\nCourse Number: 11-671\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-671 Foundations of Computational Data I>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 47-843 Foundations of Data Science.txt"
        },
        "page_content":"<start course metadata for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Data Science\nCourse Number: 47-843\nDepartment: Business Administration\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ravindran Kannan\nRooms: TEP 5219\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-843 Foundations of Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 02-613 Algorithms and Advanced Data Structures.txt"
        },
        "page_content":"<start course metadata for 02-613 Algorithms and Advanced Data Structures>\nSemester: Spring 2024 (aka S24)\nCourse Name: Algorithms and Advanced Data Structures\nCourse Number: 02-613\nDepartment: Computational Biology\nNumber of Units: 12\nPrerequisites: None\nInstructors: Dan DeBlasio, Hosein Mohimani\nRooms: WEH 7500\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 02-613 Algorithms and Advanced Data Structures>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 02-613 Algorithms and Advanced Data Structures.txt"
        },
        "page_content":"<start course metadata for 02-613 Algorithms and Advanced Data Structures>\nSemester: Fall 2023 (aka F23)\nCourse Name: Algorithms and Advanced Data Structures\nCourse Number: 02-613\nDepartment: Computational Biology\nNumber of Units: 12\nPrerequisites: None\nInstructors: Yun Yu\nRooms: DH 2315\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 02-613 Algorithms and Advanced Data Structures>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 2) 36-200 Reasoning with Data.txt"
        },
        "page_content":"<start course metadata for 36-200 Reasoning with Data>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Name: Reasoning with Data\nCourse Number: 36-200\nDepartment: Statistics and Data Science\nNumber of Units: 9\nPrerequisites: None\nInstructors: Gordon Weinberg\nRooms: BH 140B; BH A36\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-200 Reasoning with Data>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 36-995 Reading and Research.txt"
        },
        "page_content":"<start course metadata for 36-995 Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Arun Kuchibhotla, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Joel Greenhouse, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Rebecca Nugent, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes, Zachary Branson",
        "type":"Document"
      }
    ],
    "model_output":"\nAnnette Han, Carolyn Rose",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who is teaching the course \"Foundations of Computational Data Science\" in summer 2024? Write the answer without diacritics, and list the instructor names in alphabetical order by first name, separated by comma.\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Annette Han, Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>\n-----\n<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>\n-----\n<start course metadata for 11-637 Foundations of Computational Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Computational Data Science\nCourse Number: 11-637\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-637 Foundations of Computational Data Science>\n-----\n<start course metadata for 11-672 Foundations of Computational Data Science II>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data Science II\nCourse Number: 11-672\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: 11-671\nInstructors: Carolyn Rose\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-672 Foundations of Computational Data Science II>\n-----\n<start course metadata for 11-671 Foundations of Computational Data I>\nSemester: Spring 2024 (aka S24)\nCourse Name: Foundations of Computational Data I\nCourse Number: 11-671\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Carolyn Rose\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-671 Foundations of Computational Data I>\n-----\n<start course metadata for 47-843 Foundations of Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Foundations of Data Science\nCourse Number: 47-843\nDepartment: Business Administration\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ravindran Kannan\nRooms: TEP 5219\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-843 Foundations of Data Science>\n-----\n<start course metadata for 02-613 Algorithms and Advanced Data Structures>\nSemester: Spring 2024 (aka S24)\nCourse Name: Algorithms and Advanced Data Structures\nCourse Number: 02-613\nDepartment: Computational Biology\nNumber of Units: 12\nPrerequisites: None\nInstructors: Dan DeBlasio, Hosein Mohimani\nRooms: WEH 7500\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 02-613 Algorithms and Advanced Data Structures>\n-----\n<start course metadata for 02-613 Algorithms and Advanced Data Structures>\nSemester: Fall 2023 (aka F23)\nCourse Name: Algorithms and Advanced Data Structures\nCourse Number: 02-613\nDepartment: Computational Biology\nNumber of Units: 12\nPrerequisites: None\nInstructors: Yun Yu\nRooms: DH 2315\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 02-613 Algorithms and Advanced Data Structures>\n-----\n<start course metadata for 36-200 Reasoning with Data>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Name: Reasoning with Data\nCourse Number: 36-200\nDepartment: Statistics and Data Science\nNumber of Units: 9\nPrerequisites: None\nInstructors: Gordon Weinberg\nRooms: BH 140B; BH A36\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 36-200 Reasoning with Data>\n-----\n<start course metadata for 36-995 Reading and Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Reading and Research\nCourse Number: 36-995\nDepartment: Statistics and Data Science\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Aaditya Ramdas, Alexander Reinhart, Alexandra Chouldechova, Ann Lee, Arun Kuchibhotla, Chad Schafer, Christopher Genovese, Cosma Shalizi, Edward Kennedy, Eli Ben-Michael, Jiashun Jin, Jing Lei, Joel Greenhouse, Kathryn Roeder, Larry Wasserman, Matey Neykov, Mikael Kuusela, Nynke Niezink, Rebecca Nugent, Robert Kass, Robin Mejia, Sivaraman Balakrishnan, Valerie Ventura, Will Townes, Zachary Branson\n-----\n\n### Response ###\n\nUser: Who is teaching the course \"Foundations of Computational Data Science\" in summer 2024? Write the answer without diacritics, and list the instructor names in alphabetical order by first name, separated by comma.\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Eric Nyberg",
    "index":26,
    "Q":"Who taught the course called \"Data Science Capstone Research\" in summer 2023?",
    "A":"Eric Nyberg",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-635 Data Science Capstone Research.txt"
        },
        "page_content":"<start course metadata for 11-635 Data Science Capstone Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Capstone Research\nCourse Number: 11-635\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg\nRooms: TEP 1403\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-635 Data Science Capstone Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-635 Data Science Capstone Research.txt"
        },
        "page_content":"<start course metadata for 11-635 Data Science Capstone Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Data Science Capstone Research\nCourse Number: 11-635\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-635 Data Science Capstone Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-635 Data Science Capstone Research.txt"
        },
        "page_content":"<start course description for 11-635 Data Science Capstone Research>\nSemester: Spring 2024 (aka S24)\nCourse Description: The MCDS Capstone Research Course is the final large team project for MCDS master degree students.  Students take 11-635 combined with 11-632 as combined capstone course for process & outcomes.  This process and outcome course evaluates the project team's use of software engineering methodology and evaluates the outcomes of the capstone project. Software Engineering best practices. Researching and developing innovative solutions to open problems. Tools are dependent on the specific project.  General tools include: Github.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-635 Data Science Capstone Research.txt"
        },
        "page_content":"<start course description for 11-635 Data Science Capstone Research>\nSemester: Fall 2023 (aka F23)\nCourse Description: The MCDS Capstone Research Course is the final large team project for MCDS master degree students.  Students take 11-635 combined with 11-632 as combined capstone course for process & outcomes.  This process and outcome course evaluates the project team's use of software engineering methodology and evaluates the outcomes of the capstone project.\n<\/end course description for 11-635 Data Science Capstone Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-632 Data Science Capstone.txt"
        },
        "page_content":"<start course metadata for 11-632 Data Science Capstone>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Capstone\nCourse Number: 11-632\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg\nRooms: TEP 1403\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-632 Data Science Capstone>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 67-426 Special Topics - Capstone course in Data Science.txt"
        },
        "page_content":"<start course metadata for 67-426 Special Topics - Capstone course in Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Special Topics - Capstone course in Data Science\nCourse Number: 67-426\nDepartment: Information Systems Program\nNumber of Units: 9\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: DNM DNM\nLocations: Doha, Qatar\n<\/end course metadata for 67-426 Special Topics - Capstone course in Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 67-426 Special Topics - Capstone course in Data Science.txt"
        },
        "page_content":"<start course metadata for 67-426 Special Topics - Capstone course in Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Special Topics - Capstone course in Data Science\nCourse Number: 67-426\nDepartment: Information Systems Program\nNumber of Units: 9\nPrerequisites: None\nInstructors: Houda Bouamor\nRooms: CMB 3048\nLocations: Doha, Qatar\n<\/end course metadata for 67-426 Special Topics - Capstone course in Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 67-426 Special Topics - Capstone course in Data Science.txt"
        },
        "page_content":"<start course description for 67-426 Special Topics - Capstone course in Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Description: TBA\n<\/end course description for 67-426 Special Topics - Capstone course in Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 38-617 MS in Data Analytics for Science Capstone Project Course.txt"
        },
        "page_content":"<start course metadata for 38-617 MS in Data Analytics for Science Capstone Project Course>\nSemester: Spring 2024 (aka S24)\nCourse Name: MS in Data Analytics for Science Capstone Project Course\nCourse Number: 38-617\nDepartment: MCS Interdisciplinary\nNumber of Units: 12\nPrerequisites: None\nInstructors: John Urbanic Jr, Manfred Paulini\nRooms: DH 2105\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 38-617 MS in Data Analytics for Science Capstone Project Course>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 38-617 MS in Data Analytics for Science Capstone Project Course.txt"
        },
        "page_content":"<start course description for 38-617 MS in Data Analytics for Science Capstone Project Course>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-635 Data Science Capstone Research.txt"
        },
        "page_content":"<start course metadata for 11-635 Data Science Capstone Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Capstone Research\nCourse Number: 11-635\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg\nRooms: TEP 1403\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-635 Data Science Capstone Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-635 Data Science Capstone Research.txt"
        },
        "page_content":"<start course metadata for 11-635 Data Science Capstone Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Data Science Capstone Research\nCourse Number: 11-635\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-635 Data Science Capstone Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-635 Data Science Capstone Research.txt"
        },
        "page_content":"<start course description for 11-635 Data Science Capstone Research>\nSemester: Spring 2024 (aka S24)\nCourse Description: The MCDS Capstone Research Course is the final large team project for MCDS master degree students.  Students take 11-635 combined with 11-632 as combined capstone course for process & outcomes.  This process and outcome course evaluates the project team's use of software engineering methodology and evaluates the outcomes of the capstone project. Software Engineering best practices. Researching and developing innovative solutions to open problems. Tools are dependent on the specific project.  General tools include: Github.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-635 Data Science Capstone Research.txt"
        },
        "page_content":"<start course description for 11-635 Data Science Capstone Research>\nSemester: Fall 2023 (aka F23)\nCourse Description: The MCDS Capstone Research Course is the final large team project for MCDS master degree students.  Students take 11-635 combined with 11-632 as combined capstone course for process & outcomes.  This process and outcome course evaluates the project team's use of software engineering methodology and evaluates the outcomes of the capstone project.\n<\/end course description for 11-635 Data Science Capstone Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-632 Data Science Capstone.txt"
        },
        "page_content":"<start course metadata for 11-632 Data Science Capstone>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Capstone\nCourse Number: 11-632\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg\nRooms: TEP 1403\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-632 Data Science Capstone>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 67-426 Special Topics - Capstone course in Data Science.txt"
        },
        "page_content":"<start course metadata for 67-426 Special Topics - Capstone course in Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Special Topics - Capstone course in Data Science\nCourse Number: 67-426\nDepartment: Information Systems Program\nNumber of Units: 9\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: DNM DNM\nLocations: Doha, Qatar\n<\/end course metadata for 67-426 Special Topics - Capstone course in Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 67-426 Special Topics - Capstone course in Data Science.txt"
        },
        "page_content":"<start course metadata for 67-426 Special Topics - Capstone course in Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Special Topics - Capstone course in Data Science\nCourse Number: 67-426\nDepartment: Information Systems Program\nNumber of Units: 9\nPrerequisites: None\nInstructors: Houda Bouamor\nRooms: CMB 3048\nLocations: Doha, Qatar\n<\/end course metadata for 67-426 Special Topics - Capstone course in Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 67-426 Special Topics - Capstone course in Data Science.txt"
        },
        "page_content":"<start course description for 67-426 Special Topics - Capstone course in Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Description: TBA\n<\/end course description for 67-426 Special Topics - Capstone course in Data Science>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 38-617 MS in Data Analytics for Science Capstone Project Course.txt"
        },
        "page_content":"<start course metadata for 38-617 MS in Data Analytics for Science Capstone Project Course>\nSemester: Spring 2024 (aka S24)\nCourse Name: MS in Data Analytics for Science Capstone Project Course\nCourse Number: 38-617\nDepartment: MCS Interdisciplinary\nNumber of Units: 12\nPrerequisites: None\nInstructors: John Urbanic Jr, Manfred Paulini\nRooms: DH 2105\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 38-617 MS in Data Analytics for Science Capstone Project Course>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 38-617 MS in Data Analytics for Science Capstone Project Course.txt"
        },
        "page_content":"<start course description for 38-617 MS in Data Analytics for Science Capstone Project Course>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      }
    ],
    "model_output":"\nThe instructor for the course \"Data Science Capstone Research\" in summer 2023 was Eric Nyberg.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who taught the course called \"Data Science Capstone Research\" in summer 2023?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-635 Data Science Capstone Research>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Capstone Research\nCourse Number: 11-635\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg\nRooms: TEP 1403\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-635 Data Science Capstone Research>\n-----\n<start course metadata for 11-635 Data Science Capstone Research>\nSemester: Spring 2024 (aka S24)\nCourse Name: Data Science Capstone Research\nCourse Number: 11-635\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-635 Data Science Capstone Research>\n-----\n<start course description for 11-635 Data Science Capstone Research>\nSemester: Spring 2024 (aka S24)\nCourse Description: The MCDS Capstone Research Course is the final large team project for MCDS master degree students.  Students take 11-635 combined with 11-632 as combined capstone course for process & outcomes.  This process and outcome course evaluates the project team's use of software engineering methodology and evaluates the outcomes of the capstone project. Software Engineering best practices. Researching and developing innovative solutions to open problems. Tools are dependent on the specific project.  General tools include: Github.\n-----\n<start course description for 11-635 Data Science Capstone Research>\nSemester: Fall 2023 (aka F23)\nCourse Description: The MCDS Capstone Research Course is the final large team project for MCDS master degree students.  Students take 11-635 combined with 11-632 as combined capstone course for process & outcomes.  This process and outcome course evaluates the project team's use of software engineering methodology and evaluates the outcomes of the capstone project.\n<\/end course description for 11-635 Data Science Capstone Research>\n-----\n<start course metadata for 11-632 Data Science Capstone>\nSemester: Fall 2023 (aka F23)\nCourse Name: Data Science Capstone\nCourse Number: 11-632\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Eric Nyberg\nRooms: TEP 1403\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-632 Data Science Capstone>\n-----\n<start course metadata for 67-426 Special Topics - Capstone course in Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Name: Special Topics - Capstone course in Data Science\nCourse Number: 67-426\nDepartment: Information Systems Program\nNumber of Units: 9\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: DNM DNM\nLocations: Doha, Qatar\n<\/end course metadata for 67-426 Special Topics - Capstone course in Data Science>\n-----\n<start course metadata for 67-426 Special Topics - Capstone course in Data Science>\nSemester: Fall 2023 (aka F23)\nCourse Name: Special Topics - Capstone course in Data Science\nCourse Number: 67-426\nDepartment: Information Systems Program\nNumber of Units: 9\nPrerequisites: None\nInstructors: Houda Bouamor\nRooms: CMB 3048\nLocations: Doha, Qatar\n<\/end course metadata for 67-426 Special Topics - Capstone course in Data Science>\n-----\n<start course description for 67-426 Special Topics - Capstone course in Data Science>\nSemester: Spring 2024 (aka S24)\nCourse Description: TBA\n<\/end course description for 67-426 Special Topics - Capstone course in Data Science>\n-----\n<start course metadata for 38-617 MS in Data Analytics for Science Capstone Project Course>\nSemester: Spring 2024 (aka S24)\nCourse Name: MS in Data Analytics for Science Capstone Project Course\nCourse Number: 38-617\nDepartment: MCS Interdisciplinary\nNumber of Units: 12\nPrerequisites: None\nInstructors: John Urbanic Jr, Manfred Paulini\nRooms: DH 2105\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 38-617 MS in Data Analytics for Science Capstone Project Course>\n-----\n<start course description for 38-617 MS in Data Analytics for Science Capstone Project Course>\nSemester: Spring 2024 (aka S24)\n-----\n\n### Response ###\n\nUser: Who taught the course called \"Data Science Capstone Research\" in summer 2023?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Jamie Callan",
    "index":27,
    "Q":"Who was the instructor for the \"PhD Internship\" in summer 2023?",
    "A":"Jamie Callan",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-936 PhD Internship.txt"
        },
        "page_content":"<start course metadata for 11-936 PhD Internship>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: PhD Internship\nCourse Number: 11-936\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA, Jamie Callan\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-936 PhD Internship>\n\n<start course description for 11-936 PhD Internship>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Description: TBA\n<\/end course description for 11-936 PhD Internship>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 2) 11-936 PhD Internship.txt"
        },
        "page_content":"<start course metadata for 11-936 PhD Internship>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Name: PhD Internship\nCourse Number: 11-936\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-936 PhD Internship>\n\n<start course description for 11-936 PhD Internship>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Description: TBA\n<\/end course description for 11-936 PhD Internship>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 48-704 Internship (MS & PhD).txt"
        },
        "page_content":"<start course metadata for 48-704 Internship (MS & PhD)>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship (MS & PhD)\nCourse Number: 48-704\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Dana Cupkova, Daniel Cardoso Llach, Erica Cochran, Joshua Bard, Joshua Lee, Ramesh Krishnamurti, Vivian Loftness\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-704 Internship (MS & PhD)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 47-998 Tepper PhD Internship.txt"
        },
        "page_content":"<start course metadata for 47-998 Tepper PhD Internship>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Tepper PhD Internship\nCourse Number: 47-998\nDepartment: Business Administration\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Ali Shourideh\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-998 Tepper PhD Internship>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 2) 47-998 Tepper PhD Internship.txt"
        },
        "page_content":"<start course metadata for 47-998 Tepper PhD Internship>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Name: Tepper PhD Internship\nCourse Number: 47-998\nDepartment: Business Administration\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-998 Tepper PhD Internship>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 90-989 Phd Internship.txt"
        },
        "page_content":"<start course metadata for 90-989 Phd Internship>\nSemester: Spring 2024 (aka S24)\nCourse Name: Phd Internship\nCourse Number: 90-989\nDepartment: Public Policy & Mgt:Sch of Pub Pol & Mgt\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: George Chen\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 90-989 Phd Internship>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 18-996 Internship one for Electrical and Computer Engineering PhD Students.txt"
        },
        "page_content":"<start course metadata for 18-996 Internship one for Electrical and Computer Engineering PhD Students>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship one for Electrical and Computer Engineering PhD Students\nCourse Number: 18-996\nDepartment: Electrical & Computer Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: James Bain\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-996 Internship one for Electrical and Computer Engineering PhD Students>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 18-997 Internship Two for Electrical and Computer Engineering PhD Students.txt"
        },
        "page_content":"<start course metadata for 18-997 Internship Two for Electrical and Computer Engineering PhD Students>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship Two for Electrical and Computer Engineering PhD Students\nCourse Number: 18-997\nDepartment: Electrical & Computer Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: James Bain\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-997 Internship Two for Electrical and Computer Engineering PhD Students>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 18-998 Internship Three Electrical and Computer Engineering PhD Students.txt"
        },
        "page_content":"<start course metadata for 18-998 Internship Three Electrical and Computer Engineering PhD Students>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship Three Electrical and Computer Engineering PhD Students\nCourse Number: 18-998\nDepartment: Electrical & Computer Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: James Bain\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-998 Internship Three Electrical and Computer Engineering PhD Students>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 24-795 PhD Internship in Teaching Counterpoint.txt"
        },
        "page_content":"<start course metadata for 24-795 PhD Internship in Teaching Counterpoint>\nSemester: Spring 2024 (aka S24)\nCourse Name: PhD Internship in Teaching Counterpoint\nCourse Number: 24-795\nDepartment: Mechanical Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Chris Hertz\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 24-795 PhD Internship in Teaching Counterpoint>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-936 PhD Internship.txt"
        },
        "page_content":"<start course metadata for 11-936 PhD Internship>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: PhD Internship\nCourse Number: 11-936\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA, Jamie Callan\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-936 PhD Internship>\n\n<start course description for 11-936 PhD Internship>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Description: TBA\n<\/end course description for 11-936 PhD Internship>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 2) 11-936 PhD Internship.txt"
        },
        "page_content":"<start course metadata for 11-936 PhD Internship>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Name: PhD Internship\nCourse Number: 11-936\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-936 PhD Internship>\n\n<start course description for 11-936 PhD Internship>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Description: TBA\n<\/end course description for 11-936 PhD Internship>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 48-704 Internship (MS & PhD).txt"
        },
        "page_content":"<start course metadata for 48-704 Internship (MS & PhD)>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship (MS & PhD)\nCourse Number: 48-704\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Dana Cupkova, Daniel Cardoso Llach, Erica Cochran, Joshua Bard, Joshua Lee, Ramesh Krishnamurti, Vivian Loftness\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-704 Internship (MS & PhD)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 47-998 Tepper PhD Internship.txt"
        },
        "page_content":"<start course metadata for 47-998 Tepper PhD Internship>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Tepper PhD Internship\nCourse Number: 47-998\nDepartment: Business Administration\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Ali Shourideh\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-998 Tepper PhD Internship>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 2) 47-998 Tepper PhD Internship.txt"
        },
        "page_content":"<start course metadata for 47-998 Tepper PhD Internship>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Name: Tepper PhD Internship\nCourse Number: 47-998\nDepartment: Business Administration\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-998 Tepper PhD Internship>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 90-989 Phd Internship.txt"
        },
        "page_content":"<start course metadata for 90-989 Phd Internship>\nSemester: Spring 2024 (aka S24)\nCourse Name: Phd Internship\nCourse Number: 90-989\nDepartment: Public Policy & Mgt:Sch of Pub Pol & Mgt\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: George Chen\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 90-989 Phd Internship>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 18-996 Internship one for Electrical and Computer Engineering PhD Students.txt"
        },
        "page_content":"<start course metadata for 18-996 Internship one for Electrical and Computer Engineering PhD Students>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship one for Electrical and Computer Engineering PhD Students\nCourse Number: 18-996\nDepartment: Electrical & Computer Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: James Bain\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-996 Internship one for Electrical and Computer Engineering PhD Students>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 18-997 Internship Two for Electrical and Computer Engineering PhD Students.txt"
        },
        "page_content":"<start course metadata for 18-997 Internship Two for Electrical and Computer Engineering PhD Students>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship Two for Electrical and Computer Engineering PhD Students\nCourse Number: 18-997\nDepartment: Electrical & Computer Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: James Bain\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-997 Internship Two for Electrical and Computer Engineering PhD Students>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 18-998 Internship Three Electrical and Computer Engineering PhD Students.txt"
        },
        "page_content":"<start course metadata for 18-998 Internship Three Electrical and Computer Engineering PhD Students>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship Three Electrical and Computer Engineering PhD Students\nCourse Number: 18-998\nDepartment: Electrical & Computer Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: James Bain\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-998 Internship Three Electrical and Computer Engineering PhD Students>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 24-795 PhD Internship in Teaching Counterpoint.txt"
        },
        "page_content":"<start course metadata for 24-795 PhD Internship in Teaching Counterpoint>\nSemester: Spring 2024 (aka S24)\nCourse Name: PhD Internship in Teaching Counterpoint\nCourse Number: 24-795\nDepartment: Mechanical Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Chris Hertz\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 24-795 PhD Internship in Teaching Counterpoint>",
        "type":"Document"
      }
    ],
    "model_output":"\nThe instructor for the \"PhD Internship\" in summer 2023 was Jamie Callan.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who was the instructor for the \"PhD Internship\" in summer 2023?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-936 PhD Internship>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: PhD Internship\nCourse Number: 11-936\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA, Jamie Callan\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-936 PhD Internship>\n\n<start course description for 11-936 PhD Internship>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Description: TBA\n<\/end course description for 11-936 PhD Internship>\n-----\n<start course metadata for 11-936 PhD Internship>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Name: PhD Internship\nCourse Number: 11-936\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-936 PhD Internship>\n\n<start course description for 11-936 PhD Internship>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Description: TBA\n<\/end course description for 11-936 PhD Internship>\n-----\n<start course metadata for 48-704 Internship (MS & PhD)>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship (MS & PhD)\nCourse Number: 48-704\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Dana Cupkova, Daniel Cardoso Llach, Erica Cochran, Joshua Bard, Joshua Lee, Ramesh Krishnamurti, Vivian Loftness\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-704 Internship (MS & PhD)>\n-----\n<start course metadata for 47-998 Tepper PhD Internship>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Tepper PhD Internship\nCourse Number: 47-998\nDepartment: Business Administration\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Ali Shourideh\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-998 Tepper PhD Internship>\n-----\n<start course metadata for 47-998 Tepper PhD Internship>\nSemester: Summer Two 2024 (aka M24, M24 Mini 2, Summer 2024 Mini 2)\nCourse Name: Tepper PhD Internship\nCourse Number: 47-998\nDepartment: Business Administration\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 47-998 Tepper PhD Internship>\n-----\n<start course metadata for 90-989 Phd Internship>\nSemester: Spring 2024 (aka S24)\nCourse Name: Phd Internship\nCourse Number: 90-989\nDepartment: Public Policy & Mgt:Sch of Pub Pol & Mgt\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: George Chen\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 90-989 Phd Internship>\n-----\n<start course metadata for 18-996 Internship one for Electrical and Computer Engineering PhD Students>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship one for Electrical and Computer Engineering PhD Students\nCourse Number: 18-996\nDepartment: Electrical & Computer Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: James Bain\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-996 Internship one for Electrical and Computer Engineering PhD Students>\n-----\n<start course metadata for 18-997 Internship Two for Electrical and Computer Engineering PhD Students>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship Two for Electrical and Computer Engineering PhD Students\nCourse Number: 18-997\nDepartment: Electrical & Computer Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: James Bain\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-997 Internship Two for Electrical and Computer Engineering PhD Students>\n-----\n<start course metadata for 18-998 Internship Three Electrical and Computer Engineering PhD Students>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Internship Three Electrical and Computer Engineering PhD Students\nCourse Number: 18-998\nDepartment: Electrical & Computer Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: James Bain\nRooms: DNM DNM\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania; San Jose, California\n<\/end course metadata for 18-998 Internship Three Electrical and Computer Engineering PhD Students>\n-----\n<start course metadata for 24-795 PhD Internship in Teaching Counterpoint>\nSemester: Spring 2024 (aka S24)\nCourse Name: PhD Internship in Teaching Counterpoint\nCourse Number: 24-795\nDepartment: Mechanical Engineering\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Chris Hertz\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 24-795 PhD Internship in Teaching Counterpoint>\n-----\n\n### Response ###\n\nUser: Who was the instructor for the \"PhD Internship\" in summer 2023?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Teruko Mitamura",
    "index":28,
    "Q":"Who taught the course \"MIIS Directed Study\" in fall 2023?",
    "A":"Teruko Mitamura",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-690 MIIS Directed Study.txt"
        },
        "page_content":"<start course metadata for 11-690 MIIS Directed Study>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Directed Study\nCourse Number: 11-690\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Teruko Mitamura\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-690 MIIS Directed Study>\n\n<start course description for 11-690 MIIS Directed Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: to be determined by the department\n<\/end course description for 11-690 MIIS Directed Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-690 MIIS Directed Study.txt"
        },
        "page_content":"<start course metadata for 11-690 MIIS Directed Study>\nSemester: Spring 2024 (aka S24)\nCourse Name: MIIS Directed Study\nCourse Number: 11-690\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Teruko Mitamura\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-690 MIIS Directed Study>\n\n<start course description for 11-690 MIIS Directed Study>\nSemester: Spring 2024 (aka S24)\nCourse Description: to be determined by the department\n<\/end course description for 11-690 MIIS Directed Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Intro to ML (MLD)\n\nMIIS Directed Study\n\nQuestion Answering\n\nIntro to Deep Learning\n\nMIIS Capstone Planning Seminar\n\nMIIS Directed Study\n\nInternship\t\nMIIS Capstone Project\n\nLanguage and Statistics\n\nComp Semantics for NLP\n\nML for Signal Processing\n\nElective\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 49-749 Independent Study.txt"
        },
        "page_content":"<start course description for 49-749 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: This independent study is designed to give students an opportunity to explore pertinent subjects through faculty directed reading or research. Variable hrs. Once you and the faculty have agreed upon the independent study, send the independent study form to the manager of Integrated Innovation Institute for enrollment. Restricted to only MII-PS students.\n<\/end course description for 49-749 Independent Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-696 MIIS Capstone Planning Seminar.txt"
        },
        "page_content":"<start course metadata for 11-696 MIIS Capstone Planning Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Planning Seminar\nCourse Number: 11-696\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-696 MIIS Capstone Planning Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-927 MIIS Capstone Project.txt"
        },
        "page_content":"<start course metadata for 11-927 MIIS Capstone Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Project\nCourse Number: 11-927\nDepartment: Language Technologies Institute\nNumber of Units: 36\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-927 MIIS Capstone Project>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 49-748 Independent Study.txt"
        },
        "page_content":"<start course description for 49-748 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: This independent study is designed to give students an opportunity to explore pertinent subjects through faculty directed reading or research. Variable hrs. Once you and the faculty have agreed upon the independent study, send the independent study form to the manager of Integrated Innovation Institute for enrollment. Restricted to only MIIPS students.\n<\/end course description for 49-748 Independent Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Fall 1\n\nSpring\n\nSummer\n\nSearch Engines\n\nAnalysis of Social Media\n\nDesign and Engineering of Intelligent Systems\n\nDirected Study\n\nMachine Learning\n\nNatural Language Processing\n\nQuestion Answering\n\nDirected Study\n\nMIIS Capstone Planning Seminar\n\nAcademic Research Practices and Scientific Communities\n\nMIIS Capstone Project\n\n \n\nHere are some example schedules for completing the MIIS-21 program.\n\nExample Course of Study #1\n\nThis schedule would satisfy course requirements for a student interested in deepening their expertise in Machine Learning area of concentration.\n\nFall 1\tSpring 1\tSummer\tFall 2\tSpring 2\nSearch Engines\n\nAlgorithms for NLP",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Summer\n\nFall 2\n\nMachine Learning\n\nSearch Engines\n\nDesign and Engineering of Intelligent Systems\\ Directed Study\n\nLanguage and Statistics\n\nNatural Language Processing\n\nQuestion Answering\n\nDirected Study\n\nMIIS Capstone Planning Seminar\n\nInternship\n\nMachine Learning for Text Mining\n\nMIIS Capstone Project\n\n \n\nExample Course of Study #2\n\nThis schedule would satisfy course requirements for a student interested in voice-based computer applications.\n\nFall 1\n\nSpring\n\nSummer\n\nFall 2\n\nMachine Learning\n\nAlgorithms for NLP\n\nSpeech Recognition and Understanding\n\nDirected Study\n\nApplied Machine Learning\n\nCompetitive Engineering",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-696 MIIS Capstone Planning Seminar.txt"
        },
        "page_content":"<start course description for 11-696 MIIS Capstone Planning Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Description: The MIIS Capstone Planning Seminar prepares students to complete the MIIS Capstone Project in the following semester.  Students are organized into teams that will work together to complete the capstone project.  They define project goals, requirements, success metrics, and deliverables; and they identify and acquires data, software, and other resources required for successful completion of the project. The planning seminar must be completed in the semester prior to taking the capstone project.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-690 MIIS Directed Study.txt"
        },
        "page_content":"<start course metadata for 11-690 MIIS Directed Study>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Directed Study\nCourse Number: 11-690\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Teruko Mitamura\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-690 MIIS Directed Study>\n\n<start course description for 11-690 MIIS Directed Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: to be determined by the department\n<\/end course description for 11-690 MIIS Directed Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-690 MIIS Directed Study.txt"
        },
        "page_content":"<start course metadata for 11-690 MIIS Directed Study>\nSemester: Spring 2024 (aka S24)\nCourse Name: MIIS Directed Study\nCourse Number: 11-690\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Teruko Mitamura\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-690 MIIS Directed Study>\n\n<start course description for 11-690 MIIS Directed Study>\nSemester: Spring 2024 (aka S24)\nCourse Description: to be determined by the department\n<\/end course description for 11-690 MIIS Directed Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Intro to ML (MLD)\n\nMIIS Directed Study\n\nQuestion Answering\n\nIntro to Deep Learning\n\nMIIS Capstone Planning Seminar\n\nMIIS Directed Study\n\nInternship\t\nMIIS Capstone Project\n\nLanguage and Statistics\n\nComp Semantics for NLP\n\nML for Signal Processing\n\nElective\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 49-749 Independent Study.txt"
        },
        "page_content":"<start course description for 49-749 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: This independent study is designed to give students an opportunity to explore pertinent subjects through faculty directed reading or research. Variable hrs. Once you and the faculty have agreed upon the independent study, send the independent study form to the manager of Integrated Innovation Institute for enrollment. Restricted to only MII-PS students.\n<\/end course description for 49-749 Independent Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-696 MIIS Capstone Planning Seminar.txt"
        },
        "page_content":"<start course metadata for 11-696 MIIS Capstone Planning Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Planning Seminar\nCourse Number: 11-696\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-696 MIIS Capstone Planning Seminar>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-927 MIIS Capstone Project.txt"
        },
        "page_content":"<start course metadata for 11-927 MIIS Capstone Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Project\nCourse Number: 11-927\nDepartment: Language Technologies Institute\nNumber of Units: 36\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-927 MIIS Capstone Project>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 49-748 Independent Study.txt"
        },
        "page_content":"<start course description for 49-748 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: This independent study is designed to give students an opportunity to explore pertinent subjects through faculty directed reading or research. Variable hrs. Once you and the faculty have agreed upon the independent study, send the independent study form to the manager of Integrated Innovation Institute for enrollment. Restricted to only MIIPS students.\n<\/end course description for 49-748 Independent Study>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Fall 1\n\nSpring\n\nSummer\n\nSearch Engines\n\nAnalysis of Social Media\n\nDesign and Engineering of Intelligent Systems\n\nDirected Study\n\nMachine Learning\n\nNatural Language Processing\n\nQuestion Answering\n\nDirected Study\n\nMIIS Capstone Planning Seminar\n\nAcademic Research Practices and Scientific Communities\n\nMIIS Capstone Project\n\n \n\nHere are some example schedules for completing the MIIS-21 program.\n\nExample Course of Study #1\n\nThis schedule would satisfy course requirements for a student interested in deepening their expertise in Machine Learning area of concentration.\n\nFall 1\tSpring 1\tSummer\tFall 2\tSpring 2\nSearch Engines\n\nAlgorithms for NLP",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Summer\n\nFall 2\n\nMachine Learning\n\nSearch Engines\n\nDesign and Engineering of Intelligent Systems\\ Directed Study\n\nLanguage and Statistics\n\nNatural Language Processing\n\nQuestion Answering\n\nDirected Study\n\nMIIS Capstone Planning Seminar\n\nInternship\n\nMachine Learning for Text Mining\n\nMIIS Capstone Project\n\n \n\nExample Course of Study #2\n\nThis schedule would satisfy course requirements for a student interested in voice-based computer applications.\n\nFall 1\n\nSpring\n\nSummer\n\nFall 2\n\nMachine Learning\n\nAlgorithms for NLP\n\nSpeech Recognition and Understanding\n\nDirected Study\n\nApplied Machine Learning\n\nCompetitive Engineering",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-696 MIIS Capstone Planning Seminar.txt"
        },
        "page_content":"<start course description for 11-696 MIIS Capstone Planning Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Description: The MIIS Capstone Planning Seminar prepares students to complete the MIIS Capstone Project in the following semester.  Students are organized into teams that will work together to complete the capstone project.  They define project goals, requirements, success metrics, and deliverables; and they identify and acquires data, software, and other resources required for successful completion of the project. The planning seminar must be completed in the semester prior to taking the capstone project.",
        "type":"Document"
      }
    ],
    "model_output":"\nTeruko Mitamura taught the course \"MIIS Directed Study\" in fall 2023.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who taught the course \"MIIS Directed Study\" in fall 2023?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 11-690 MIIS Directed Study>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Directed Study\nCourse Number: 11-690\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Teruko Mitamura\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-690 MIIS Directed Study>\n\n<start course description for 11-690 MIIS Directed Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: to be determined by the department\n<\/end course description for 11-690 MIIS Directed Study>\n-----\n<start course metadata for 11-690 MIIS Directed Study>\nSemester: Spring 2024 (aka S24)\nCourse Name: MIIS Directed Study\nCourse Number: 11-690\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Teruko Mitamura\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-690 MIIS Directed Study>\n\n<start course description for 11-690 MIIS Directed Study>\nSemester: Spring 2024 (aka S24)\nCourse Description: to be determined by the department\n<\/end course description for 11-690 MIIS Directed Study>\n-----\nIntro to ML (MLD)\n\nMIIS Directed Study\n\nQuestion Answering\n\nIntro to Deep Learning\n\nMIIS Capstone Planning Seminar\n\nMIIS Directed Study\n\nInternship\t\nMIIS Capstone Project\n\nLanguage and Statistics\n\nComp Semantics for NLP\n\nML for Signal Processing\n\nElective\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.\n-----\n<start course description for 49-749 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: This independent study is designed to give students an opportunity to explore pertinent subjects through faculty directed reading or research. Variable hrs. Once you and the faculty have agreed upon the independent study, send the independent study form to the manager of Integrated Innovation Institute for enrollment. Restricted to only MII-PS students.\n<\/end course description for 49-749 Independent Study>\n-----\n<start course metadata for 11-696 MIIS Capstone Planning Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Planning Seminar\nCourse Number: 11-696\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-696 MIIS Capstone Planning Seminar>\n-----\n<start course metadata for 11-927 MIIS Capstone Project>\nSemester: Fall 2023 (aka F23)\nCourse Name: MIIS Capstone Project\nCourse Number: 11-927\nDepartment: Language Technologies Institute\nNumber of Units: 36\nPrerequisites: None\nInstructors: Ralf Brown\nRooms: DNM DNM\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-927 MIIS Capstone Project>\n-----\n<start course description for 49-748 Independent Study>\nSemester: Fall 2023 (aka F23)\nCourse Description: This independent study is designed to give students an opportunity to explore pertinent subjects through faculty directed reading or research. Variable hrs. Once you and the faculty have agreed upon the independent study, send the independent study form to the manager of Integrated Innovation Institute for enrollment. Restricted to only MIIPS students.\n<\/end course description for 49-748 Independent Study>\n-----\nFall 1\n\nSpring\n\nSummer\n\nSearch Engines\n\nAnalysis of Social Media\n\nDesign and Engineering of Intelligent Systems\n\nDirected Study\n\nMachine Learning\n\nNatural Language Processing\n\nQuestion Answering\n\nDirected Study\n\nMIIS Capstone Planning Seminar\n\nAcademic Research Practices and Scientific Communities\n\nMIIS Capstone Project\n\n \n\nHere are some example schedules for completing the MIIS-21 program.\n\nExample Course of Study #1\n\nThis schedule would satisfy course requirements for a student interested in deepening their expertise in Machine Learning area of concentration.\n\nFall 1\tSpring 1\tSummer\tFall 2\tSpring 2\nSearch Engines\n\nAlgorithms for NLP\n-----\nSummer\n\nFall 2\n\nMachine Learning\n\nSearch Engines\n\nDesign and Engineering of Intelligent Systems\\ Directed Study\n\nLanguage and Statistics\n\nNatural Language Processing\n\nQuestion Answering\n\nDirected Study\n\nMIIS Capstone Planning Seminar\n\nInternship\n\nMachine Learning for Text Mining\n\nMIIS Capstone Project\n\n \n\nExample Course of Study #2\n\nThis schedule would satisfy course requirements for a student interested in voice-based computer applications.\n\nFall 1\n\nSpring\n\nSummer\n\nFall 2\n\nMachine Learning\n\nAlgorithms for NLP\n\nSpeech Recognition and Understanding\n\nDirected Study\n\nApplied Machine Learning\n\nCompetitive Engineering\n-----\n<start course description for 11-696 MIIS Capstone Planning Seminar>\nSemester: Fall 2023 (aka F23)\nCourse Description: The MIIS Capstone Planning Seminar prepares students to complete the MIIS Capstone Project in the following semester.  Students are organized into teams that will work together to complete the capstone project.  They define project goals, requirements, success metrics, and deliverables; and they identify and acquires data, software, and other resources required for successful completion of the project. The planning seminar must be completed in the semester prior to taking the capstone project.\n-----\n\n### Response ###\n\nUser: Who taught the course \"MIIS Directed Study\" in fall 2023?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Shinji Watanabe",
    "index":29,
    "Q":"Who was the instructor for \"Speech Recognition and Understanding\" in fall 2023?",
    "A":"Shinji Watanabe",
    "category":"courses",
    "filepath":"..\/annotations\/karina-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 18-781 Speech Recognition and Understanding.txt"
        },
        "page_content":"<start course metadata for 18-781 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)\nCourse Name: Speech Recognition and Understanding\nCourse Number: 18-781\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Shinji Watanabe\nRooms: GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-781 Speech Recognition and Understanding>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-751 Speech Recognition and Understanding.txt"
        },
        "page_content":"<start course metadata for 11-751 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)\nCourse Name: Speech Recognition and Understanding\nCourse Number: 11-751\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Shinji Watanabe\nRooms: GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-751 Speech Recognition and Understanding>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 18-781 Speech Recognition and Understanding.txt"
        },
        "page_content":"<start course description for 18-781 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-751 Speech Recognition and Understanding.txt"
        },
        "page_content":"<start course description for 11-751 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-753 Advanced Laboratory in Speech Recognition.txt"
        },
        "page_content":"<start course metadata for 11-753 Advanced Laboratory in Speech Recognition>\nSemester: Spring 2024 (aka S24)\nCourse Name: Advanced Laboratory in Speech Recognition\nCourse Number: 11-753\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-753 Advanced Laboratory in Speech Recognition>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 18-781 Speech Recognition and Understanding.txt"
        },
        "page_content":"<\/end course description for 18-781 Speech Recognition and Understanding>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-751 Speech Recognition and Understanding.txt"
        },
        "page_content":"<\/end course description for 11-751 Speech Recognition and Understanding>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-753 Advanced Laboratory in Speech Recognition.txt"
        },
        "page_content":"<start course description for 11-753 Advanced Laboratory in Speech Recognition>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 54-103 Speech I.txt"
        },
        "page_content":"<start course metadata for 54-103 Speech I>\nSemester: Fall 2023 (aka F23)\nCourse Name: Speech I\nCourse Number: 54-103\nDepartment: Drama\nNumber of Units: 4\nPrerequisites: None\nInstructors: Gary Logan\nRooms: PCA A41\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 54-103 Speech I>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 54-203 Voice and Speech II.txt"
        },
        "page_content":"<start course metadata for 54-203 Voice and Speech II>\nSemester: Fall 2023 (aka F23)\nCourse Name: Voice and Speech II\nCourse Number: 54-203\nDepartment: Drama\nNumber of Units: 4\nPrerequisites: 54-103 and 54-104\nInstructors: Gary Logan\nRooms: PCA A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 54-203 Voice and Speech II>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 18-781 Speech Recognition and Understanding.txt"
        },
        "page_content":"<start course metadata for 18-781 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)\nCourse Name: Speech Recognition and Understanding\nCourse Number: 18-781\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Shinji Watanabe\nRooms: GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-781 Speech Recognition and Understanding>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-751 Speech Recognition and Understanding.txt"
        },
        "page_content":"<start course metadata for 11-751 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)\nCourse Name: Speech Recognition and Understanding\nCourse Number: 11-751\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Shinji Watanabe\nRooms: GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-751 Speech Recognition and Understanding>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 18-781 Speech Recognition and Understanding.txt"
        },
        "page_content":"<start course description for 18-781 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-751 Speech Recognition and Understanding.txt"
        },
        "page_content":"<start course description for 11-751 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-753 Advanced Laboratory in Speech Recognition.txt"
        },
        "page_content":"<start course metadata for 11-753 Advanced Laboratory in Speech Recognition>\nSemester: Spring 2024 (aka S24)\nCourse Name: Advanced Laboratory in Speech Recognition\nCourse Number: 11-753\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-753 Advanced Laboratory in Speech Recognition>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 18-781 Speech Recognition and Understanding.txt"
        },
        "page_content":"<\/end course description for 18-781 Speech Recognition and Understanding>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-751 Speech Recognition and Understanding.txt"
        },
        "page_content":"<\/end course description for 11-751 Speech Recognition and Understanding>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-753 Advanced Laboratory in Speech Recognition.txt"
        },
        "page_content":"<start course description for 11-753 Advanced Laboratory in Speech Recognition>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 54-103 Speech I.txt"
        },
        "page_content":"<start course metadata for 54-103 Speech I>\nSemester: Fall 2023 (aka F23)\nCourse Name: Speech I\nCourse Number: 54-103\nDepartment: Drama\nNumber of Units: 4\nPrerequisites: None\nInstructors: Gary Logan\nRooms: PCA A41\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 54-103 Speech I>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 54-203 Voice and Speech II.txt"
        },
        "page_content":"<start course metadata for 54-203 Voice and Speech II>\nSemester: Fall 2023 (aka F23)\nCourse Name: Voice and Speech II\nCourse Number: 54-203\nDepartment: Drama\nNumber of Units: 4\nPrerequisites: 54-103 and 54-104\nInstructors: Gary Logan\nRooms: PCA A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 54-203 Voice and Speech II>",
        "type":"Document"
      }
    ],
    "model_output":"\nThe instructor for \"Speech Recognition and Understanding\" in fall 2023 was Shinji Watanabe.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who was the instructor for \"Speech Recognition and Understanding\" in fall 2023?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n<start course metadata for 18-781 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)\nCourse Name: Speech Recognition and Understanding\nCourse Number: 18-781\nDepartment: Electrical & Computer Engineering\nNumber of Units: 12\nPrerequisites: None\nInstructors: Shinji Watanabe\nRooms: GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 18-781 Speech Recognition and Understanding>\n-----\n<start course metadata for 11-751 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)\nCourse Name: Speech Recognition and Understanding\nCourse Number: 11-751\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Shinji Watanabe\nRooms: GHC 4307\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-751 Speech Recognition and Understanding>\n-----\n<start course description for 18-781 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)\n-----\n<start course description for 11-751 Speech Recognition and Understanding>\nSemester: Fall 2023 (aka F23)\n-----\n<start course metadata for 11-753 Advanced Laboratory in Speech Recognition>\nSemester: Spring 2024 (aka S24)\nCourse Name: Advanced Laboratory in Speech Recognition\nCourse Number: 11-753\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-753 Advanced Laboratory in Speech Recognition>\n-----\n<\/end course description for 18-781 Speech Recognition and Understanding>\n-----\n<\/end course description for 11-751 Speech Recognition and Understanding>\n-----\n<start course description for 11-753 Advanced Laboratory in Speech Recognition>\nSemester: Spring 2024 (aka S24)\n-----\n<start course metadata for 54-103 Speech I>\nSemester: Fall 2023 (aka F23)\nCourse Name: Speech I\nCourse Number: 54-103\nDepartment: Drama\nNumber of Units: 4\nPrerequisites: None\nInstructors: Gary Logan\nRooms: PCA A41\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 54-103 Speech I>\n-----\n<start course metadata for 54-203 Voice and Speech II>\nSemester: Fall 2023 (aka F23)\nCourse Name: Voice and Speech II\nCourse Number: 54-203\nDepartment: Drama\nNumber of Units: 4\nPrerequisites: 54-103 and 54-104\nInstructors: Gary Logan\nRooms: PCA A35\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 54-203 Voice and Speech II>\n-----\n\n### Response ###\n\nUser: Who was the instructor for \"Speech Recognition and Understanding\" in fall 2023?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.4666666667,
    "recall":0.6363636364,
    "precision":0.3684210526,
    "A_hat":"A bushbar is a structure attached to a buggy that a person pushes to propel the buggy forward. It is also known as a pushbar.",
    "index":0,
    "Q":"What is a bushbar on a buggy?",
    "A":"It's a structure attached to a buggy that allows a human to push the buggy",
    "category":"history",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Driver: Person who travels with a buggy and controls the vehicles via steering and braking systems.\n\nPushbar: Structure attached to a buggy that a person pushes to propel that buggy forward.\n\nPusher: Person who propels a buggy via a pushbar along one of the five hills of the buggy course.\n\nShell: Entire outer structure or covering of a buggy that determines that buggy\u2019s aerodynamic characteristics.\n\nTransition: Procedure whereby one pusher finishes pushing a buggy and the next pusher in sequence starts to push that same buggy.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Chute: A section of the freeroll portion of the buggy course (near the southwestern end of Frew Street at its intersection with Schenley Drive) where buggies make the sharp righthand turn from Schenley Drive onto Frew Street.\n\nChute Flagger: Team member who provides a signal for buggy drivers to know when to start the right-hand turn from Schenley Drive onto Frew Street.\n\nDriver: Person who travels with a buggy and controls the vehicles via steering and braking systems.\n\nPushbar: Structure attached to a buggy that a person pushes to propel that buggy forward.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"The Machine\n\nThe basics of a buggy are straightforward, but teams are often secretive in how they build the machines, in particular the way they brake, steer and what types of wheels are used.\n\nEach has a body, pushbar for runners to move the machine up the hills, wheels, a safety harness and driving and braking mechanisms. Some also include fairings, a type of housing around the wheels that help reduce drag, make the vehicle quieter and just looks cool.\n\nFairings have been a key feature for the Fringe team in recent years, which is celebrating its 50th anniversary of Buggy.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Depending on Friday and Saturday\u2019s conditions, most heats may run just two lanes instead of three. But still, despite some of the challenges, Chen said she wouldn\u2019t miss it.\n\n\u201cBeing a driver is really fun,\u201d Chen said. \u201cI love going fast and going around the course.\u201d\n\nSweepstakes Slang\n\nBuggy: Vehicle being raced and also a nickname for the competition.\n\nChute: A section of the freeroll portion of the buggy course (near the southwestern end of Frew Street at its intersection with Schenley Drive) where buggies make the sharp righthand turn from Schenley Drive onto Frew Street.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"This year\u2019s buggy names will be under wraps until Thursday, when the Buggy Showcase will take place from noon to 2 p.m. in Weigand Gymnasium in the Cohon University Center. It\u2019s one of the few times spectators can see buggies up close.\n\nDave Singh explains how Fringe builds its buggies. Each team keeps its actual processes a secret, but each buggy has certain features such as a body, pushbar, wheels and driving and braking mechanisms. Behind Singh are other buggies built by Fringe.\n\nBehind the Wheel",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Fringe vehicles often are named with the letter \u201cB,\u201d like Boson, Blueshift, Bissa and Bumper. Other teams, such as Apex, often use names that connotate fire, while the SDC (Student Dormitory Committee) team, uses names such as Vice, Bane, Avarice and Malice.\n\nThis year\u2019s buggy names will be under wraps until Thursday, when the Buggy Showcase will take place from noon to 2 p.m. in Weigand Gymnasium in the Cohon University Center. It\u2019s one of the few times spectators can see buggies up close.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Buggy Races Keep Rolling at Carnegie Mellon\n\nIn its 99th year, the tradition is a Spring Carnival treat\n\nBy Heidi Opdyke Email\n\nMedia Inquiries\n\nSweepstakes, also known as the Buggy Races, has come a long way at Carnegie Mellon University. The slick, torpedo-like vessels carrying drivers with nerves of steel are a far cry from the two-man teams that once changed places halfway through a race and rode in everything from rain barrels with bicycle wheels to three-wheeled ash cans 99 years ago.\n\nToday, it takes six people to maneuver the .84 -mile course around Schenley Park\u2019s Flagstaff Hill.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"An mural celebrating Buggy can be found in CMU\u2019s Stever House. The artwork is part of a larger installation showcasing Sweepstakes and its traditions.\n\nMembers of Fringe, celebrating their 50th year of Buggy racing, allowed a rare visit into its shop for a behind-the-scenes tour.\n\nThis year Fringe is planning to roll four different vehicles, built and maintained in the Fringe workshop in the basement of the East Campus Garage, known as the \u201cFroom.\u201d",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Fairings have been a key feature for the Fringe team in recent years, which is celebrating its 50th anniversary of Buggy.\n\n\u201cWe have a reputation of being the quietest on the course,\u201d said Diya Nuxoll, who wrapped up her bachelor\u2019s degree in mechanical engineering in December and is working on an advanced studies master\u2019s degree in design and manufacturing. Nuxoll leads the Fringe team as one of two head mechanics.\n\nAn mural celebrating Buggy can be found in CMU\u2019s Stever House. The artwork is part of a larger installation showcasing Sweepstakes and its traditions.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"\u201cOur team\u2019s philosophy is to teach everyone how to do everything,\u201d Girdhar said. \u201cBut I came to CMU wanting to drive. I wanted to drive so badly.\u201d\n\nAmy Chen demonstrates how a driver is positioned inside of Boson, a Fringe buggy built in 2016.\n\nSafety is a top priority for teams. All drivers are required to have five pieces of safety gear: mouth guard, goggles, a harness that includes three points of contact to the body of the buggy, gloves and a helmet. And during practice runs and races, flaggers man the course to let drivers know if it\u2019s safe to proceed.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Driver: Person who travels with a buggy and controls the vehicles via steering and braking systems.\n\nPushbar: Structure attached to a buggy that a person pushes to propel that buggy forward.\n\nPusher: Person who propels a buggy via a pushbar along one of the five hills of the buggy course.\n\nShell: Entire outer structure or covering of a buggy that determines that buggy\u2019s aerodynamic characteristics.\n\nTransition: Procedure whereby one pusher finishes pushing a buggy and the next pusher in sequence starts to push that same buggy.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Chute: A section of the freeroll portion of the buggy course (near the southwestern end of Frew Street at its intersection with Schenley Drive) where buggies make the sharp righthand turn from Schenley Drive onto Frew Street.\n\nChute Flagger: Team member who provides a signal for buggy drivers to know when to start the right-hand turn from Schenley Drive onto Frew Street.\n\nDriver: Person who travels with a buggy and controls the vehicles via steering and braking systems.\n\nPushbar: Structure attached to a buggy that a person pushes to propel that buggy forward.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"The Machine\n\nThe basics of a buggy are straightforward, but teams are often secretive in how they build the machines, in particular the way they brake, steer and what types of wheels are used.\n\nEach has a body, pushbar for runners to move the machine up the hills, wheels, a safety harness and driving and braking mechanisms. Some also include fairings, a type of housing around the wheels that help reduce drag, make the vehicle quieter and just looks cool.\n\nFairings have been a key feature for the Fringe team in recent years, which is celebrating its 50th anniversary of Buggy.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Depending on Friday and Saturday\u2019s conditions, most heats may run just two lanes instead of three. But still, despite some of the challenges, Chen said she wouldn\u2019t miss it.\n\n\u201cBeing a driver is really fun,\u201d Chen said. \u201cI love going fast and going around the course.\u201d\n\nSweepstakes Slang\n\nBuggy: Vehicle being raced and also a nickname for the competition.\n\nChute: A section of the freeroll portion of the buggy course (near the southwestern end of Frew Street at its intersection with Schenley Drive) where buggies make the sharp righthand turn from Schenley Drive onto Frew Street.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"This year\u2019s buggy names will be under wraps until Thursday, when the Buggy Showcase will take place from noon to 2 p.m. in Weigand Gymnasium in the Cohon University Center. It\u2019s one of the few times spectators can see buggies up close.\n\nDave Singh explains how Fringe builds its buggies. Each team keeps its actual processes a secret, but each buggy has certain features such as a body, pushbar, wheels and driving and braking mechanisms. Behind Singh are other buggies built by Fringe.\n\nBehind the Wheel",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Fringe vehicles often are named with the letter \u201cB,\u201d like Boson, Blueshift, Bissa and Bumper. Other teams, such as Apex, often use names that connotate fire, while the SDC (Student Dormitory Committee) team, uses names such as Vice, Bane, Avarice and Malice.\n\nThis year\u2019s buggy names will be under wraps until Thursday, when the Buggy Showcase will take place from noon to 2 p.m. in Weigand Gymnasium in the Cohon University Center. It\u2019s one of the few times spectators can see buggies up close.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Buggy Races Keep Rolling at Carnegie Mellon\n\nIn its 99th year, the tradition is a Spring Carnival treat\n\nBy Heidi Opdyke Email\n\nMedia Inquiries\n\nSweepstakes, also known as the Buggy Races, has come a long way at Carnegie Mellon University. The slick, torpedo-like vessels carrying drivers with nerves of steel are a far cry from the two-man teams that once changed places halfway through a race and rode in everything from rain barrels with bicycle wheels to three-wheeled ash cans 99 years ago.\n\nToday, it takes six people to maneuver the .84 -mile course around Schenley Park\u2019s Flagstaff Hill.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"An mural celebrating Buggy can be found in CMU\u2019s Stever House. The artwork is part of a larger installation showcasing Sweepstakes and its traditions.\n\nMembers of Fringe, celebrating their 50th year of Buggy racing, allowed a rare visit into its shop for a behind-the-scenes tour.\n\nThis year Fringe is planning to roll four different vehicles, built and maintained in the Fringe workshop in the basement of the East Campus Garage, known as the \u201cFroom.\u201d",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"Fairings have been a key feature for the Fringe team in recent years, which is celebrating its 50th anniversary of Buggy.\n\n\u201cWe have a reputation of being the quietest on the course,\u201d said Diya Nuxoll, who wrapped up her bachelor\u2019s degree in mechanical engineering in December and is working on an advanced studies master\u2019s degree in design and manufacturing. Nuxoll leads the Fringe team as one of two head mechanics.\n\nAn mural celebrating Buggy can be found in CMU\u2019s Stever House. The artwork is part of a larger installation showcasing Sweepstakes and its traditions.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/buggy\/The History of Buggy.txt"
        },
        "page_content":"\u201cOur team\u2019s philosophy is to teach everyone how to do everything,\u201d Girdhar said. \u201cBut I came to CMU wanting to drive. I wanted to drive so badly.\u201d\n\nAmy Chen demonstrates how a driver is positioned inside of Boson, a Fringe buggy built in 2016.\n\nSafety is a top priority for teams. All drivers are required to have five pieces of safety gear: mouth guard, goggles, a harness that includes three points of contact to the body of the buggy, gloves and a helmet. And during practice runs and races, flaggers man the course to let drivers know if it\u2019s safe to proceed.",
        "type":"Document"
      }
    ],
    "model_output":"\nA bushbar is a structure attached to a buggy that a person pushes to propel the buggy forward. It is also known as a pushbar.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"What is a bushbar on a buggy?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nDriver: Person who travels with a buggy and controls the vehicles via steering and braking systems.\n\nPushbar: Structure attached to a buggy that a person pushes to propel that buggy forward.\n\nPusher: Person who propels a buggy via a pushbar along one of the five hills of the buggy course.\n\nShell: Entire outer structure or covering of a buggy that determines that buggy\u2019s aerodynamic characteristics.\n\nTransition: Procedure whereby one pusher finishes pushing a buggy and the next pusher in sequence starts to push that same buggy.\n-----\nChute: A section of the freeroll portion of the buggy course (near the southwestern end of Frew Street at its intersection with Schenley Drive) where buggies make the sharp righthand turn from Schenley Drive onto Frew Street.\n\nChute Flagger: Team member who provides a signal for buggy drivers to know when to start the right-hand turn from Schenley Drive onto Frew Street.\n\nDriver: Person who travels with a buggy and controls the vehicles via steering and braking systems.\n\nPushbar: Structure attached to a buggy that a person pushes to propel that buggy forward.\n-----\nThe Machine\n\nThe basics of a buggy are straightforward, but teams are often secretive in how they build the machines, in particular the way they brake, steer and what types of wheels are used.\n\nEach has a body, pushbar for runners to move the machine up the hills, wheels, a safety harness and driving and braking mechanisms. Some also include fairings, a type of housing around the wheels that help reduce drag, make the vehicle quieter and just looks cool.\n\nFairings have been a key feature for the Fringe team in recent years, which is celebrating its 50th anniversary of Buggy.\n-----\nDepending on Friday and Saturday\u2019s conditions, most heats may run just two lanes instead of three. But still, despite some of the challenges, Chen said she wouldn\u2019t miss it.\n\n\u201cBeing a driver is really fun,\u201d Chen said. \u201cI love going fast and going around the course.\u201d\n\nSweepstakes Slang\n\nBuggy: Vehicle being raced and also a nickname for the competition.\n\nChute: A section of the freeroll portion of the buggy course (near the southwestern end of Frew Street at its intersection with Schenley Drive) where buggies make the sharp righthand turn from Schenley Drive onto Frew Street.\n-----\nThis year\u2019s buggy names will be under wraps until Thursday, when the Buggy Showcase will take place from noon to 2 p.m. in Weigand Gymnasium in the Cohon University Center. It\u2019s one of the few times spectators can see buggies up close.\n\nDave Singh explains how Fringe builds its buggies. Each team keeps its actual processes a secret, but each buggy has certain features such as a body, pushbar, wheels and driving and braking mechanisms. Behind Singh are other buggies built by Fringe.\n\nBehind the Wheel\n-----\nFringe vehicles often are named with the letter \u201cB,\u201d like Boson, Blueshift, Bissa and Bumper. Other teams, such as Apex, often use names that connotate fire, while the SDC (Student Dormitory Committee) team, uses names such as Vice, Bane, Avarice and Malice.\n\nThis year\u2019s buggy names will be under wraps until Thursday, when the Buggy Showcase will take place from noon to 2 p.m. in Weigand Gymnasium in the Cohon University Center. It\u2019s one of the few times spectators can see buggies up close.\n-----\nBuggy Races Keep Rolling at Carnegie Mellon\n\nIn its 99th year, the tradition is a Spring Carnival treat\n\nBy Heidi Opdyke Email\n\nMedia Inquiries\n\nSweepstakes, also known as the Buggy Races, has come a long way at Carnegie Mellon University. The slick, torpedo-like vessels carrying drivers with nerves of steel are a far cry from the two-man teams that once changed places halfway through a race and rode in everything from rain barrels with bicycle wheels to three-wheeled ash cans 99 years ago.\n\nToday, it takes six people to maneuver the .84 -mile course around Schenley Park\u2019s Flagstaff Hill.\n-----\nAn mural celebrating Buggy can be found in CMU\u2019s Stever House. The artwork is part of a larger installation showcasing Sweepstakes and its traditions.\n\nMembers of Fringe, celebrating their 50th year of Buggy racing, allowed a rare visit into its shop for a behind-the-scenes tour.\n\nThis year Fringe is planning to roll four different vehicles, built and maintained in the Fringe workshop in the basement of the East Campus Garage, known as the \u201cFroom.\u201d\n-----\nFairings have been a key feature for the Fringe team in recent years, which is celebrating its 50th anniversary of Buggy.\n\n\u201cWe have a reputation of being the quietest on the course,\u201d said Diya Nuxoll, who wrapped up her bachelor\u2019s degree in mechanical engineering in December and is working on an advanced studies master\u2019s degree in design and manufacturing. Nuxoll leads the Fringe team as one of two head mechanics.\n\nAn mural celebrating Buggy can be found in CMU\u2019s Stever House. The artwork is part of a larger installation showcasing Sweepstakes and its traditions.\n-----\n\u201cOur team\u2019s philosophy is to teach everyone how to do everything,\u201d Girdhar said. \u201cBut I came to CMU wanting to drive. I wanted to drive so badly.\u201d\n\nAmy Chen demonstrates how a driver is positioned inside of Boson, a Fringe buggy built in 2016.\n\nSafety is a top priority for teams. All drivers are required to have five pieces of safety gear: mouth guard, goggles, a harness that includes three points of contact to the body of the buggy, gloves and a helmet. And during practice runs and races, flaggers man the course to let drivers know if it\u2019s safe to proceed.\n-----\n\n### Response ###\n\nUser: What is a bushbar on a buggy?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"1967",
    "index":1,
    "Q":"When did Carnegie Institute of Technology merge with Mellon Institute?",
    "A":"1967",
    "category":"history",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"In 1967, Carnegie Tech merged with the Mellon Institute, a science research center founded by the Mellon family of Pittsburgh, to become known as Carnegie Mellon University. The merger built upon a long history of support from the Mellons.\nIt allowed Carnegie Mellon to establish the last of its current pillars: the\u00a0Mellon College of Science\u00a0and the College of Humanities and Social Sciences, now known as\u00a0Marianna Brown Dietrich College of Humanities and Social Sciences.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"government through the Defense Department\u2019s Advanced Research Projects Agency, or DARPA. In 1967, Carnegie Institute of Technology merged with the nearby Mellon Institute of Industrial Research to form Carnegie-Mellon University. The Department of Computer Science moved into the newly created Mellon Institute of Science, later renamed Mellon College of Science, or MCS. Future SCS dean Raj Reddy joined the CSD in 1969 after three years as an assistant professor at Stanford. He brought with him research in speech, language and computer vision. But in 1970 and 1971, the new Computer Science Department faced its first crisis, as half of its",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Tartan and CMU Facts.txt"
        },
        "page_content":"From Tartan and CMU Facts:\nQ: Who founded Carnegie Mellon University?\nA: Carnegie Technical Schools was founded in 1900 by Andrew Carnegie. Twelve years later it became known as the Carnegie Institute of Technology. In 1967, the school merged with Mellon Institute and became what is known today as Carnegie Mellon University.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"It allowed Carnegie Mellon to establish the last of its current pillars: the\u00a0Mellon College of Science\u00a0and the College of Humanities and Social Sciences, now known as\u00a0Marianna Brown Dietrich College of Humanities and Social Sciences.\nIn 2017, Carnegie Mellon celebrated the 50th anniversary of the Carnegie Tech-Mellon Institute merger, revisiting the shared vision of the founders and recognizing the impact it has had, and will continue to have, in the world of higher education, research and discovery.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"science Ph.D.s were graduates of this program.Computer Science Department establishedIn 1965, Carnegie Tech established its Computer Science Department, or CSD, with a $5 million grant from the R.K. Mellon Foundation. Perlis was the first department head. There were no undergraduates; only Ph.D. students were admitted, and the department\u2019s focus was on research, much of it funded by the federal government through the Defense Department\u2019s Advanced Research Projects Agency, or DARPA. In 1967, Carnegie Institute of Technology merged with the nearby Mellon Institute of Industrial Research to form Carnegie-Mellon University. The Department of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"For an expanded history of the School of Computer Science and its predecessors at CMU, read \"Institutional Memories\" in the Summer 2014 issue of The Link magazine.In 2014, the School of Computer Science celebrated its 25th year as a stand-alone college within Carnegie Mellon University. It was arguably the first college devoted solely to computer science in the United States, and a model for others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"science Ph.D. program createdIn 1961, the Computation Center and its newest computer, a Bendix G-20, were moved to recently completed Scaife Hall. That same year, Carnegie Tech created an interdisciplinary Ph.D. program called Systems and Communications Sciences, combining elements of computer science, mathematics, psychology, business and electrical engineering. The university\u2019s first computer science Ph.D.s were graduates of this program.Computer Science Department establishedIn 1965, Carnegie Tech established its Computer Science Department, or CSD, with a $5 million grant from the R.K. Mellon Foundation. Perlis was the first department",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"that would reach virtually every room on campus, along with a GUI-based computing environment, and providing networked PCs or workstations for 7,000 students, faculty members and employees. Called the Andrew Project, it turned Carnegie Mellon into the best-connected, most-wired university in the world\u2014a process Newell called \u201cgreening up the campus with computer science.\u201d CMU also became home to a new Software Engineering Institute, funded by the Defense Department, to study computer security and develop best practices in the design of operating systems. Between 1982 and 1985, the amount of sponsored research in the Computer Science",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 84-198 Research Training_ Carnegie Mellon Institute for Security and Technology.txt"
        },
        "page_content":"<start course description for 84-198 Research Training: Carnegie Mellon Institute for Security and Technology>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"In 1967, Carnegie Tech merged with the Mellon Institute, a science research center founded by the Mellon family of Pittsburgh, to become known as Carnegie Mellon University. The merger built upon a long history of support from the Mellons.\nIt allowed Carnegie Mellon to establish the last of its current pillars: the\u00a0Mellon College of Science\u00a0and the College of Humanities and Social Sciences, now known as\u00a0Marianna Brown Dietrich College of Humanities and Social Sciences.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"government through the Defense Department\u2019s Advanced Research Projects Agency, or DARPA. In 1967, Carnegie Institute of Technology merged with the nearby Mellon Institute of Industrial Research to form Carnegie-Mellon University. The Department of Computer Science moved into the newly created Mellon Institute of Science, later renamed Mellon College of Science, or MCS. Future SCS dean Raj Reddy joined the CSD in 1969 after three years as an assistant professor at Stanford. He brought with him research in speech, language and computer vision. But in 1970 and 1971, the new Computer Science Department faced its first crisis, as half of its",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Tartan and CMU Facts.txt"
        },
        "page_content":"From Tartan and CMU Facts:\nQ: Who founded Carnegie Mellon University?\nA: Carnegie Technical Schools was founded in 1900 by Andrew Carnegie. Twelve years later it became known as the Carnegie Institute of Technology. In 1967, the school merged with Mellon Institute and became what is known today as Carnegie Mellon University.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"It allowed Carnegie Mellon to establish the last of its current pillars: the\u00a0Mellon College of Science\u00a0and the College of Humanities and Social Sciences, now known as\u00a0Marianna Brown Dietrich College of Humanities and Social Sciences.\nIn 2017, Carnegie Mellon celebrated the 50th anniversary of the Carnegie Tech-Mellon Institute merger, revisiting the shared vision of the founders and recognizing the impact it has had, and will continue to have, in the world of higher education, research and discovery.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"science Ph.D.s were graduates of this program.Computer Science Department establishedIn 1965, Carnegie Tech established its Computer Science Department, or CSD, with a $5 million grant from the R.K. Mellon Foundation. Perlis was the first department head. There were no undergraduates; only Ph.D. students were admitted, and the department\u2019s focus was on research, much of it funded by the federal government through the Defense Department\u2019s Advanced Research Projects Agency, or DARPA. In 1967, Carnegie Institute of Technology merged with the nearby Mellon Institute of Industrial Research to form Carnegie-Mellon University. The Department of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"For an expanded history of the School of Computer Science and its predecessors at CMU, read \"Institutional Memories\" in the Summer 2014 issue of The Link magazine.In 2014, the School of Computer Science celebrated its 25th year as a stand-alone college within Carnegie Mellon University. It was arguably the first college devoted solely to computer science in the United States, and a model for others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"science Ph.D. program createdIn 1961, the Computation Center and its newest computer, a Bendix G-20, were moved to recently completed Scaife Hall. That same year, Carnegie Tech created an interdisciplinary Ph.D. program called Systems and Communications Sciences, combining elements of computer science, mathematics, psychology, business and electrical engineering. The university\u2019s first computer science Ph.D.s were graduates of this program.Computer Science Department establishedIn 1965, Carnegie Tech established its Computer Science Department, or CSD, with a $5 million grant from the R.K. Mellon Foundation. Perlis was the first department",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"that would reach virtually every room on campus, along with a GUI-based computing environment, and providing networked PCs or workstations for 7,000 students, faculty members and employees. Called the Andrew Project, it turned Carnegie Mellon into the best-connected, most-wired university in the world\u2014a process Newell called \u201cgreening up the campus with computer science.\u201d CMU also became home to a new Software Engineering Institute, funded by the Defense Department, to study computer security and develop best practices in the design of operating systems. Between 1982 and 1985, the amount of sponsored research in the Computer Science",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 84-198 Research Training_ Carnegie Mellon Institute for Security and Technology.txt"
        },
        "page_content":"<start course description for 84-198 Research Training: Carnegie Mellon Institute for Security and Technology>\nSemester: Spring 2024 (aka S24)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of",
        "type":"Document"
      }
    ],
    "model_output":"Carnegie Institute of Technology merged with Mellon Institute in 1967.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"When did Carnegie Institute of Technology merge with Mellon Institute?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nIn 1967, Carnegie Tech merged with the Mellon Institute, a science research center founded by the Mellon family of Pittsburgh, to become known as Carnegie Mellon University. The merger built upon a long history of support from the Mellons.\nIt allowed Carnegie Mellon to establish the last of its current pillars: the\u00a0Mellon College of Science\u00a0and the College of Humanities and Social Sciences, now known as\u00a0Marianna Brown Dietrich College of Humanities and Social Sciences.\n-----\ngovernment through the Defense Department\u2019s Advanced Research Projects Agency, or DARPA. In 1967, Carnegie Institute of Technology merged with the nearby Mellon Institute of Industrial Research to form Carnegie-Mellon University. The Department of Computer Science moved into the newly created Mellon Institute of Science, later renamed Mellon College of Science, or MCS. Future SCS dean Raj Reddy joined the CSD in 1969 after three years as an assistant professor at Stanford. He brought with him research in speech, language and computer vision. But in 1970 and 1971, the new Computer Science Department faced its first crisis, as half of its\n-----\nFrom Tartan and CMU Facts:\nQ: Who founded Carnegie Mellon University?\nA: Carnegie Technical Schools was founded in 1900 by Andrew Carnegie. Twelve years later it became known as the Carnegie Institute of Technology. In 1967, the school merged with Mellon Institute and became what is known today as Carnegie Mellon University.\n-----\nIt allowed Carnegie Mellon to establish the last of its current pillars: the\u00a0Mellon College of Science\u00a0and the College of Humanities and Social Sciences, now known as\u00a0Marianna Brown Dietrich College of Humanities and Social Sciences.\nIn 2017, Carnegie Mellon celebrated the 50th anniversary of the Carnegie Tech-Mellon Institute merger, revisiting the shared vision of the founders and recognizing the impact it has had, and will continue to have, in the world of higher education, research and discovery.\n-----\nscience Ph.D.s were graduates of this program.Computer Science Department establishedIn 1965, Carnegie Tech established its Computer Science Department, or CSD, with a $5 million grant from the R.K. Mellon Foundation. Perlis was the first department head. There were no undergraduates; only Ph.D. students were admitted, and the department\u2019s focus was on research, much of it funded by the federal government through the Defense Department\u2019s Advanced Research Projects Agency, or DARPA. In 1967, Carnegie Institute of Technology merged with the nearby Mellon Institute of Industrial Research to form Carnegie-Mellon University. The Department of\n-----\nFor an expanded history of the School of Computer Science and its predecessors at CMU, read \"Institutional Memories\" in the Summer 2014 issue of The Link magazine.In 2014, the School of Computer Science celebrated its 25th year as a stand-alone college within Carnegie Mellon University. It was arguably the first college devoted solely to computer science in the United States, and a model for others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing\n-----\nscience Ph.D. program createdIn 1961, the Computation Center and its newest computer, a Bendix G-20, were moved to recently completed Scaife Hall. That same year, Carnegie Tech created an interdisciplinary Ph.D. program called Systems and Communications Sciences, combining elements of computer science, mathematics, psychology, business and electrical engineering. The university\u2019s first computer science Ph.D.s were graduates of this program.Computer Science Department establishedIn 1965, Carnegie Tech established its Computer Science Department, or CSD, with a $5 million grant from the R.K. Mellon Foundation. Perlis was the first department\n-----\nthat would reach virtually every room on campus, along with a GUI-based computing environment, and providing networked PCs or workstations for 7,000 students, faculty members and employees. Called the Andrew Project, it turned Carnegie Mellon into the best-connected, most-wired university in the world\u2014a process Newell called \u201cgreening up the campus with computer science.\u201d CMU also became home to a new Software Engineering Institute, funded by the Defense Department, to study computer security and develop best practices in the design of operating systems. Between 1982 and 1985, the amount of sponsored research in the Computer Science\n-----\n<start course description for 84-198 Research Training: Carnegie Mellon Institute for Security and Technology>\nSemester: Spring 2024 (aka S24)\n-----\nothers that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of\n-----\n\n### Response ###\n\nUser: When did Carnegie Institute of Technology merge with Mellon Institute?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.6666666667,
    "recall":0.5,
    "precision":1.0,
    "A_hat":"Scotland",
    "index":2,
    "Q":"Where was CMU's founder born?",
    "A":"Dunfermline, Scotland",
    "category":"history",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"Carnegie Mellon University has been a birthplace \nof innovation since its founding in 1900.\nToday, CMU is a global leader bringing groundbreaking \nideas to market and creating successful startup \nbusinesses. Our award-winning faculty are renowned for \nworking closely with students to solve major scientific, \ntechnological and societal challenges. We put a strong \nemphasis on creating things \u2014 from art to robots. We \nhave become a model for economic development in \nforming partnerships with companies such as Uber, \nGoogle and Disney. Our students are recruited by some \nof the world\u2019s most innovative companies.\nMANAGEMENT \nINFORMATION \nSYSTEMS",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"History -     CMU - Carnegie Mellon University\nCarnegie Mellon University\n Andrew Carnegie \n\nA self-educated \"working boy\" who loved books, Andrew Carnegie emigrated from Scotland in 1848 and settled in Pittsburgh, Pa. Attending night school and borrowing books, Carnegie went from factory worker in a textile mill to successful entrepreneur and industrialist. He rose to prominence by founding what became the world's largest steel producing company by the end of the 19th century.\n\n\n \n\n Carnegie Technical Schools",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"for cybersecurity , providing \nsupport to more than 110 \ncenters around the world \nThe world\u2019s first university \nrobotics department ,  \nfounded in 1979\nAlumnus Andy Warhol   \n(CFA1949), pop artist pioneer  \nand cultural icon\nOne of only 29 universities  \ninvited to be a member of the \nWorld Economic Forum\u2019s \nGlobal University  \nLeaders Forum\nCMU.EDU\nECONOMIC IMPACT\n\u2022 Attracting major companies  \u2014  \nincluding Google, Intel, Uber and GE \u2014  \nto locate operations and create new  \njobs in Pittsburgh\n\u2022 To date, the CMU community has \nlaunched more than 400 startups  \nand created more than 152 spinoff \ncompanies .",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/CMU Quick Facts.txt"
        },
        "page_content":"From Tartan and CMU Facts:\nName of School:\u00a0Carnegie Mellon University\nCity\/Zip:\u00a0Pittsburgh, PA 15213\nFounded:\u00a01900\nEnrollment (undergrad):\u00a06,982- Fall 2021\nEnrollment (graduate and doctoral):\u00a07,062 - Fall 2021\nAlumni:\u00a0102,577\nNickname:\u00a0Tartans\nMascot:\u00a0Scottie Dog\nSchool Colors:\u00a0Cardinal and Gray\nFootball Stadium and Track and Field:\u00a0Gesling Stadium\nCapacity:\u00a03,500\nSurface:\u00a0FieldTurf\nBasketball\/Volleyball Gym:\u00a0Wiegand Gymnasium\nCapacity: 500\nSoccer Stadium:\u00a0CMU Soccer Field\nCapacity:\u00a0250\nSurface:\u00a0FieldTurf\nAffiliation:\u00a0NCAA Division III\nConference:\u00a0University Athletic Association | Presidents' Athletic Conference (Football Only)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Tartan and CMU Facts.txt"
        },
        "page_content":"From Tartan and CMU Facts:\nQ: Who founded Carnegie Mellon University?\nA: Carnegie Technical Schools was founded in 1900 by Andrew Carnegie. Twelve years later it became known as the Carnegie Institute of Technology. In 1967, the school merged with Mellon Institute and became what is known today as Carnegie Mellon University.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"in 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was \nawarded to Mao Yisheng, father  \nof Chinese bridge construction. \nDuolingo , invented by professor  \nLuis von Ahn (CS 2003, 2005), had  \n10 million downloads in 12 months \nand was named Apple\u2019s 2013 app  \nof the year.\n:-)\nLEADERSHIP\nFarnam Jahanian   \nPresident\nDavid Coulter  \nChair, Board of Trustees\nJames H. Garrett Jr.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"For an expanded history of the School of Computer Science and its predecessors at CMU, read \"Institutional Memories\" in the Summer 2014 issue of The Link magazine.In 2014, the School of Computer Science celebrated its 25th year as a stand-alone college within Carnegie Mellon University. It was arguably the first college devoted solely to computer science in the United States, and a model for others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"Science would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3, 1989.Undergraduate degrees beginFor several years, undergraduates interested in computer science pursued an \u201capplied math\/CS\u201d bachelor\u2019s degree offered by the Mathematics Department. CSD professor Mary Shaw (CS\u201972) led CMU\u2019s first effort to design an undergraduate curriculum solely in computer science. She and her colleagues were guided by the Carnegie Plan\u2014guidelines established in 1938 under",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/About Scotty, CMU's mascot.txt"
        },
        "page_content":"About Scotty, CMU's mascot:\nThe Scottish terrier has long been a familiar figure around Carnegie Mellon's campus. For years students have suited up in an unofficial Scottish terrier costume to excite the fans at athletic events. But the relationship between the Scottish terrier breed and Carnegie Mellon far precedes anybody doing somersaults in a dog costume. Andrew Carnegie, founder of the university, kept a Scottish terrier as his pet.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"Carnegie Mellon University has been a birthplace \nof innovation since its founding in 1900.\nToday, CMU is a global leader bringing groundbreaking \nideas to market and creating successful startup \nbusinesses. Our award-winning faculty are renowned for \nworking closely with students to solve major scientific, \ntechnological and societal challenges. We put a strong \nemphasis on creating things \u2014 from art to robots. We \nhave become a model for economic development in \nforming partnerships with companies such as Uber, \nGoogle and Disney. Our students are recruited by some \nof the world\u2019s most innovative companies.\nMANAGEMENT \nINFORMATION \nSYSTEMS",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"History -     CMU - Carnegie Mellon University\nCarnegie Mellon University\n Andrew Carnegie \n\nA self-educated \"working boy\" who loved books, Andrew Carnegie emigrated from Scotland in 1848 and settled in Pittsburgh, Pa. Attending night school and borrowing books, Carnegie went from factory worker in a textile mill to successful entrepreneur and industrialist. He rose to prominence by founding what became the world's largest steel producing company by the end of the 19th century.\n\n\n \n\n Carnegie Technical Schools",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"for cybersecurity , providing \nsupport to more than 110 \ncenters around the world \nThe world\u2019s first university \nrobotics department ,  \nfounded in 1979\nAlumnus Andy Warhol   \n(CFA1949), pop artist pioneer  \nand cultural icon\nOne of only 29 universities  \ninvited to be a member of the \nWorld Economic Forum\u2019s \nGlobal University  \nLeaders Forum\nCMU.EDU\nECONOMIC IMPACT\n\u2022 Attracting major companies  \u2014  \nincluding Google, Intel, Uber and GE \u2014  \nto locate operations and create new  \njobs in Pittsburgh\n\u2022 To date, the CMU community has \nlaunched more than 400 startups  \nand created more than 152 spinoff \ncompanies .",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/CMU Quick Facts.txt"
        },
        "page_content":"From Tartan and CMU Facts:\nName of School:\u00a0Carnegie Mellon University\nCity\/Zip:\u00a0Pittsburgh, PA 15213\nFounded:\u00a01900\nEnrollment (undergrad):\u00a06,982- Fall 2021\nEnrollment (graduate and doctoral):\u00a07,062 - Fall 2021\nAlumni:\u00a0102,577\nNickname:\u00a0Tartans\nMascot:\u00a0Scottie Dog\nSchool Colors:\u00a0Cardinal and Gray\nFootball Stadium and Track and Field:\u00a0Gesling Stadium\nCapacity:\u00a03,500\nSurface:\u00a0FieldTurf\nBasketball\/Volleyball Gym:\u00a0Wiegand Gymnasium\nCapacity: 500\nSoccer Stadium:\u00a0CMU Soccer Field\nCapacity:\u00a0250\nSurface:\u00a0FieldTurf\nAffiliation:\u00a0NCAA Division III\nConference:\u00a0University Athletic Association | Presidents' Athletic Conference (Football Only)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Tartan and CMU Facts.txt"
        },
        "page_content":"From Tartan and CMU Facts:\nQ: Who founded Carnegie Mellon University?\nA: Carnegie Technical Schools was founded in 1900 by Andrew Carnegie. Twelve years later it became known as the Carnegie Institute of Technology. In 1967, the school merged with Mellon Institute and became what is known today as Carnegie Mellon University.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"in 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was \nawarded to Mao Yisheng, father  \nof Chinese bridge construction. \nDuolingo , invented by professor  \nLuis von Ahn (CS 2003, 2005), had  \n10 million downloads in 12 months \nand was named Apple\u2019s 2013 app  \nof the year.\n:-)\nLEADERSHIP\nFarnam Jahanian   \nPresident\nDavid Coulter  \nChair, Board of Trustees\nJames H. Garrett Jr.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"For an expanded history of the School of Computer Science and its predecessors at CMU, read \"Institutional Memories\" in the Summer 2014 issue of The Link magazine.In 2014, the School of Computer Science celebrated its 25th year as a stand-alone college within Carnegie Mellon University. It was arguably the first college devoted solely to computer science in the United States, and a model for others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"Science would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3, 1989.Undergraduate degrees beginFor several years, undergraduates interested in computer science pursued an \u201capplied math\/CS\u201d bachelor\u2019s degree offered by the Mathematics Department. CSD professor Mary Shaw (CS\u201972) led CMU\u2019s first effort to design an undergraduate curriculum solely in computer science. She and her colleagues were guided by the Carnegie Plan\u2014guidelines established in 1938 under",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/About Scotty, CMU's mascot.txt"
        },
        "page_content":"About Scotty, CMU's mascot:\nThe Scottish terrier has long been a familiar figure around Carnegie Mellon's campus. For years students have suited up in an unofficial Scottish terrier costume to excite the fans at athletic events. But the relationship between the Scottish terrier breed and Carnegie Mellon far precedes anybody doing somersaults in a dog costume. Andrew Carnegie, founder of the university, kept a Scottish terrier as his pet.",
        "type":"Document"
      }
    ],
    "model_output":"\nAndrew Carnegie, the founder of Carnegie Mellon University, was born in Scotland in 1835.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Where was CMU's founder born?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nCarnegie Mellon University has been a birthplace \nof innovation since its founding in 1900.\nToday, CMU is a global leader bringing groundbreaking \nideas to market and creating successful startup \nbusinesses. Our award-winning faculty are renowned for \nworking closely with students to solve major scientific, \ntechnological and societal challenges. We put a strong \nemphasis on creating things \u2014 from art to robots. We \nhave become a model for economic development in \nforming partnerships with companies such as Uber, \nGoogle and Disney. Our students are recruited by some \nof the world\u2019s most innovative companies.\nMANAGEMENT \nINFORMATION \nSYSTEMS\n-----\nHistory -     CMU - Carnegie Mellon University\nCarnegie Mellon University\n Andrew Carnegie \n\nA self-educated \"working boy\" who loved books, Andrew Carnegie emigrated from Scotland in 1848 and settled in Pittsburgh, Pa. Attending night school and borrowing books, Carnegie went from factory worker in a textile mill to successful entrepreneur and industrialist. He rose to prominence by founding what became the world's largest steel producing company by the end of the 19th century.\n\n\n \n\n Carnegie Technical Schools\n-----\nfor cybersecurity , providing \nsupport to more than 110 \ncenters around the world \nThe world\u2019s first university \nrobotics department ,  \nfounded in 1979\nAlumnus Andy Warhol   \n(CFA1949), pop artist pioneer  \nand cultural icon\nOne of only 29 universities  \ninvited to be a member of the \nWorld Economic Forum\u2019s \nGlobal University  \nLeaders Forum\nCMU.EDU\nECONOMIC IMPACT\n\u2022 Attracting major companies  \u2014  \nincluding Google, Intel, Uber and GE \u2014  \nto locate operations and create new  \njobs in Pittsburgh\n\u2022 To date, the CMU community has \nlaunched more than 400 startups  \nand created more than 152 spinoff \ncompanies .\n-----\nothers that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of\n-----\nFrom Tartan and CMU Facts:\nName of School:\u00a0Carnegie Mellon University\nCity\/Zip:\u00a0Pittsburgh, PA 15213\nFounded:\u00a01900\nEnrollment (undergrad):\u00a06,982- Fall 2021\nEnrollment (graduate and doctoral):\u00a07,062 - Fall 2021\nAlumni:\u00a0102,577\nNickname:\u00a0Tartans\nMascot:\u00a0Scottie Dog\nSchool Colors:\u00a0Cardinal and Gray\nFootball Stadium and Track and Field:\u00a0Gesling Stadium\nCapacity:\u00a03,500\nSurface:\u00a0FieldTurf\nBasketball\/Volleyball Gym:\u00a0Wiegand Gymnasium\nCapacity: 500\nSoccer Stadium:\u00a0CMU Soccer Field\nCapacity:\u00a0250\nSurface:\u00a0FieldTurf\nAffiliation:\u00a0NCAA Division III\nConference:\u00a0University Athletic Association | Presidents' Athletic Conference (Football Only)\n-----\nFrom Tartan and CMU Facts:\nQ: Who founded Carnegie Mellon University?\nA: Carnegie Technical Schools was founded in 1900 by Andrew Carnegie. Twelve years later it became known as the Carnegie Institute of Technology. In 1967, the school merged with Mellon Institute and became what is known today as Carnegie Mellon University.\n-----\nin 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was \nawarded to Mao Yisheng, father  \nof Chinese bridge construction. \nDuolingo , invented by professor  \nLuis von Ahn (CS 2003, 2005), had  \n10 million downloads in 12 months \nand was named Apple\u2019s 2013 app  \nof the year.\n:-)\nLEADERSHIP\nFarnam Jahanian   \nPresident\nDavid Coulter  \nChair, Board of Trustees\nJames H. Garrett Jr.\n-----\nFor an expanded history of the School of Computer Science and its predecessors at CMU, read \"Institutional Memories\" in the Summer 2014 issue of The Link magazine.In 2014, the School of Computer Science celebrated its 25th year as a stand-alone college within Carnegie Mellon University. It was arguably the first college devoted solely to computer science in the United States, and a model for others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing\n-----\nScience would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3, 1989.Undergraduate degrees beginFor several years, undergraduates interested in computer science pursued an \u201capplied math\/CS\u201d bachelor\u2019s degree offered by the Mathematics Department. CSD professor Mary Shaw (CS\u201972) led CMU\u2019s first effort to design an undergraduate curriculum solely in computer science. She and her colleagues were guided by the Carnegie Plan\u2014guidelines established in 1938 under\n-----\nAbout Scotty, CMU's mascot:\nThe Scottish terrier has long been a familiar figure around Carnegie Mellon's campus. For years students have suited up in an unofficial Scottish terrier costume to excite the fans at athletic events. But the relationship between the Scottish terrier breed and Carnegie Mellon far precedes anybody doing somersaults in a dog costume. Andrew Carnegie, founder of the university, kept a Scottish terrier as his pet.\n-----\n\n### Response ###\n\nUser: Where was CMU's founder born?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"1908",
    "index":3,
    "Q":"When was the CMU Kiltie Band created?",
    "A":"1908",
    "category":"history",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/The Kiltie Band at CMU.txt"
        },
        "page_content":"The Kiltie Band at CMU\n\nThe Kiltie Band began in 1908 with a group of just seven students dedicated to supporting Carnegie Tech football, and today's Kiltie Band continues a tradition of excellence originated over a century ago. The Band took the field for its first official performance on November 25th, 1922, on what would have been Andrew Carnegie's 87th birthday.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Kiltie Band Concert on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Kiltie Band Concert\n\nTitle: Kiltie Band Concert\nDate: April 11, 2024\nTime: 3:30 PM-4:30 PM ET\n\nWhat better way to open Carnival than with the infamous \u201cBand without Pants\u201d? Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Kiltie Band FAQs.txt"
        },
        "page_content":"From Kiltie Band FAQs:\nQ: When is the first rehearsal?  \nA: On the first day of class (Monday) at 5:30 p.m. in the CUC Studio Theater. If you have questions, please email the Direcator at\u00a0jolisar@andrew.cmu.edu.\n\nFrom Kiltie Band FAQs:\nQ: Can I borrow a school instrument?  \nA: There are several Kiltie-owned instruments available for your use. Loans begin at 4:30 p.m. before the first rehearsal.\u00a0  \n\nFrom Kiltie Band FAQs:\nQ: What do they wear under those kilts?  \nA: Join and you\u2019ll find out!",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Kiltie Band FAQs.txt"
        },
        "page_content":"From Kiltie Band FAQs:\nQ: Are there auditions?  \nA: No, any member of the campus community with music experience is able to join the Kiltie Band!  \n\nFrom Kiltie Band FAQs:\nQ: Do I have to memorize music?  \nA: No, the music is changed for every show. You should invest in a good and trusty lyre.  \n\nFrom Kiltie Band FAQs:\nQ: When is the first rehearsal?  \nA: On the first day of class (Monday) at 5:30 p.m. in the CUC Studio Theater. If you have questions, please email the Direcator at\u00a0jolisar@andrew.cmu.edu.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/The Kiltie Band at CMU.txt"
        },
        "page_content":"The Kiltie Band is a campus organization recognized by Student Senate and administered by the Department of Athletics, Physical Education and Recreation. Membership is open to all members of the campus\/community without audition. Participants must do their best to promote the success of the ensemble through attendance, attitude, and dependability.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Kiltie Band Alumni & Student Reception on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Kiltie Band Alumni & Student Reception\n\nTitle: Kiltie Band Alumni & Student Reception\nDate: April 11, 2024\nTime: 4:30 PM-6:30 PM ET\n\nAfter the Kiltie Band Spring Carnival kick-off concert, current and former Kilties are invited for food and fun!Note: Registration required. Walk-ins are welcome if space permits. No event fee. Open to the Kiltie community and guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Kiltie Band FAQs.txt"
        },
        "page_content":"From Kiltie Band FAQs:\nQ: When are rehearsals?  \nA: Football season: Mondays and Thursdays from 5:30 p.m.-7:30 p.m. and Game Day 9:30-11:00a.m. Concert Season: Mondays and Thursdays from 5:30-6:30 p.m.  \nLocation is the CUC Studio Theater.  \n\nFrom Kiltie Band FAQs:\nQ: When are performances?  \nA: The Kiltie Band performs at all home football games, a holiday concert, and two spring concerts. Times and dates for all performances are announced at the first practice.  \n\nFrom Kiltie Band FAQs:\nQ: Are there auditions?  \nA: No, any member of the campus community with music experience is able to join the Kiltie Band!",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/The Kiltie Band at CMU.txt"
        },
        "page_content":"The Kiltie Marching Band consists of musicians and colorguard and plays at all Carnegie Mellon home football games. There is a new show every week with music ranging from traditional marches and oldies to current pop tunes and jazz standards.  \n  \nAfter football season, the Kiltie Concert Band plays a holiday concert and two spring concerts, including a performance at Carnegie Mellon\u2019s Spring Carnival. Additionally, a part of the band gets together and acts as a pep band for the basketball teams.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"in 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was \nawarded to Mao Yisheng, father  \nof Chinese bridge construction. \nDuolingo , invented by professor  \nLuis von Ahn (CS 2003, 2005), had  \n10 million downloads in 12 months \nand was named Apple\u2019s 2013 app  \nof the year.\n:-)\nLEADERSHIP\nFarnam Jahanian   \nPresident\nDavid Coulter  \nChair, Board of Trustees\nJames H. Garrett Jr.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"The experiment, which lasted two years, was an unqualified success. Separately, and also in 1986, the Pittsburgh Supercomputing Center was created as a joint effort between CMU, the University of Pittsburgh and Westinghouse Electric Corp.SCS is officially formedCMU\u2019s Faculty Senate in the fall of 1988 agreed to President Richard Cyert\u2019s plan to elevate the Department of Computer Science to college status. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/The Kiltie Band at CMU.txt"
        },
        "page_content":"The Kiltie Band at CMU\n\nThe Kiltie Band began in 1908 with a group of just seven students dedicated to supporting Carnegie Tech football, and today's Kiltie Band continues a tradition of excellence originated over a century ago. The Band took the field for its first official performance on November 25th, 1922, on what would have been Andrew Carnegie's 87th birthday.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Kiltie Band Concert on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Kiltie Band Concert\n\nTitle: Kiltie Band Concert\nDate: April 11, 2024\nTime: 3:30 PM-4:30 PM ET\n\nWhat better way to open Carnival than with the infamous \u201cBand without Pants\u201d? Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Kiltie Band FAQs.txt"
        },
        "page_content":"From Kiltie Band FAQs:\nQ: When is the first rehearsal?  \nA: On the first day of class (Monday) at 5:30 p.m. in the CUC Studio Theater. If you have questions, please email the Direcator at\u00a0jolisar@andrew.cmu.edu.\n\nFrom Kiltie Band FAQs:\nQ: Can I borrow a school instrument?  \nA: There are several Kiltie-owned instruments available for your use. Loans begin at 4:30 p.m. before the first rehearsal.\u00a0  \n\nFrom Kiltie Band FAQs:\nQ: What do they wear under those kilts?  \nA: Join and you\u2019ll find out!",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Kiltie Band FAQs.txt"
        },
        "page_content":"From Kiltie Band FAQs:\nQ: Are there auditions?  \nA: No, any member of the campus community with music experience is able to join the Kiltie Band!  \n\nFrom Kiltie Band FAQs:\nQ: Do I have to memorize music?  \nA: No, the music is changed for every show. You should invest in a good and trusty lyre.  \n\nFrom Kiltie Band FAQs:\nQ: When is the first rehearsal?  \nA: On the first day of class (Monday) at 5:30 p.m. in the CUC Studio Theater. If you have questions, please email the Direcator at\u00a0jolisar@andrew.cmu.edu.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/The Kiltie Band at CMU.txt"
        },
        "page_content":"The Kiltie Band is a campus organization recognized by Student Senate and administered by the Department of Athletics, Physical Education and Recreation. Membership is open to all members of the campus\/community without audition. Participants must do their best to promote the success of the ensemble through attendance, attitude, and dependability.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Kiltie Band Alumni & Student Reception on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Kiltie Band Alumni & Student Reception\n\nTitle: Kiltie Band Alumni & Student Reception\nDate: April 11, 2024\nTime: 4:30 PM-6:30 PM ET\n\nAfter the Kiltie Band Spring Carnival kick-off concert, current and former Kilties are invited for food and fun!Note: Registration required. Walk-ins are welcome if space permits. No event fee. Open to the Kiltie community and guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Kiltie Band FAQs.txt"
        },
        "page_content":"From Kiltie Band FAQs:\nQ: When are rehearsals?  \nA: Football season: Mondays and Thursdays from 5:30 p.m.-7:30 p.m. and Game Day 9:30-11:00a.m. Concert Season: Mondays and Thursdays from 5:30-6:30 p.m.  \nLocation is the CUC Studio Theater.  \n\nFrom Kiltie Band FAQs:\nQ: When are performances?  \nA: The Kiltie Band performs at all home football games, a holiday concert, and two spring concerts. Times and dates for all performances are announced at the first practice.  \n\nFrom Kiltie Band FAQs:\nQ: Are there auditions?  \nA: No, any member of the campus community with music experience is able to join the Kiltie Band!",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/The Kiltie Band at CMU.txt"
        },
        "page_content":"The Kiltie Marching Band consists of musicians and colorguard and plays at all Carnegie Mellon home football games. There is a new show every week with music ranging from traditional marches and oldies to current pop tunes and jazz standards.  \n  \nAfter football season, the Kiltie Concert Band plays a holiday concert and two spring concerts, including a performance at Carnegie Mellon\u2019s Spring Carnival. Additionally, a part of the band gets together and acts as a pep band for the basketball teams.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"in 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was \nawarded to Mao Yisheng, father  \nof Chinese bridge construction. \nDuolingo , invented by professor  \nLuis von Ahn (CS 2003, 2005), had  \n10 million downloads in 12 months \nand was named Apple\u2019s 2013 app  \nof the year.\n:-)\nLEADERSHIP\nFarnam Jahanian   \nPresident\nDavid Coulter  \nChair, Board of Trustees\nJames H. Garrett Jr.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"The experiment, which lasted two years, was an unqualified success. Separately, and also in 1986, the Pittsburgh Supercomputing Center was created as a joint effort between CMU, the University of Pittsburgh and Westinghouse Electric Corp.SCS is officially formedCMU\u2019s Faculty Senate in the fall of 1988 agreed to President Richard Cyert\u2019s plan to elevate the Department of Computer Science to college status. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert",
        "type":"Document"
      }
    ],
    "model_output":"\nThe CMU Kiltie Band was created in 1908 with a group of just seven students dedicated to supporting Carnegie Tech football.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"When was the CMU Kiltie Band created?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nThe Kiltie Band at CMU\n\nThe Kiltie Band began in 1908 with a group of just seven students dedicated to supporting Carnegie Tech football, and today's Kiltie Band continues a tradition of excellence originated over a century ago. The Band took the field for its first official performance on November 25th, 1922, on what would have been Andrew Carnegie's 87th birthday.\n-----\nSpring Carnival 2024 Event Kiltie Band Concert\n\nTitle: Kiltie Band Concert\nDate: April 11, 2024\nTime: 3:30 PM-4:30 PM ET\n\nWhat better way to open Carnival than with the infamous \u201cBand without Pants\u201d? Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.\n-----\nFrom Kiltie Band FAQs:\nQ: When is the first rehearsal?  \nA: On the first day of class (Monday) at 5:30 p.m. in the CUC Studio Theater. If you have questions, please email the Direcator at\u00a0jolisar@andrew.cmu.edu.\n\nFrom Kiltie Band FAQs:\nQ: Can I borrow a school instrument?  \nA: There are several Kiltie-owned instruments available for your use. Loans begin at 4:30 p.m. before the first rehearsal.\u00a0  \n\nFrom Kiltie Band FAQs:\nQ: What do they wear under those kilts?  \nA: Join and you\u2019ll find out!\n-----\nFrom Kiltie Band FAQs:\nQ: Are there auditions?  \nA: No, any member of the campus community with music experience is able to join the Kiltie Band!  \n\nFrom Kiltie Band FAQs:\nQ: Do I have to memorize music?  \nA: No, the music is changed for every show. You should invest in a good and trusty lyre.  \n\nFrom Kiltie Band FAQs:\nQ: When is the first rehearsal?  \nA: On the first day of class (Monday) at 5:30 p.m. in the CUC Studio Theater. If you have questions, please email the Direcator at\u00a0jolisar@andrew.cmu.edu.\n-----\nThe Kiltie Band is a campus organization recognized by Student Senate and administered by the Department of Athletics, Physical Education and Recreation. Membership is open to all members of the campus\/community without audition. Participants must do their best to promote the success of the ensemble through attendance, attitude, and dependability.\n-----\nSpring Carnival 2024 Event Kiltie Band Alumni & Student Reception\n\nTitle: Kiltie Band Alumni & Student Reception\nDate: April 11, 2024\nTime: 4:30 PM-6:30 PM ET\n\nAfter the Kiltie Band Spring Carnival kick-off concert, current and former Kilties are invited for food and fun!Note: Registration required. Walk-ins are welcome if space permits. No event fee. Open to the Kiltie community and guests.\n-----\nFrom Kiltie Band FAQs:\nQ: When are rehearsals?  \nA: Football season: Mondays and Thursdays from 5:30 p.m.-7:30 p.m. and Game Day 9:30-11:00a.m. Concert Season: Mondays and Thursdays from 5:30-6:30 p.m.  \nLocation is the CUC Studio Theater.  \n\nFrom Kiltie Band FAQs:\nQ: When are performances?  \nA: The Kiltie Band performs at all home football games, a holiday concert, and two spring concerts. Times and dates for all performances are announced at the first practice.  \n\nFrom Kiltie Band FAQs:\nQ: Are there auditions?  \nA: No, any member of the campus community with music experience is able to join the Kiltie Band!\n-----\nThe Kiltie Marching Band consists of musicians and colorguard and plays at all Carnegie Mellon home football games. There is a new show every week with music ranging from traditional marches and oldies to current pop tunes and jazz standards.  \n  \nAfter football season, the Kiltie Concert Band plays a holiday concert and two spring concerts, including a performance at Carnegie Mellon\u2019s Spring Carnival. Additionally, a part of the band gets together and acts as a pep band for the basketball teams.\n-----\nin 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was \nawarded to Mao Yisheng, father  \nof Chinese bridge construction. \nDuolingo , invented by professor  \nLuis von Ahn (CS 2003, 2005), had  \n10 million downloads in 12 months \nand was named Apple\u2019s 2013 app  \nof the year.\n:-)\nLEADERSHIP\nFarnam Jahanian   \nPresident\nDavid Coulter  \nChair, Board of Trustees\nJames H. Garrett Jr.\n-----\nThe experiment, which lasted two years, was an unqualified success. Separately, and also in 1986, the Pittsburgh Supercomputing Center was created as a joint effort between CMU, the University of Pittsburgh and Westinghouse Electric Corp.SCS is officially formedCMU\u2019s Faculty Senate in the fall of 1988 agreed to President Richard Cyert\u2019s plan to elevate the Department of Computer Science to college status. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert\n-----\n\n### Response ###\n\nUser: When was the CMU Kiltie Band created?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.0,
    "recall":0.0,
    "precision":0.0,
    "A_hat":"2000",
    "index":4,
    "Q":"How many studens does CMU have?",
    "A":"16,779",
    "category":"history",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 9.txt"
        },
        "page_content":"the second fall semester and zero or one in the second spring semester.  The courses \nbelow are automatically approved.  A stud ent who wants to take a course not listed \nmust obtain approval of the Director prior to  registering.  In general, the Director will \napprove any graduate SCS course of not more than  12 units.  It is also possible to seek \napproval for courses in other Colleges at  CMU.  However, those courses must be \nrationally related to an AI career in order to be approved as electives.  \n11-636 MSAII Independent Study (may be tak en ONCE as an electi ve unless permission \nof the Director is obtained)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 57-422 Singers.txt"
        },
        "page_content":"<start course description for 57-422 Singers>\nSemester: Spring 2024 (aka S24)\nCourse Description: The CMU Singers is a specialized group of 12-16 singers, who are also members of the CMU Chorus, who perform music written especially for a small vocal ensemble.  These students must demonstrate an advanced level of vocal ability and musicianship to handle the most challenging of vocal repertory suitable for young singers.  Membership will be determined by the CMU Chorus audition.\n<\/end course description for 57-422 Singers>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 57-422 Singers.txt"
        },
        "page_content":"<start course description for 57-422 Singers>\nSemester: Fall 2023 (aka F23)\nCourse Description: The CMU Singers is a specialized group of 12-16 singers, who are also members of the CMU Chorus, who perform music written especially for a small vocal ensemble.  These students must demonstrate an advanced level of vocal ability and musicianship to handle the most challenging of vocal repertory suitable for young singers.  Membership will be determined by the CMU Chorus audition.\n<\/end course description for 57-422 Singers>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 13.txt"
        },
        "page_content":"268-6232. The annual security and fire safety report is also available online at  \nhttps:\/\/www.cmu.edu\/police\/annualreports\/ .  \n14.3.6  Shuttle and Escort Services \nParking and Transportation coordinates the Shuttle Service and Escort Service provided for \nCMU students, faculty, and community. The Shuttle & Escort website has full information \nabout these services, stops, routes, tracking and schedules.  \n14.4 The WORD \n\u00a0http:\/\/www.cmu.edu\/student-affairs\/theword\/\/  \nThe WORD is Carnegie Mellon University\u2019s stud ent on-line handbook and is considered a \nsupplement to the department (and sometimes college) handbook. The WORD contains",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 94-823 Measuring Social.txt"
        },
        "page_content":"7 sponsors come to CMU.  In the past, teams have built social applications, social algorithms, experimental methodologies, crowdsourced campaigns and real time information dash boards for their clients.  This class offers an opportunity for students interested in analyzing social data, working in a consultative fashion with actual clients on real issues, and learning about global issues associated with an increasingly social culture.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/The Kiltie Band at CMU.txt"
        },
        "page_content":"The Kiltie Band at CMU\n\nThe Kiltie Band began in 1908 with a group of just seven students dedicated to supporting Carnegie Tech football, and today's Kiltie Band continues a tradition of excellence originated over a century ago. The Band took the field for its first official performance on November 25th, 1922, on what would have been Andrew Carnegie's 87th birthday.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 13.txt"
        },
        "page_content":"14.4 The WORD \n\u00a0http:\/\/www.cmu.edu\/student-affairs\/theword\/\/  \nThe WORD is Carnegie Mellon University\u2019s stud ent on-line handbook and is considered a \nsupplement to the department (and sometimes college) handbook. The WORD contains \ncampus resources and opportunities, academic policy information and resources, community \nstandards information and resources. It is designed to provide all students with the tools, \nguidance, and insights to help you achieve your  full potential as a member of the Carnegie \nMellon community. Information about the following is included in The WORD (not an",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 76-270 Communicating Inclusively, Equitably, and Persuasively in the Workplace.txt"
        },
        "page_content":"Department: English\nNumber of Units: 9\nPrerequisites: (76-101) or (76-102) or (76-106 and 76-107) or (76-106 and 76-108) or (76-107 and 76-108)\nInstructors: Andrew Gordon, Jeremy Rosselot-Merritt\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 76-270 Communicating Inclusively, Equitably, and Persuasively in the Workplace>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 0.txt"
        },
        "page_content":"Handbook-MSAII-2022-2023\n1 Welcome \nWelcome to Carnegie Mellon University!  Being in the CMU School of Computer Science (SCS) \nis a unique experience because of the size of the school (over 2000 students, staff and faculty), \nthe quality of its members, the variety of research being conducted, and unparalleled learning \nopportunities.  We encourage you to take advantage of CMU offerings, both inside and outside \nSCS, and also to explore Pittsburgh and southwest Pennsylvania to the extent your schedule \npermits.   What you will find is an environment that encourages and rewards hard work and",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 2.txt"
        },
        "page_content":"curriculum, the MCDS seminar, electives and capstone project. \n\uf0b7 The capstone project consists of students working at CMU on a research project, \nor on an industry-sponsored project. \n\uf0b7 The student must complete 144 eligible units of study. This includes eight core and \nconcentration courses, two 12-unit seminar courses and two 12-unit capstone \ncourses. All students complete a common MCDS core in their first two semesters, \nconsisting of five courses. All students must also complete at least one \nconcentration, consisting of three courses in one of three areas: Analytics,",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 9.txt"
        },
        "page_content":"the second fall semester and zero or one in the second spring semester.  The courses \nbelow are automatically approved.  A stud ent who wants to take a course not listed \nmust obtain approval of the Director prior to  registering.  In general, the Director will \napprove any graduate SCS course of not more than  12 units.  It is also possible to seek \napproval for courses in other Colleges at  CMU.  However, those courses must be \nrationally related to an AI career in order to be approved as electives.  \n11-636 MSAII Independent Study (may be tak en ONCE as an electi ve unless permission \nof the Director is obtained)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 57-422 Singers.txt"
        },
        "page_content":"<start course description for 57-422 Singers>\nSemester: Spring 2024 (aka S24)\nCourse Description: The CMU Singers is a specialized group of 12-16 singers, who are also members of the CMU Chorus, who perform music written especially for a small vocal ensemble.  These students must demonstrate an advanced level of vocal ability and musicianship to handle the most challenging of vocal repertory suitable for young singers.  Membership will be determined by the CMU Chorus audition.\n<\/end course description for 57-422 Singers>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 57-422 Singers.txt"
        },
        "page_content":"<start course description for 57-422 Singers>\nSemester: Fall 2023 (aka F23)\nCourse Description: The CMU Singers is a specialized group of 12-16 singers, who are also members of the CMU Chorus, who perform music written especially for a small vocal ensemble.  These students must demonstrate an advanced level of vocal ability and musicianship to handle the most challenging of vocal repertory suitable for young singers.  Membership will be determined by the CMU Chorus audition.\n<\/end course description for 57-422 Singers>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 13.txt"
        },
        "page_content":"268-6232. The annual security and fire safety report is also available online at  \nhttps:\/\/www.cmu.edu\/police\/annualreports\/ .  \n14.3.6  Shuttle and Escort Services \nParking and Transportation coordinates the Shuttle Service and Escort Service provided for \nCMU students, faculty, and community. The Shuttle & Escort website has full information \nabout these services, stops, routes, tracking and schedules.  \n14.4 The WORD \n\u00a0http:\/\/www.cmu.edu\/student-affairs\/theword\/\/  \nThe WORD is Carnegie Mellon University\u2019s stud ent on-line handbook and is considered a \nsupplement to the department (and sometimes college) handbook. The WORD contains",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 94-823 Measuring Social.txt"
        },
        "page_content":"7 sponsors come to CMU.  In the past, teams have built social applications, social algorithms, experimental methodologies, crowdsourced campaigns and real time information dash boards for their clients.  This class offers an opportunity for students interested in analyzing social data, working in a consultative fashion with actual clients on real issues, and learning about global issues associated with an increasingly social culture.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/The Kiltie Band at CMU.txt"
        },
        "page_content":"The Kiltie Band at CMU\n\nThe Kiltie Band began in 1908 with a group of just seven students dedicated to supporting Carnegie Tech football, and today's Kiltie Band continues a tradition of excellence originated over a century ago. The Band took the field for its first official performance on November 25th, 1922, on what would have been Andrew Carnegie's 87th birthday.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 13.txt"
        },
        "page_content":"14.4 The WORD \n\u00a0http:\/\/www.cmu.edu\/student-affairs\/theword\/\/  \nThe WORD is Carnegie Mellon University\u2019s stud ent on-line handbook and is considered a \nsupplement to the department (and sometimes college) handbook. The WORD contains \ncampus resources and opportunities, academic policy information and resources, community \nstandards information and resources. It is designed to provide all students with the tools, \nguidance, and insights to help you achieve your  full potential as a member of the Carnegie \nMellon community. Information about the following is included in The WORD (not an",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 76-270 Communicating Inclusively, Equitably, and Persuasively in the Workplace.txt"
        },
        "page_content":"Department: English\nNumber of Units: 9\nPrerequisites: (76-101) or (76-102) or (76-106 and 76-107) or (76-106 and 76-108) or (76-107 and 76-108)\nInstructors: Andrew Gordon, Jeremy Rosselot-Merritt\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 76-270 Communicating Inclusively, Equitably, and Persuasively in the Workplace>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 0.txt"
        },
        "page_content":"Handbook-MSAII-2022-2023\n1 Welcome \nWelcome to Carnegie Mellon University!  Being in the CMU School of Computer Science (SCS) \nis a unique experience because of the size of the school (over 2000 students, staff and faculty), \nthe quality of its members, the variety of research being conducted, and unparalleled learning \nopportunities.  We encourage you to take advantage of CMU offerings, both inside and outside \nSCS, and also to explore Pittsburgh and southwest Pennsylvania to the extent your schedule \npermits.   What you will find is an environment that encourages and rewards hard work and",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 2.txt"
        },
        "page_content":"curriculum, the MCDS seminar, electives and capstone project. \n\uf0b7 The capstone project consists of students working at CMU on a research project, \nor on an industry-sponsored project. \n\uf0b7 The student must complete 144 eligible units of study. This includes eight core and \nconcentration courses, two 12-unit seminar courses and two 12-unit capstone \ncourses. All students complete a common MCDS core in their first two semesters, \nconsisting of five courses. All students must also complete at least one \nconcentration, consisting of three courses in one of three areas: Analytics,",
        "type":"Document"
      }
    ],
    "model_output":"\nAccording to the provided documents, Carnegie Mellon University (CMU) has over 2000 students, staff, and faculty.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"How many studens does CMU have?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nthe second fall semester and zero or one in the second spring semester.  The courses \nbelow are automatically approved.  A stud ent who wants to take a course not listed \nmust obtain approval of the Director prior to  registering.  In general, the Director will \napprove any graduate SCS course of not more than  12 units.  It is also possible to seek \napproval for courses in other Colleges at  CMU.  However, those courses must be \nrationally related to an AI career in order to be approved as electives.  \n11-636 MSAII Independent Study (may be tak en ONCE as an electi ve unless permission \nof the Director is obtained)\n-----\n<start course description for 57-422 Singers>\nSemester: Spring 2024 (aka S24)\nCourse Description: The CMU Singers is a specialized group of 12-16 singers, who are also members of the CMU Chorus, who perform music written especially for a small vocal ensemble.  These students must demonstrate an advanced level of vocal ability and musicianship to handle the most challenging of vocal repertory suitable for young singers.  Membership will be determined by the CMU Chorus audition.\n<\/end course description for 57-422 Singers>\n-----\n<start course description for 57-422 Singers>\nSemester: Fall 2023 (aka F23)\nCourse Description: The CMU Singers is a specialized group of 12-16 singers, who are also members of the CMU Chorus, who perform music written especially for a small vocal ensemble.  These students must demonstrate an advanced level of vocal ability and musicianship to handle the most challenging of vocal repertory suitable for young singers.  Membership will be determined by the CMU Chorus audition.\n<\/end course description for 57-422 Singers>\n-----\n268-6232. The annual security and fire safety report is also available online at  \nhttps:\/\/www.cmu.edu\/police\/annualreports\/ .  \n14.3.6  Shuttle and Escort Services \nParking and Transportation coordinates the Shuttle Service and Escort Service provided for \nCMU students, faculty, and community. The Shuttle & Escort website has full information \nabout these services, stops, routes, tracking and schedules.  \n14.4 The WORD \n\u00a0http:\/\/www.cmu.edu\/student-affairs\/theword\/\/  \nThe WORD is Carnegie Mellon University\u2019s stud ent on-line handbook and is considered a \nsupplement to the department (and sometimes college) handbook. The WORD contains\n-----\n7 sponsors come to CMU.  In the past, teams have built social applications, social algorithms, experimental methodologies, crowdsourced campaigns and real time information dash boards for their clients.  This class offers an opportunity for students interested in analyzing social data, working in a consultative fashion with actual clients on real issues, and learning about global issues associated with an increasingly social culture.\n-----\nThe Kiltie Band at CMU\n\nThe Kiltie Band began in 1908 with a group of just seven students dedicated to supporting Carnegie Tech football, and today's Kiltie Band continues a tradition of excellence originated over a century ago. The Band took the field for its first official performance on November 25th, 1922, on what would have been Andrew Carnegie's 87th birthday.\n-----\n14.4 The WORD \n\u00a0http:\/\/www.cmu.edu\/student-affairs\/theword\/\/  \nThe WORD is Carnegie Mellon University\u2019s stud ent on-line handbook and is considered a \nsupplement to the department (and sometimes college) handbook. The WORD contains \ncampus resources and opportunities, academic policy information and resources, community \nstandards information and resources. It is designed to provide all students with the tools, \nguidance, and insights to help you achieve your  full potential as a member of the Carnegie \nMellon community. Information about the following is included in The WORD (not an\n-----\nDepartment: English\nNumber of Units: 9\nPrerequisites: (76-101) or (76-102) or (76-106 and 76-107) or (76-106 and 76-108) or (76-107 and 76-108)\nInstructors: Andrew Gordon, Jeremy Rosselot-Merritt\nRooms: CMU REMOTE\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 76-270 Communicating Inclusively, Equitably, and Persuasively in the Workplace>\n-----\nHandbook-MSAII-2022-2023\n1 Welcome \nWelcome to Carnegie Mellon University!  Being in the CMU School of Computer Science (SCS) \nis a unique experience because of the size of the school (over 2000 students, staff and faculty), \nthe quality of its members, the variety of research being conducted, and unparalleled learning \nopportunities.  We encourage you to take advantage of CMU offerings, both inside and outside \nSCS, and also to explore Pittsburgh and southwest Pennsylvania to the extent your schedule \npermits.   What you will find is an environment that encourages and rewards hard work and\n-----\ncurriculum, the MCDS seminar, electives and capstone project. \n\uf0b7 The capstone project consists of students working at CMU on a research project, \nor on an industry-sponsored project. \n\uf0b7 The student must complete 144 eligible units of study. This includes eight core and \nconcentration courses, two 12-unit seminar courses and two 12-unit capstone \ncourses. All students complete a common MCDS core in their first two semesters, \nconsisting of five courses. All students must also complete at least one \nconcentration, consisting of three courses in one of three areas: Analytics,\n-----\n\n### Response ###\n\nUser: How many studens does CMU have?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.5,
    "recall":0.3333333333,
    "precision":1.0,
    "A_hat":"1900",
    "index":5,
    "Q":"When did Andrew Carnegie say \"My Heart is in the Work.\"?",
    "A":"November 15, 1900",
    "category":"history",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"76%  U.S. 24%  InternationalGLOBAL COMMUNITY\nStudents representing\n126 countries\nFaculty representing\n56 countries\nAlumni representing \n148 countries\nOF COMPUTER \nSCIENCE\u2019S FIRST-\nYEAR STUDENTS  \nWERE WOMEN  \nIN 2019\nNearly triple the  \nnational average\u201c My Heart is in the Work. \u201d  \n Andrew Carnegie, Founder  \n November 15, 1900\n49.8 %\n87%  U.S. 13%  InternationalSCHOOLS AND COLLEGES\nCollege of Engineering \nCollege of Fine Arts\nDietrich College of Humanities  \nand Social Sciences\nHeinz College of Information Systems \nand Public Policy\nMellon College of Science\nSchool of Computer Science\nTepper School of Business",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"\"My heart is in the work,\" he stated, which would become part of the school's official motto.\nThe Carnegie Technical Schools offered two- and three-year certificates in the arts as well as in engineering disciplines and included a college for women, Margaret Morrison Carnegie College.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"At one point the richest man in the world, Carnegie believed that \"to die rich is to die disgraced.\" He turned his attention to writing, social activism and philanthropy, determined to establish educational opportunities for the general public where few existed.\nIn 1900, he donated $1 million for the creation of a technical institute for the city of Pittsburgh, envisioning a school where working-class men and women of Pittsburgh could learn practical skills, trades and crafts that would enhance their careers, lives and communities.\n\"My heart is in the work,\" he stated, which would become part of the school's official motto.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"History -     CMU - Carnegie Mellon University\nCarnegie Mellon University\n Andrew Carnegie \n\nA self-educated \"working boy\" who loved books, Andrew Carnegie emigrated from Scotland in 1848 and settled in Pittsburgh, Pa. Attending night school and borrowing books, Carnegie went from factory worker in a textile mill to successful entrepreneur and industrialist. He rose to prominence by founding what became the world's largest steel producing company by the end of the 19th century.\n\n\n \n\n Carnegie Technical Schools",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"will also be rewarding professionally and personally.  \nObtaining a Ph.D. is a long and often intense journey. A healthy work -life balance helps to keep it \nin perspective. Carnegie Mellon  is located in Pittsburgh, a city with a rich industrial and labor \nheritage. In the past, it was the heart of the U.S. steel industry, a source  for quality packaged foods, \nan important financial hub, and an early pioneer in railroads, radio, and nuclear power. This is a \ncity where people worked hard and made things that changed the world. Today, Pittsburgh has",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"It initiated the 'Carnegie Plan' in 1938, a new curriculum that required science and engineer students to take courses in humanities and social sciences in order to better understand the needs of society.\nCarnegie died in 1919, but his vision for an educated public lived on after him.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"6. Andrew project, 1982It was long the dream of computer scientists to put a workstation in every home and office, but no one had actually tried to accomplish it until researchers from Carnegie Mellon University and IBM launched the Andrew Project. Soon, every student, faculty member and employee had access to email, word processing, file-transfer services and graphics programs, and CMU was the most-wired campus in the world.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 2.txt"
        },
        "page_content":"3.3.18 Incomplete grades \nCarnegie Mellon University students are expected to complete a course during the \nacademic semester in which the course was taken. However, if the instructor agrees, a \ngrade of \u201cI\u201d (incomplete) may be given when a student has been unable to complete the \nwork of a course. However, the work completed up to that date must be of passing quality \nand the grade of incomplete provides no undue advantage to that student over other \nstudents. \n \nBy awarding an \u201cI\u201d grade, an instructor must specify the requirements for the completion \nof the work and designate a default letter grade in the event that the student fails to",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Tartan and CMU Facts.txt"
        },
        "page_content":"From Tartan and CMU Facts:\nQ: Who founded Carnegie Mellon University?\nA: Carnegie Technical Schools was founded in 1900 by Andrew Carnegie. Twelve years later it became known as the Carnegie Institute of Technology. In 1967, the school merged with Mellon Institute and became what is known today as Carnegie Mellon University.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/The Kiltie Band at CMU.txt"
        },
        "page_content":"The Kiltie Band at CMU\n\nThe Kiltie Band began in 1908 with a group of just seven students dedicated to supporting Carnegie Tech football, and today's Kiltie Band continues a tradition of excellence originated over a century ago. The Band took the field for its first official performance on November 25th, 1922, on what would have been Andrew Carnegie's 87th birthday.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"76%  U.S. 24%  InternationalGLOBAL COMMUNITY\nStudents representing\n126 countries\nFaculty representing\n56 countries\nAlumni representing \n148 countries\nOF COMPUTER \nSCIENCE\u2019S FIRST-\nYEAR STUDENTS  \nWERE WOMEN  \nIN 2019\nNearly triple the  \nnational average\u201c My Heart is in the Work. \u201d  \n Andrew Carnegie, Founder  \n November 15, 1900\n49.8 %\n87%  U.S. 13%  InternationalSCHOOLS AND COLLEGES\nCollege of Engineering \nCollege of Fine Arts\nDietrich College of Humanities  \nand Social Sciences\nHeinz College of Information Systems \nand Public Policy\nMellon College of Science\nSchool of Computer Science\nTepper School of Business",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"\"My heart is in the work,\" he stated, which would become part of the school's official motto.\nThe Carnegie Technical Schools offered two- and three-year certificates in the arts as well as in engineering disciplines and included a college for women, Margaret Morrison Carnegie College.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"At one point the richest man in the world, Carnegie believed that \"to die rich is to die disgraced.\" He turned his attention to writing, social activism and philanthropy, determined to establish educational opportunities for the general public where few existed.\nIn 1900, he donated $1 million for the creation of a technical institute for the city of Pittsburgh, envisioning a school where working-class men and women of Pittsburgh could learn practical skills, trades and crafts that would enhance their careers, lives and communities.\n\"My heart is in the work,\" he stated, which would become part of the school's official motto.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"History -     CMU - Carnegie Mellon University\nCarnegie Mellon University\n Andrew Carnegie \n\nA self-educated \"working boy\" who loved books, Andrew Carnegie emigrated from Scotland in 1848 and settled in Pittsburgh, Pa. Attending night school and borrowing books, Carnegie went from factory worker in a textile mill to successful entrepreneur and industrialist. He rose to prominence by founding what became the world's largest steel producing company by the end of the 19th century.\n\n\n \n\n Carnegie Technical Schools",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"will also be rewarding professionally and personally.  \nObtaining a Ph.D. is a long and often intense journey. A healthy work -life balance helps to keep it \nin perspective. Carnegie Mellon  is located in Pittsburgh, a city with a rich industrial and labor \nheritage. In the past, it was the heart of the U.S. steel industry, a source  for quality packaged foods, \nan important financial hub, and an early pioneer in railroads, radio, and nuclear power. This is a \ncity where people worked hard and made things that changed the world. Today, Pittsburgh has",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"It initiated the 'Carnegie Plan' in 1938, a new curriculum that required science and engineer students to take courses in humanities and social sciences in order to better understand the needs of society.\nCarnegie died in 1919, but his vision for an educated public lived on after him.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"6. Andrew project, 1982It was long the dream of computer scientists to put a workstation in every home and office, but no one had actually tried to accomplish it until researchers from Carnegie Mellon University and IBM launched the Andrew Project. Soon, every student, faculty member and employee had access to email, word processing, file-transfer services and graphics programs, and CMU was the most-wired campus in the world.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 2.txt"
        },
        "page_content":"3.3.18 Incomplete grades \nCarnegie Mellon University students are expected to complete a course during the \nacademic semester in which the course was taken. However, if the instructor agrees, a \ngrade of \u201cI\u201d (incomplete) may be given when a student has been unable to complete the \nwork of a course. However, the work completed up to that date must be of passing quality \nand the grade of incomplete provides no undue advantage to that student over other \nstudents. \n \nBy awarding an \u201cI\u201d grade, an instructor must specify the requirements for the completion \nof the work and designate a default letter grade in the event that the student fails to",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/Tartan and CMU Facts.txt"
        },
        "page_content":"From Tartan and CMU Facts:\nQ: Who founded Carnegie Mellon University?\nA: Carnegie Technical Schools was founded in 1900 by Andrew Carnegie. Twelve years later it became known as the Carnegie Institute of Technology. In 1967, the school merged with Mellon Institute and became what is known today as Carnegie Mellon University.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/athletics\/The Kiltie Band at CMU.txt"
        },
        "page_content":"The Kiltie Band at CMU\n\nThe Kiltie Band began in 1908 with a group of just seven students dedicated to supporting Carnegie Tech football, and today's Kiltie Band continues a tradition of excellence originated over a century ago. The Band took the field for its first official performance on November 25th, 1922, on what would have been Andrew Carnegie's 87th birthday.",
        "type":"Document"
      }
    ],
    "model_output":"\nAndrew Carnegie said, \"My Heart is in the Work\" on November 15, 1900.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"When did Andrew Carnegie say \"My Heart is in the Work.\"?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n76%  U.S. 24%  InternationalGLOBAL COMMUNITY\nStudents representing\n126 countries\nFaculty representing\n56 countries\nAlumni representing \n148 countries\nOF COMPUTER \nSCIENCE\u2019S FIRST-\nYEAR STUDENTS  \nWERE WOMEN  \nIN 2019\nNearly triple the  \nnational average\u201c My Heart is in the Work. \u201d  \n Andrew Carnegie, Founder  \n November 15, 1900\n49.8 %\n87%  U.S. 13%  InternationalSCHOOLS AND COLLEGES\nCollege of Engineering \nCollege of Fine Arts\nDietrich College of Humanities  \nand Social Sciences\nHeinz College of Information Systems \nand Public Policy\nMellon College of Science\nSchool of Computer Science\nTepper School of Business\n-----\n\"My heart is in the work,\" he stated, which would become part of the school's official motto.\nThe Carnegie Technical Schools offered two- and three-year certificates in the arts as well as in engineering disciplines and included a college for women, Margaret Morrison Carnegie College.\n-----\nAt one point the richest man in the world, Carnegie believed that \"to die rich is to die disgraced.\" He turned his attention to writing, social activism and philanthropy, determined to establish educational opportunities for the general public where few existed.\nIn 1900, he donated $1 million for the creation of a technical institute for the city of Pittsburgh, envisioning a school where working-class men and women of Pittsburgh could learn practical skills, trades and crafts that would enhance their careers, lives and communities.\n\"My heart is in the work,\" he stated, which would become part of the school's official motto.\n-----\nHistory -     CMU - Carnegie Mellon University\nCarnegie Mellon University\n Andrew Carnegie \n\nA self-educated \"working boy\" who loved books, Andrew Carnegie emigrated from Scotland in 1848 and settled in Pittsburgh, Pa. Attending night school and borrowing books, Carnegie went from factory worker in a textile mill to successful entrepreneur and industrialist. He rose to prominence by founding what became the world's largest steel producing company by the end of the 19th century.\n\n\n \n\n Carnegie Technical Schools\n-----\nwill also be rewarding professionally and personally.  \nObtaining a Ph.D. is a long and often intense journey. A healthy work -life balance helps to keep it \nin perspective. Carnegie Mellon  is located in Pittsburgh, a city with a rich industrial and labor \nheritage. In the past, it was the heart of the U.S. steel industry, a source  for quality packaged foods, \nan important financial hub, and an early pioneer in railroads, radio, and nuclear power. This is a \ncity where people worked hard and made things that changed the world. Today, Pittsburgh has\n-----\nIt initiated the 'Carnegie Plan' in 1938, a new curriculum that required science and engineer students to take courses in humanities and social sciences in order to better understand the needs of society.\nCarnegie died in 1919, but his vision for an educated public lived on after him.\n-----\n6. Andrew project, 1982It was long the dream of computer scientists to put a workstation in every home and office, but no one had actually tried to accomplish it until researchers from Carnegie Mellon University and IBM launched the Andrew Project. Soon, every student, faculty member and employee had access to email, word processing, file-transfer services and graphics programs, and CMU was the most-wired campus in the world.\n-----\n3.3.18 Incomplete grades \nCarnegie Mellon University students are expected to complete a course during the \nacademic semester in which the course was taken. However, if the instructor agrees, a \ngrade of \u201cI\u201d (incomplete) may be given when a student has been unable to complete the \nwork of a course. However, the work completed up to that date must be of passing quality \nand the grade of incomplete provides no undue advantage to that student over other \nstudents. \n \nBy awarding an \u201cI\u201d grade, an instructor must specify the requirements for the completion \nof the work and designate a default letter grade in the event that the student fails to\n-----\nFrom Tartan and CMU Facts:\nQ: Who founded Carnegie Mellon University?\nA: Carnegie Technical Schools was founded in 1900 by Andrew Carnegie. Twelve years later it became known as the Carnegie Institute of Technology. In 1967, the school merged with Mellon Institute and became what is known today as Carnegie Mellon University.\n-----\nThe Kiltie Band at CMU\n\nThe Kiltie Band began in 1908 with a group of just seven students dedicated to supporting Carnegie Tech football, and today's Kiltie Band continues a tradition of excellence originated over a century ago. The Band took the field for its first official performance on November 25th, 1922, on what would have been Andrew Carnegie's 87th birthday.\n-----\n\n### Response ###\n\nUser: When did Andrew Carnegie say \"My Heart is in the Work.\"?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Artificial Intelligence",
    "index":6,
    "Q":"In 1975, Simon and Newell got the Turing Award. What area of computer science did they work on that lead to the award?",
    "A":"Artificial intelligence",
    "category":"history",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"These computers were the forerunners of today\u2019s ubiquitous multi-core desktops and laptops.Turing Awards and a Nobel PrizeIn 1975, Simon and Newell were awarded the A.M. Turing Award for their work in artificial intelligence. (As of 2014, 12 CMU alumni or faculty have been awarded Turings, sometimes considered the Nobel Prize of computing.) Three years later, Simon received the Nobel Prize in Economics for his work on decision-making theory. As the 1970s progressed, Newell became interested in human-computer interaction, and began a long relationship with Xerox\u2019s Palo Alto Research Center, or PARC, which released the Xerox Alto in 1973.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"department head.Multi-processor machines emergeCSD emerged from the brief crisis as a highly agile, interdisciplinary entity, with many new faculty members taking joint appointments with other CMU departments. Several large projects emerged in the Computer Science Department, including C.mmp, the first shared-memory multiprocessor computer, with 16 processing units, and Cm*, a 50-processor computer. These computers were the forerunners of today\u2019s ubiquitous multi-core desktops and laptops.Turing Awards and a Nobel PrizeIn 1975, Simon and Newell were awarded the A.M. Turing Award for their work in artificial intelligence. (As of 2014, 12 CMU",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of RAND designed the Logic Theorist, a computer program that could develop proofs for theorems in much the same way a human would work. They also developed linked-list data structures, the foundation of computer programming. Perlis, Simon and Newell are credited with defining the term \u201ccomputer science\u201d as \u201cthe theory and design of computers,\u201d as well as (in Newell\u2019s words) \u201cthe study of the",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"15. Model checking, 1994CMU professor Edmund Clarke had long stressed the importance of verifying computer hardware and software through a formal problem-solving technique called \u201cmodel checking.\u201d In 1994, his arguments gained new weight with the discovery that Intel\u2019s amazing new Pentium chip made errors on certain math problems. Clarke would go on to receive the Turing Award for his role in the development of model checking.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"developed linked-list data structures, the foundation of computer programming. Perlis, Simon and Newell are credited with defining the term \u201ccomputer science\u201d as \u201cthe theory and design of computers,\u201d as well as (in Newell\u2019s words) \u201cthe study of the phenomena arising from them.\u201d In 1958, Perlis began teaching the first freshman-level computer programming course in the United States at Carnegie Tech.Computer science Ph.D. program createdIn 1961, the Computation Center and its newest computer, a Bendix G-20, were moved to recently completed Scaife Hall. That same year, Carnegie Tech created an interdisciplinary Ph.D. program called Systems and",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"1. Artificial intelligence, 1955-56. Can you write a working computer program without a computer? Herb Simon (H\u201990), at left, Allen Newell (IA\u201957), at right, and Cliff Shaw did. The team created the first artificial intelligence program, Logic Theorist, which could solve logic puzzles in the same way that a human might solve them. Newell demonstrated that it worked by writing the instructions on 3-by-5 index cards that were manipulated on the kitchen table by Newell, his wife, and a group of Carnegie Tech grad students.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"in research. Indeed, by itself, the Robotics Institute is the largest university robotics research group in the world, with more than 500 people and more than 100 ongoing research projects. A half-century ago, Perlis, Simon and Newell outlined a vision for computer science. The School of Computer Science at CMU remains committed to continuing and extending their vision in the context of big data and connected computing in the 21st century.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"4. Speech recognition, 1976If you have an iPhone, ask Siri to look up \u201cHearsay I,\u201d the first computer system capable of continuous speech recognition. It was developed by future Turing Award winner and future SCS dean Raj Reddy along with his students. Their work on subsequent systems established many of the principles that still underlie speech recognition software.\n5. Emoticons, 1982Sure, it was just a joke, but (for better or worse) it\u2019s endured for more than three decades. CMU researcher Scott Fahlman created the emoticon to clear up misunderstandings on computer message boards. We\u2019ve been looking at the world sideways ever since. :-)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"1948:\u00a0The Graduate School of Industrial Administration, later renamed the\u00a0David A. Tepper School of Business, focusing on quantitative analysis and pioneering the field of management science.\n1968:\u00a0School of Urban and Public Affairs, later renamed the\u00a0H. John Heinz III College, providing graduate training for work in the public sector.\n1986:\u00a0School of Computer Science, pioneering computing and artificial intelligence, led by interdisciplinary efforts of Allen Newell and Herbert Simon.\n\n\n\n\n \n\n Carnegie Mellon University",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"These computers were the forerunners of today\u2019s ubiquitous multi-core desktops and laptops.Turing Awards and a Nobel PrizeIn 1975, Simon and Newell were awarded the A.M. Turing Award for their work in artificial intelligence. (As of 2014, 12 CMU alumni or faculty have been awarded Turings, sometimes considered the Nobel Prize of computing.) Three years later, Simon received the Nobel Prize in Economics for his work on decision-making theory. As the 1970s progressed, Newell became interested in human-computer interaction, and began a long relationship with Xerox\u2019s Palo Alto Research Center, or PARC, which released the Xerox Alto in 1973.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"department head.Multi-processor machines emergeCSD emerged from the brief crisis as a highly agile, interdisciplinary entity, with many new faculty members taking joint appointments with other CMU departments. Several large projects emerged in the Computer Science Department, including C.mmp, the first shared-memory multiprocessor computer, with 16 processing units, and Cm*, a 50-processor computer. These computers were the forerunners of today\u2019s ubiquitous multi-core desktops and laptops.Turing Awards and a Nobel PrizeIn 1975, Simon and Newell were awarded the A.M. Turing Award for their work in artificial intelligence. (As of 2014, 12 CMU",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of RAND designed the Logic Theorist, a computer program that could develop proofs for theorems in much the same way a human would work. They also developed linked-list data structures, the foundation of computer programming. Perlis, Simon and Newell are credited with defining the term \u201ccomputer science\u201d as \u201cthe theory and design of computers,\u201d as well as (in Newell\u2019s words) \u201cthe study of the",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"15. Model checking, 1994CMU professor Edmund Clarke had long stressed the importance of verifying computer hardware and software through a formal problem-solving technique called \u201cmodel checking.\u201d In 1994, his arguments gained new weight with the discovery that Intel\u2019s amazing new Pentium chip made errors on certain math problems. Clarke would go on to receive the Turing Award for his role in the development of model checking.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"developed linked-list data structures, the foundation of computer programming. Perlis, Simon and Newell are credited with defining the term \u201ccomputer science\u201d as \u201cthe theory and design of computers,\u201d as well as (in Newell\u2019s words) \u201cthe study of the phenomena arising from them.\u201d In 1958, Perlis began teaching the first freshman-level computer programming course in the United States at Carnegie Tech.Computer science Ph.D. program createdIn 1961, the Computation Center and its newest computer, a Bendix G-20, were moved to recently completed Scaife Hall. That same year, Carnegie Tech created an interdisciplinary Ph.D. program called Systems and",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"1. Artificial intelligence, 1955-56. Can you write a working computer program without a computer? Herb Simon (H\u201990), at left, Allen Newell (IA\u201957), at right, and Cliff Shaw did. The team created the first artificial intelligence program, Logic Theorist, which could solve logic puzzles in the same way that a human might solve them. Newell demonstrated that it worked by writing the instructions on 3-by-5 index cards that were manipulated on the kitchen table by Newell, his wife, and a group of Carnegie Tech grad students.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"in research. Indeed, by itself, the Robotics Institute is the largest university robotics research group in the world, with more than 500 people and more than 100 ongoing research projects. A half-century ago, Perlis, Simon and Newell outlined a vision for computer science. The School of Computer Science at CMU remains committed to continuing and extending their vision in the context of big data and connected computing in the 21st century.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"4. Speech recognition, 1976If you have an iPhone, ask Siri to look up \u201cHearsay I,\u201d the first computer system capable of continuous speech recognition. It was developed by future Turing Award winner and future SCS dean Raj Reddy along with his students. Their work on subsequent systems established many of the principles that still underlie speech recognition software.\n5. Emoticons, 1982Sure, it was just a joke, but (for better or worse) it\u2019s endured for more than three decades. CMU researcher Scott Fahlman created the emoticon to clear up misunderstandings on computer message boards. We\u2019ve been looking at the world sideways ever since. :-)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University History.txt"
        },
        "page_content":"1948:\u00a0The Graduate School of Industrial Administration, later renamed the\u00a0David A. Tepper School of Business, focusing on quantitative analysis and pioneering the field of management science.\n1968:\u00a0School of Urban and Public Affairs, later renamed the\u00a0H. John Heinz III College, providing graduate training for work in the public sector.\n1986:\u00a0School of Computer Science, pioneering computing and artificial intelligence, led by interdisciplinary efforts of Allen Newell and Herbert Simon.\n\n\n\n\n \n\n Carnegie Mellon University",
        "type":"Document"
      }
    ],
    "model_output":"\nHerbert Simon and Allen Newell received the Turing Award in 1975 for their work in artificial intelligence. Specifically, they were recognized for their development of the first artificial intelligence program, Logic Theorist, which could solve logic puzzles in the same way that a human might solve them. This work laid the foundation for the field of artificial intelligence and paved the way for subsequent advancements in the field.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"In 1975, Simon and Newell got the Turing Award. What area of computer science did they work on that lead to the award?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nThese computers were the forerunners of today\u2019s ubiquitous multi-core desktops and laptops.Turing Awards and a Nobel PrizeIn 1975, Simon and Newell were awarded the A.M. Turing Award for their work in artificial intelligence. (As of 2014, 12 CMU alumni or faculty have been awarded Turings, sometimes considered the Nobel Prize of computing.) Three years later, Simon received the Nobel Prize in Economics for his work on decision-making theory. As the 1970s progressed, Newell became interested in human-computer interaction, and began a long relationship with Xerox\u2019s Palo Alto Research Center, or PARC, which released the Xerox Alto in 1973.\n-----\ndepartment head.Multi-processor machines emergeCSD emerged from the brief crisis as a highly agile, interdisciplinary entity, with many new faculty members taking joint appointments with other CMU departments. Several large projects emerged in the Computer Science Department, including C.mmp, the first shared-memory multiprocessor computer, with 16 processing units, and Cm*, a 50-processor computer. These computers were the forerunners of today\u2019s ubiquitous multi-core desktops and laptops.Turing Awards and a Nobel PrizeIn 1975, Simon and Newell were awarded the A.M. Turing Award for their work in artificial intelligence. (As of 2014, 12 CMU\n-----\nCMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of RAND designed the Logic Theorist, a computer program that could develop proofs for theorems in much the same way a human would work. They also developed linked-list data structures, the foundation of computer programming. Perlis, Simon and Newell are credited with defining the term \u201ccomputer science\u201d as \u201cthe theory and design of computers,\u201d as well as (in Newell\u2019s words) \u201cthe study of the\n-----\n15. Model checking, 1994CMU professor Edmund Clarke had long stressed the importance of verifying computer hardware and software through a formal problem-solving technique called \u201cmodel checking.\u201d In 1994, his arguments gained new weight with the discovery that Intel\u2019s amazing new Pentium chip made errors on certain math problems. Clarke would go on to receive the Turing Award for his role in the development of model checking.\n-----\ndeveloped linked-list data structures, the foundation of computer programming. Perlis, Simon and Newell are credited with defining the term \u201ccomputer science\u201d as \u201cthe theory and design of computers,\u201d as well as (in Newell\u2019s words) \u201cthe study of the phenomena arising from them.\u201d In 1958, Perlis began teaching the first freshman-level computer programming course in the United States at Carnegie Tech.Computer science Ph.D. program createdIn 1961, the Computation Center and its newest computer, a Bendix G-20, were moved to recently completed Scaife Hall. That same year, Carnegie Tech created an interdisciplinary Ph.D. program called Systems and\n-----\nothers that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of\n-----\n1. Artificial intelligence, 1955-56. Can you write a working computer program without a computer? Herb Simon (H\u201990), at left, Allen Newell (IA\u201957), at right, and Cliff Shaw did. The team created the first artificial intelligence program, Logic Theorist, which could solve logic puzzles in the same way that a human might solve them. Newell demonstrated that it worked by writing the instructions on 3-by-5 index cards that were manipulated on the kitchen table by Newell, his wife, and a group of Carnegie Tech grad students.\n-----\nin research. Indeed, by itself, the Robotics Institute is the largest university robotics research group in the world, with more than 500 people and more than 100 ongoing research projects. A half-century ago, Perlis, Simon and Newell outlined a vision for computer science. The School of Computer Science at CMU remains committed to continuing and extending their vision in the context of big data and connected computing in the 21st century.\n-----\n4. Speech recognition, 1976If you have an iPhone, ask Siri to look up \u201cHearsay I,\u201d the first computer system capable of continuous speech recognition. It was developed by future Turing Award winner and future SCS dean Raj Reddy along with his students. Their work on subsequent systems established many of the principles that still underlie speech recognition software.\n5. Emoticons, 1982Sure, it was just a joke, but (for better or worse) it\u2019s endured for more than three decades. CMU researcher Scott Fahlman created the emoticon to clear up misunderstandings on computer message boards. We\u2019ve been looking at the world sideways ever since. :-)\n-----\n1948:\u00a0The Graduate School of Industrial Administration, later renamed the\u00a0David A. Tepper School of Business, focusing on quantitative analysis and pioneering the field of management science.\n1968:\u00a0School of Urban and Public Affairs, later renamed the\u00a0H. John Heinz III College, providing graduate training for work in the public sector.\n1986:\u00a0School of Computer Science, pioneering computing and artificial intelligence, led by interdisciplinary efforts of Allen Newell and Herbert Simon.\n\n\n\n\n \n\n Carnegie Mellon University\n-----\n\n### Response ###\n\nUser: In 1975, Simon and Newell got the Turing Award. What area of computer science did they work on that lead to the award?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"The Language Technologies Institute",
    "index":7,
    "Q":"Which department did CMU's Center for Machine Translation become?",
    "A":"Language Technologies Institute",
    "category":"history",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"status. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert (H\u201989) told faculty and staff that Habermann had been appointed CMU\u2019s first Dean of Computer Science, effective Dec. 1, and that the School of Computer Science would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"at SCS, along with more than 600 master\u2019s degree students.New departments, new areas of studyAlong the way, the Center for Machine Translation became the Language Technologies Institute, and other new departments were formed, including the Human-Computer Interaction Institute (1993), the Institute for Software Research (1999), the Machine Learning Department (2006) and the Ray and Stephanie Lane Center for Computational Biology (2009). SCS\u2019s seven degree-granting departments draw faculty and students from a wide variety of disciplines, including engineering, mathematics, social sciences, linguistics and design.Committed to extending our",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"The experiment, which lasted two years, was an unqualified success. Separately, and also in 1986, the Pittsburgh Supercomputing Center was created as a joint effort between CMU, the University of Pittsburgh and Westinghouse Electric Corp.SCS is officially formedCMU\u2019s Faculty Senate in the fall of 1988 agreed to President Richard Cyert\u2019s plan to elevate the Department of Computer Science to college status. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Lori Levin.txt"
        },
        "page_content":"Name: Lori Levin\nTitle: Research Professor\nEmail lsl@cs.cmu.edu\nPhone: 412-268-6193\nOffice: 5717 Gates & Hillman Centers\nInterests: Machine Translation, Natural Language Processing and Computational Linguistics, Corpus Annotation and Resources",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Graham Neubig.txt"
        },
        "page_content":"Name: Graham Neubig\nTitle: Associate Professor\nEmail gneubig@cs.cmu.edu\nPhone: \nOffice: 5409 Gates & Hillman Centers\nInterests: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Affiliated Faculty | Carnegie Mellon University | Roni Rosenfeld.txt"
        },
        "page_content":"Name: Roni Rosenfeld\nTitle: Professor and Head: Machine Learning Department\nEmail roni.rosenfeld@cs.cmu.edu\nPhone: 412-268-7678\nOffice: 8002 Gates & Hillman Centers\nInterests: Computational Epidemiology, Dialog Systems for the Developing World",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 0.txt"
        },
        "page_content":"consisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language \nprocessing, machine learning, and computational biology.  Many MLT graduates continue on to PhD programs in the LTI or other leading universities.  Other graduates  go on to work in the \ncomputer industry, many at major corporate research laboratories.  \nThere are significant differences between CMU's different departments and degree programs in philosophical approach, procedures, policies , and regulations. Each department issues a",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Ralf Brown.txt"
        },
        "page_content":"Name: Ralf Brown\nTitle: Principal Systems Scientist\nEmail ralf@andrew.cmu.edu\nPhone: 412-268-8298\nOffice: 5711 Gates & Hillman Centers\nInterests: Information Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Translation, Natural Language Processing and Computational Linguistics",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-755 Machine Learning for Signal Processing.txt"
        },
        "page_content":"<start course metadata for 11-755 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 11-755\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: CMU REMOTE; DH A302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-755 Machine Learning for Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"on the work of other faculty members, an undergraduate program in computer science was created during the 1989-90 academic year. Seven CS majors were admitted to the program as sophomores. Another 73 undergraduates were admitted in 1990\u201391. By 1995, there were 401 undergraduates in the School of Computer Science; in fall 2013, more than 600 undergraduates made up about 37 percent of student enrollment at SCS, along with more than 600 master\u2019s degree students.New departments, new areas of studyAlong the way, the Center for Machine Translation became the Language Technologies Institute, and other new departments were formed, including the",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"status. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert (H\u201989) told faculty and staff that Habermann had been appointed CMU\u2019s first Dean of Computer Science, effective Dec. 1, and that the School of Computer Science would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"at SCS, along with more than 600 master\u2019s degree students.New departments, new areas of studyAlong the way, the Center for Machine Translation became the Language Technologies Institute, and other new departments were formed, including the Human-Computer Interaction Institute (1993), the Institute for Software Research (1999), the Machine Learning Department (2006) and the Ray and Stephanie Lane Center for Computational Biology (2009). SCS\u2019s seven degree-granting departments draw faculty and students from a wide variety of disciplines, including engineering, mathematics, social sciences, linguistics and design.Committed to extending our",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"The experiment, which lasted two years, was an unqualified success. Separately, and also in 1986, the Pittsburgh Supercomputing Center was created as a joint effort between CMU, the University of Pittsburgh and Westinghouse Electric Corp.SCS is officially formedCMU\u2019s Faculty Senate in the fall of 1988 agreed to President Richard Cyert\u2019s plan to elevate the Department of Computer Science to college status. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Lori Levin.txt"
        },
        "page_content":"Name: Lori Levin\nTitle: Research Professor\nEmail lsl@cs.cmu.edu\nPhone: 412-268-6193\nOffice: 5717 Gates & Hillman Centers\nInterests: Machine Translation, Natural Language Processing and Computational Linguistics, Corpus Annotation and Resources",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Graham Neubig.txt"
        },
        "page_content":"Name: Graham Neubig\nTitle: Associate Professor\nEmail gneubig@cs.cmu.edu\nPhone: \nOffice: 5409 Gates & Hillman Centers\nInterests: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Affiliated Faculty | Carnegie Mellon University | Roni Rosenfeld.txt"
        },
        "page_content":"Name: Roni Rosenfeld\nTitle: Professor and Head: Machine Learning Department\nEmail roni.rosenfeld@cs.cmu.edu\nPhone: 412-268-7678\nOffice: 8002 Gates & Hillman Centers\nInterests: Computational Epidemiology, Dialog Systems for the Developing World",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 0.txt"
        },
        "page_content":"consisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language \nprocessing, machine learning, and computational biology.  Many MLT graduates continue on to PhD programs in the LTI or other leading universities.  Other graduates  go on to work in the \ncomputer industry, many at major corporate research laboratories.  \nThere are significant differences between CMU's different departments and degree programs in philosophical approach, procedures, policies , and regulations. Each department issues a",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Ralf Brown.txt"
        },
        "page_content":"Name: Ralf Brown\nTitle: Principal Systems Scientist\nEmail ralf@andrew.cmu.edu\nPhone: 412-268-8298\nOffice: 5711 Gates & Hillman Centers\nInterests: Information Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Translation, Natural Language Processing and Computational Linguistics",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-755 Machine Learning for Signal Processing.txt"
        },
        "page_content":"<start course metadata for 11-755 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 11-755\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: CMU REMOTE; DH A302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-755 Machine Learning for Signal Processing>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"on the work of other faculty members, an undergraduate program in computer science was created during the 1989-90 academic year. Seven CS majors were admitted to the program as sophomores. Another 73 undergraduates were admitted in 1990\u201391. By 1995, there were 401 undergraduates in the School of Computer Science; in fall 2013, more than 600 undergraduates made up about 37 percent of student enrollment at SCS, along with more than 600 master\u2019s degree students.New departments, new areas of studyAlong the way, the Center for Machine Translation became the Language Technologies Institute, and other new departments were formed, including the",
        "type":"Document"
      }
    ],
    "model_output":"\nThe Center for Machine Translation at CMU became the Language Technologies Institute.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Which department did CMU's Center for Machine Translation become?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nstatus. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert (H\u201989) told faculty and staff that Habermann had been appointed CMU\u2019s first Dean of Computer Science, effective Dec. 1, and that the School of Computer Science would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3,\n-----\nat SCS, along with more than 600 master\u2019s degree students.New departments, new areas of studyAlong the way, the Center for Machine Translation became the Language Technologies Institute, and other new departments were formed, including the Human-Computer Interaction Institute (1993), the Institute for Software Research (1999), the Machine Learning Department (2006) and the Ray and Stephanie Lane Center for Computational Biology (2009). SCS\u2019s seven degree-granting departments draw faculty and students from a wide variety of disciplines, including engineering, mathematics, social sciences, linguistics and design.Committed to extending our\n-----\nThe experiment, which lasted two years, was an unqualified success. Separately, and also in 1986, the Pittsburgh Supercomputing Center was created as a joint effort between CMU, the University of Pittsburgh and Westinghouse Electric Corp.SCS is officially formedCMU\u2019s Faculty Senate in the fall of 1988 agreed to President Richard Cyert\u2019s plan to elevate the Department of Computer Science to college status. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert\n-----\nName: Lori Levin\nTitle: Research Professor\nEmail lsl@cs.cmu.edu\nPhone: 412-268-6193\nOffice: 5717 Gates & Hillman Centers\nInterests: Machine Translation, Natural Language Processing and Computational Linguistics, Corpus Annotation and Resources\n-----\nName: Graham Neubig\nTitle: Associate Professor\nEmail gneubig@cs.cmu.edu\nPhone: \nOffice: 5409 Gates & Hillman Centers\nInterests: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning\n-----\nName: Roni Rosenfeld\nTitle: Professor and Head: Machine Learning Department\nEmail roni.rosenfeld@cs.cmu.edu\nPhone: 412-268-7678\nOffice: 8002 Gates & Hillman Centers\nInterests: Computational Epidemiology, Dialog Systems for the Developing World\n-----\nconsisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language \nprocessing, machine learning, and computational biology.  Many MLT graduates continue on to PhD programs in the LTI or other leading universities.  Other graduates  go on to work in the \ncomputer industry, many at major corporate research laboratories.  \nThere are significant differences between CMU's different departments and degree programs in philosophical approach, procedures, policies , and regulations. Each department issues a\n-----\nName: Ralf Brown\nTitle: Principal Systems Scientist\nEmail ralf@andrew.cmu.edu\nPhone: 412-268-8298\nOffice: 5711 Gates & Hillman Centers\nInterests: Information Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Translation, Natural Language Processing and Computational Linguistics\n-----\n<start course metadata for 11-755 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 11-755\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: CMU REMOTE; DH A302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-755 Machine Learning for Signal Processing>\n-----\non the work of other faculty members, an undergraduate program in computer science was created during the 1989-90 academic year. Seven CS majors were admitted to the program as sophomores. Another 73 undergraduates were admitted in 1990\u201391. By 1995, there were 401 undergraduates in the School of Computer Science; in fall 2013, more than 600 undergraduates made up about 37 percent of student enrollment at SCS, along with more than 600 master\u2019s degree students.New departments, new areas of studyAlong the way, the Center for Machine Translation became the Language Technologies Institute, and other new departments were formed, including the\n-----\n\n### Response ###\n\nUser: Which department did CMU's Center for Machine Translation become?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Hans Berliner",
    "index":8,
    "Q":"Which CMU researcher created the first computer chess program that achieves grandmaster status?",
    "A":"Hans Berliner",
    "category":"history",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"11. Computer chess, 1990Could a computer play chess at the level of the world\u2019s best players? For many years, it was considered the \u201choly grail\u201d of artificial intelligence. Hitech, developed by CMU researcher Hans Berliner (CS\u201974), was the first computer to achieve grandmaster status. CMU alumni played key roles in developing \u201cDeep Blue,\u201d the IBM machine that beat human chess champion Garry Kasparov in 1997.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of RAND designed the Logic Theorist, a computer program that could develop proofs for theorems in much the same way a human would work. They also developed linked-list data structures, the foundation of computer programming. Perlis, Simon and Newell are credited with defining the term \u201ccomputer science\u201d as \u201cthe theory and design of computers,\u201d as well as (in Newell\u2019s words) \u201cthe study of the",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"status. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert (H\u201989) told faculty and staff that Habermann had been appointed CMU\u2019s first Dean of Computer Science, effective Dec. 1, and that the School of Computer Science would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"4. Speech recognition, 1976If you have an iPhone, ask Siri to look up \u201cHearsay I,\u201d the first computer system capable of continuous speech recognition. It was developed by future Turing Award winner and future SCS dean Raj Reddy along with his students. Their work on subsequent systems established many of the principles that still underlie speech recognition software.\n5. Emoticons, 1982Sure, it was just a joke, but (for better or worse) it\u2019s endured for more than three decades. CMU researcher Scott Fahlman created the emoticon to clear up misunderstandings on computer message boards. We\u2019ve been looking at the world sideways ever since. :-)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"12. Java, 1991 As a CMU grad student, James Gosling (CS\u201983) worked on the Andrew project, which stressed interoperability between computers, whether they were Macs, IBMs or Unix machines. Those lessons served Gosling well when he developed Java, the first programming language able to run on almost any platform.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"Cognitive tutors,  which improve \nthe math skills of 500,000+ \nstudents each year \nThe first U.S. school to award  \na degree in drama  in 1914\nJames Gosling (SCS 1983) \ninvented the Java computer \nprogramming language .\nThe first exclusive higher \neducation partner of the Tony \nAwards\u00ae , co-creating the first, \nnational recognition program \nhonoring K-12 theatre educators The first smile in an email , created \nin 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"by the Mathematics Department. CSD professor Mary Shaw (CS\u201972) led CMU\u2019s first effort to design an undergraduate curriculum solely in computer science. She and her colleagues were guided by the Carnegie Plan\u2014guidelines established in 1938 under Carnegie Tech President Robert Doherty (A\u201940, E\u201948, H\u201950), outlining the principles of a sound professional education. Drawing on Shaw\u2019s plan and also on the work of other faculty members, an undergraduate program in computer science was created during the 1989-90 academic year. Seven CS majors were admitted to the program as sophomores. Another 73 undergraduates were admitted in 1990\u201391. By 1995,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"Science would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3, 1989.Undergraduate degrees beginFor several years, undergraduates interested in computer science pursued an \u201capplied math\/CS\u201d bachelor\u2019s degree offered by the Mathematics Department. CSD professor Mary Shaw (CS\u201972) led CMU\u2019s first effort to design an undergraduate curriculum solely in computer science. She and her colleagues were guided by the Carnegie Plan\u2014guidelines established in 1938 under",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"department head.Multi-processor machines emergeCSD emerged from the brief crisis as a highly agile, interdisciplinary entity, with many new faculty members taking joint appointments with other CMU departments. Several large projects emerged in the Computer Science Department, including C.mmp, the first shared-memory multiprocessor computer, with 16 processing units, and Cm*, a 50-processor computer. These computers were the forerunners of today\u2019s ubiquitous multi-core desktops and laptops.Turing Awards and a Nobel PrizeIn 1975, Simon and Newell were awarded the A.M. Turing Award for their work in artificial intelligence. (As of 2014, 12 CMU",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"11. Computer chess, 1990Could a computer play chess at the level of the world\u2019s best players? For many years, it was considered the \u201choly grail\u201d of artificial intelligence. Hitech, developed by CMU researcher Hans Berliner (CS\u201974), was the first computer to achieve grandmaster status. CMU alumni played key roles in developing \u201cDeep Blue,\u201d the IBM machine that beat human chess champion Garry Kasparov in 1997.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of RAND designed the Logic Theorist, a computer program that could develop proofs for theorems in much the same way a human would work. They also developed linked-list data structures, the foundation of computer programming. Perlis, Simon and Newell are credited with defining the term \u201ccomputer science\u201d as \u201cthe theory and design of computers,\u201d as well as (in Newell\u2019s words) \u201cthe study of the",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"status. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert (H\u201989) told faculty and staff that Habermann had been appointed CMU\u2019s first Dean of Computer Science, effective Dec. 1, and that the School of Computer Science would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"4. Speech recognition, 1976If you have an iPhone, ask Siri to look up \u201cHearsay I,\u201d the first computer system capable of continuous speech recognition. It was developed by future Turing Award winner and future SCS dean Raj Reddy along with his students. Their work on subsequent systems established many of the principles that still underlie speech recognition software.\n5. Emoticons, 1982Sure, it was just a joke, but (for better or worse) it\u2019s endured for more than three decades. CMU researcher Scott Fahlman created the emoticon to clear up misunderstandings on computer message boards. We\u2019ve been looking at the world sideways ever since. :-)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"others that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"12. Java, 1991 As a CMU grad student, James Gosling (CS\u201983) worked on the Andrew project, which stressed interoperability between computers, whether they were Macs, IBMs or Unix machines. Those lessons served Gosling well when he developed Java, the first programming language able to run on almost any platform.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"Cognitive tutors,  which improve \nthe math skills of 500,000+ \nstudents each year \nThe first U.S. school to award  \na degree in drama  in 1914\nJames Gosling (SCS 1983) \ninvented the Java computer \nprogramming language .\nThe first exclusive higher \neducation partner of the Tony \nAwards\u00ae , co-creating the first, \nnational recognition program \nhonoring K-12 theatre educators The first smile in an email , created \nin 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"by the Mathematics Department. CSD professor Mary Shaw (CS\u201972) led CMU\u2019s first effort to design an undergraduate curriculum solely in computer science. She and her colleagues were guided by the Carnegie Plan\u2014guidelines established in 1938 under Carnegie Tech President Robert Doherty (A\u201940, E\u201948, H\u201950), outlining the principles of a sound professional education. Drawing on Shaw\u2019s plan and also on the work of other faculty members, an undergraduate program in computer science was created during the 1989-90 academic year. Seven CS majors were admitted to the program as sophomores. Another 73 undergraduates were admitted in 1990\u201391. By 1995,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"Science would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3, 1989.Undergraduate degrees beginFor several years, undergraduates interested in computer science pursued an \u201capplied math\/CS\u201d bachelor\u2019s degree offered by the Mathematics Department. CSD professor Mary Shaw (CS\u201972) led CMU\u2019s first effort to design an undergraduate curriculum solely in computer science. She and her colleagues were guided by the Carnegie Plan\u2014guidelines established in 1938 under",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/History of Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"department head.Multi-processor machines emergeCSD emerged from the brief crisis as a highly agile, interdisciplinary entity, with many new faculty members taking joint appointments with other CMU departments. Several large projects emerged in the Computer Science Department, including C.mmp, the first shared-memory multiprocessor computer, with 16 processing units, and Cm*, a 50-processor computer. These computers were the forerunners of today\u2019s ubiquitous multi-core desktops and laptops.Turing Awards and a Nobel PrizeIn 1975, Simon and Newell were awarded the A.M. Turing Award for their work in artificial intelligence. (As of 2014, 12 CMU",
        "type":"Document"
      }
    ],
    "model_output":"\nHans Berliner (CS\u201974) developed the first computer chess program, Hitech, which achieved grandmaster status.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Which CMU researcher created the first computer chess program that achieves grandmaster status?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n11. Computer chess, 1990Could a computer play chess at the level of the world\u2019s best players? For many years, it was considered the \u201choly grail\u201d of artificial intelligence. Hitech, developed by CMU researcher Hans Berliner (CS\u201974), was the first computer to achieve grandmaster status. CMU alumni played key roles in developing \u201cDeep Blue,\u201d the IBM machine that beat human chess champion Garry Kasparov in 1997.\n-----\nCMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of RAND designed the Logic Theorist, a computer program that could develop proofs for theorems in much the same way a human would work. They also developed linked-list data structures, the foundation of computer programming. Perlis, Simon and Newell are credited with defining the term \u201ccomputer science\u201d as \u201cthe theory and design of computers,\u201d as well as (in Newell\u2019s words) \u201cthe study of the\n-----\nstatus. In addition to the Computer Science Department, SCS also incorporated the Robotics Institute, the Center for Machine Translation, and researchers from the Information Technology Center, which had developed Andrew. On Dec. 13, 1988, Cyert (H\u201989) told faculty and staff that Habermann had been appointed CMU\u2019s first Dean of Computer Science, effective Dec. 1, and that the School of Computer Science would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3,\n-----\n4. Speech recognition, 1976If you have an iPhone, ask Siri to look up \u201cHearsay I,\u201d the first computer system capable of continuous speech recognition. It was developed by future Turing Award winner and future SCS dean Raj Reddy along with his students. Their work on subsequent systems established many of the principles that still underlie speech recognition software.\n5. Emoticons, 1982Sure, it was just a joke, but (for better or worse) it\u2019s endured for more than three decades. CMU researcher Scott Fahlman created the emoticon to clear up misunderstandings on computer message boards. We\u2019ve been looking at the world sideways ever since. :-)\n-----\nothers that followed. But CMU\u2019s computer science era begins much earlier\u2014in 1956, with the arrival of an IBM 650 computer on the campus of what was then known as Carnegie Institute of Technology. The IBM 650 had magnetic-drum memory and a processing speed of approximately 60 instructions per second. Herb Simon (H\u201990), associate dean of the Graduate School of Industrial Administration\u2014now known as CMU\u2019s Tepper School of Business\u2014established Carnegie Tech\u2019s first Computation Center with the help of its first director, Alan Perlis (S\u201942).First freshman-level computer science courseIn 1956 and 1957, Simon, Allen Newell (IA\u201957) and Cliff Shaw of\n-----\n12. Java, 1991 As a CMU grad student, James Gosling (CS\u201983) worked on the Andrew project, which stressed interoperability between computers, whether they were Macs, IBMs or Unix machines. Those lessons served Gosling well when he developed Java, the first programming language able to run on almost any platform.\n-----\nCognitive tutors,  which improve \nthe math skills of 500,000+ \nstudents each year \nThe first U.S. school to award  \na degree in drama  in 1914\nJames Gosling (SCS 1983) \ninvented the Java computer \nprogramming language .\nThe first exclusive higher \neducation partner of the Tony \nAwards\u00ae , co-creating the first, \nnational recognition program \nhonoring K-12 theatre educators The first smile in an email , created \nin 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was\n-----\nby the Mathematics Department. CSD professor Mary Shaw (CS\u201972) led CMU\u2019s first effort to design an undergraduate curriculum solely in computer science. She and her colleagues were guided by the Carnegie Plan\u2014guidelines established in 1938 under Carnegie Tech President Robert Doherty (A\u201940, E\u201948, H\u201950), outlining the principles of a sound professional education. Drawing on Shaw\u2019s plan and also on the work of other faculty members, an undergraduate program in computer science was created during the 1989-90 academic year. Seven CS majors were admitted to the program as sophomores. Another 73 undergraduates were admitted in 1990\u201391. By 1995,\n-----\nScience would soon begin operations. SCS made its formal debut on Dec. 22, 1988, with a reception in the Wherrett Room of Skibo Hall, CMU\u2019s student union. The official announcement of CMU\u2019s new \u201cgraduate School of Computer Science\u201d was made Jan. 3, 1989.Undergraduate degrees beginFor several years, undergraduates interested in computer science pursued an \u201capplied math\/CS\u201d bachelor\u2019s degree offered by the Mathematics Department. CSD professor Mary Shaw (CS\u201972) led CMU\u2019s first effort to design an undergraduate curriculum solely in computer science. She and her colleagues were guided by the Carnegie Plan\u2014guidelines established in 1938 under\n-----\ndepartment head.Multi-processor machines emergeCSD emerged from the brief crisis as a highly agile, interdisciplinary entity, with many new faculty members taking joint appointments with other CMU departments. Several large projects emerged in the Computer Science Department, including C.mmp, the first shared-memory multiprocessor computer, with 16 processing units, and Cm*, a 50-processor computer. These computers were the forerunners of today\u2019s ubiquitous multi-core desktops and laptops.Turing Awards and a Nobel PrizeIn 1975, Simon and Newell were awarded the A.M. Turing Award for their work in artificial intelligence. (As of 2014, 12 CMU\n-----\n\n### Response ###\n\nUser: Which CMU researcher created the first computer chess program that achieves grandmaster status?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Duolingo",
    "index":9,
    "Q":"Which popular language learning app was created at CMU?",
    "A":"Duolingo",
    "category":"history",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"22. Language learning software, 2010Learning a second language has always been challenging, but a CMU spinoff called Duolingo is proving that it doesn\u2019t have to be expensive. Duolingo has developed language tutoring software that enables users to learn Spanish, English, Italian, German, Portuguese or French for free through its website and mobile apps. In the process, Duolingo users are helping to translate the Web.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-785 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-785 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-785\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-785 Introduction to Deep Learning>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-685 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-685 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-685\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-685 Introduction to Deep Learning>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 16-725 (Bio)Medical Image Analysis.txt"
        },
        "page_content":"covered topics include de-noising\/restoration, morphology, level sets, and shape\/feature analysis.  Students will develop practical experience through projects using the latest version of the National Library of Medicine Insight Toolkit ( ITK ) and SimpleITK, a popular open-source software library developed by a consortium of institutions including Carnegie Mellon University and the University of Pittsburgh. In addition to image analysis, the course will include interaction with radiologists and pathologist(s). *** Lectures are at CMU and students will visit clinicians at UPMC.  Some or all of the class lectures may also be videoed for",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"12. Java, 1991 As a CMU grad student, James Gosling (CS\u201983) worked on the Andrew project, which stressed interoperability between computers, whether they were Macs, IBMs or Unix machines. Those lessons served Gosling well when he developed Java, the first programming language able to run on almost any platform.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 05-832 Personalized Online Learning.txt"
        },
        "page_content":"learning experiences.  This course covers a number of proven personalization techniques used in advanced learning technologies. One of the techniques is the use of cognitive modeling to personalize practice of complex cognitive skills in intelligent tutoring systems. This approach, developed at CMU, may well be the most significant application of cognitive science in education and is commercially successful. We will also survey newer techniques, such as personalizing based on student meta-cognition, affect, and motivation. Finally, we will look at personalization approaches that are widely believed to be effective but have not proven to be",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 05-432 Personalized Online Learning.txt"
        },
        "page_content":"learning experiences.  This course covers a number of proven personalization techniques used in advanced learning technologies. One of the techniques is the use of cognitive modeling to personalize practice of complex cognitive skills in intelligent tutoring systems. This approach, developed at CMU, may well be the most significant application of cognitive science in education and is commercially successful. We will also survey newer techniques, such as personalizing based on student meta-cognition, affect, and motivation. Finally, we will look at personalization approaches that are widely believed to be effective but have not proven to be",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"in 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was \nawarded to Mao Yisheng, father  \nof Chinese bridge construction. \nDuolingo , invented by professor  \nLuis von Ahn (CS 2003, 2005), had  \n10 million downloads in 12 months \nand was named Apple\u2019s 2013 app  \nof the year.\n:-)\nLEADERSHIP\nFarnam Jahanian   \nPresident\nDavid Coulter  \nChair, Board of Trustees\nJames H. Garrett Jr.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Alexander Waibel.txt"
        },
        "page_content":"Name: Alexander Waibel\nTitle: Professor\nEmail waibel@cs.cmu.edu\nPhone: 412-268-7676\nOffice: 205 407 South Craig Street\nInterests: Spoken Language Translation, Machine Translation, Speech Processing, Neural Networks, Machine Learning, Multimodal Interaction, Dialog Processing",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-755 Machine Learning for Signal Processing.txt"
        },
        "page_content":"<start course metadata for 11-755 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 11-755\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: CMU REMOTE; DH A302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-755 Machine Learning for Signal Processing>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"22. Language learning software, 2010Learning a second language has always been challenging, but a CMU spinoff called Duolingo is proving that it doesn\u2019t have to be expensive. Duolingo has developed language tutoring software that enables users to learn Spanish, English, Italian, German, Portuguese or French for free through its website and mobile apps. In the process, Duolingo users are helping to translate the Web.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-785 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-785 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-785\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-785 Introduction to Deep Learning>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-685 Introduction to Deep Learning.txt"
        },
        "page_content":"<start course metadata for 11-685 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-685\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-685 Introduction to Deep Learning>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 16-725 (Bio)Medical Image Analysis.txt"
        },
        "page_content":"covered topics include de-noising\/restoration, morphology, level sets, and shape\/feature analysis.  Students will develop practical experience through projects using the latest version of the National Library of Medicine Insight Toolkit ( ITK ) and SimpleITK, a popular open-source software library developed by a consortium of institutions including Carnegie Mellon University and the University of Pittsburgh. In addition to image analysis, the course will include interaction with radiologists and pathologist(s). *** Lectures are at CMU and students will visit clinicians at UPMC.  Some or all of the class lectures may also be videoed for",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/25 Great Things about Carnegie Mellon University School of Computer Science.txt"
        },
        "page_content":"12. Java, 1991 As a CMU grad student, James Gosling (CS\u201983) worked on the Andrew project, which stressed interoperability between computers, whether they were Macs, IBMs or Unix machines. Those lessons served Gosling well when he developed Java, the first programming language able to run on almost any platform.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 05-832 Personalized Online Learning.txt"
        },
        "page_content":"learning experiences.  This course covers a number of proven personalization techniques used in advanced learning technologies. One of the techniques is the use of cognitive modeling to personalize practice of complex cognitive skills in intelligent tutoring systems. This approach, developed at CMU, may well be the most significant application of cognitive science in education and is commercially successful. We will also survey newer techniques, such as personalizing based on student meta-cognition, affect, and motivation. Finally, we will look at personalization approaches that are widely believed to be effective but have not proven to be",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 05-432 Personalized Online Learning.txt"
        },
        "page_content":"learning experiences.  This course covers a number of proven personalization techniques used in advanced learning technologies. One of the techniques is the use of cognitive modeling to personalize practice of complex cognitive skills in intelligent tutoring systems. This approach, developed at CMU, may well be the most significant application of cognitive science in education and is commercially successful. We will also survey newer techniques, such as personalizing based on student meta-cognition, affect, and motivation. Finally, we will look at personalization approaches that are widely believed to be effective but have not proven to be",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/history\/cmu\/Carnegie Mellon University Fact Sheet.txt"
        },
        "page_content":"in 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was \nawarded to Mao Yisheng, father  \nof Chinese bridge construction. \nDuolingo , invented by professor  \nLuis von Ahn (CS 2003, 2005), had  \n10 million downloads in 12 months \nand was named Apple\u2019s 2013 app  \nof the year.\n:-)\nLEADERSHIP\nFarnam Jahanian   \nPresident\nDavid Coulter  \nChair, Board of Trustees\nJames H. Garrett Jr.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/directory\/Language Technologies Institute - Faculty | Carnegie Mellon University | Alexander Waibel.txt"
        },
        "page_content":"Name: Alexander Waibel\nTitle: Professor\nEmail waibel@cs.cmu.edu\nPhone: 412-268-7676\nOffice: 205 407 South Craig Street\nInterests: Spoken Language Translation, Machine Translation, Speech Processing, Neural Networks, Machine Learning, Multimodal Interaction, Dialog Processing",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-755 Machine Learning for Signal Processing.txt"
        },
        "page_content":"<start course metadata for 11-755 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 11-755\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: CMU REMOTE; DH A302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-755 Machine Learning for Signal Processing>",
        "type":"Document"
      }
    ],
    "model_output":"\nThe popular language learning app created at CMU is Duolingo. Duolingo was developed by professor Luis von Ahn (CS 2003, 2005) and had 10 million downloads in 12 months. It was named Apple\u2019s 2013 app of the year.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Which popular language learning app was created at CMU?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n22. Language learning software, 2010Learning a second language has always been challenging, but a CMU spinoff called Duolingo is proving that it doesn\u2019t have to be expensive. Duolingo has developed language tutoring software that enables users to learn Spanish, English, Italian, German, Portuguese or French for free through its website and mobile apps. In the process, Duolingo users are helping to translate the Web.\n-----\n<start course metadata for 11-785 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-785\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-785 Introduction to Deep Learning>\n-----\n<start course metadata for 11-685 Introduction to Deep Learning>\nSemester: Spring 2024 (aka S24)\nCourse Name: Introduction to Deep Learning\nCourse Number: 11-685\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan, Rita Singh\nRooms: BH A51; CMU REMOTE\nLocations: Kigali, Rwanda; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-685 Introduction to Deep Learning>\n-----\ncovered topics include de-noising\/restoration, morphology, level sets, and shape\/feature analysis.  Students will develop practical experience through projects using the latest version of the National Library of Medicine Insight Toolkit ( ITK ) and SimpleITK, a popular open-source software library developed by a consortium of institutions including Carnegie Mellon University and the University of Pittsburgh. In addition to image analysis, the course will include interaction with radiologists and pathologist(s). *** Lectures are at CMU and students will visit clinicians at UPMC.  Some or all of the class lectures may also be videoed for\n-----\n12. Java, 1991 As a CMU grad student, James Gosling (CS\u201983) worked on the Andrew project, which stressed interoperability between computers, whether they were Macs, IBMs or Unix machines. Those lessons served Gosling well when he developed Java, the first programming language able to run on almost any platform.\n-----\nlearning experiences.  This course covers a number of proven personalization techniques used in advanced learning technologies. One of the techniques is the use of cognitive modeling to personalize practice of complex cognitive skills in intelligent tutoring systems. This approach, developed at CMU, may well be the most significant application of cognitive science in education and is commercially successful. We will also survey newer techniques, such as personalizing based on student meta-cognition, affect, and motivation. Finally, we will look at personalization approaches that are widely believed to be effective but have not proven to be\n-----\nlearning experiences.  This course covers a number of proven personalization techniques used in advanced learning technologies. One of the techniques is the use of cognitive modeling to personalize practice of complex cognitive skills in intelligent tutoring systems. This approach, developed at CMU, may well be the most significant application of cognitive science in education and is commercially successful. We will also survey newer techniques, such as personalizing based on student meta-cognition, affect, and motivation. Finally, we will look at personalization approaches that are widely believed to be effective but have not proven to be\n-----\nin 1982 by professor Scott Fahlman\nKevlar Fiber , invented by alumna \nStephanie Kwolek (MM 1946)\nThe Last Lecture , written  \nby alumni Randy Pausch (SCS 1988)  \nand Jeffrey Zaslow (DC 1980)\nIn 1919, CMU\u2019s first Ph.D.  was \nawarded to Mao Yisheng, father  \nof Chinese bridge construction. \nDuolingo , invented by professor  \nLuis von Ahn (CS 2003, 2005), had  \n10 million downloads in 12 months \nand was named Apple\u2019s 2013 app  \nof the year.\n:-)\nLEADERSHIP\nFarnam Jahanian   \nPresident\nDavid Coulter  \nChair, Board of Trustees\nJames H. Garrett Jr.\n-----\nName: Alexander Waibel\nTitle: Professor\nEmail waibel@cs.cmu.edu\nPhone: 412-268-7676\nOffice: 205 407 South Craig Street\nInterests: Spoken Language Translation, Machine Translation, Speech Processing, Neural Networks, Machine Learning, Multimodal Interaction, Dialog Processing\n-----\n<start course metadata for 11-755 Machine Learning for Signal Processing>\nSemester: Fall 2023 (aka F23)\nCourse Name: Machine Learning for Signal Processing\nCourse Number: 11-755\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Bhiksha Ramakrishnan\nRooms: CMU REMOTE; DH A302\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-755 Machine Learning for Signal Processing>\n-----\n\n### Response ###\n\nUser: Which popular language learning app was created at CMU?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.5,
    "recall":0.5,
    "precision":0.5,
    "A_hat":"Carolyn Ros\u00e9",
    "index":10,
    "Q":"Who's the program directory of LTI's Undergraduate Language Technologies Concentration?",
    "A":"Carolyn Rose",
    "category":"programs",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/LTI Concentration.txt"
        },
        "page_content":"Students must complete a semester-long directed research project in the context of being registered for an independent study or thesis.  This should provide hands-on experience and an in-depth study of a topic in same area as a chosen elective.\nAdmission: Students interested in earning a minor in language technologies must apply for admission no later than September 30 of their senior year. An admission decision will usually be made within one month. Students may petition the LTI undergraduate program director to be admitted to the minor earlier or later in their undergraduate careers. To apply, contact the program's director, Carolyn Ros\u00e9.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"PhD_Student_Handbook_2023-2024\n1  Introduction  \nWelcome to the Language Technologies Institute, a graduate department in the School of \nComputer Science at Carnegie Mellon University. You have joined a Ph.D. program that focuses on excellence, creativity, and training the next generation of research leaders. While the next few \nyears will be a time of hard work and intense concentration, we hope that your time at the LTI \nwill also be rewarding professionally and personally.  \nObtaining a Ph.D. is a long and often intense journey. A healthy work -life balance helps to keep it",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 0.txt"
        },
        "page_content":"offered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MIIS degree provides advanced study \nand practical experience in areas of Computer Science focused on the processing and analysis \nof unstructured and semi -structured information, for example, text, image, video, speech, and \naudio information. It is a practice -oriented professional degree designed for students who \nwant to rapidly master advanced content -analysis, mining, and intelligent information \ntechnologies prior to beginning or resuming leadership careers in industry and government.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 0.txt"
        },
        "page_content":"Office of Graduate and Postdoc Affairs, the Office of the Dean of Student Affairs, and others, \nare included in Appendix A of this handbook.  \n1.2 The MLT Degree  \nThe Master of Language Technologies (MLT) is a research- oriented Master of Science degree \noffered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MLT program is a 24 -month program \nconsisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 7.txt"
        },
        "page_content":"Handbook-MSAII-2022-2023\n8 MSAII Policies \nThe Language Technologies Institute (LTI) ha s prepared this statement of policies, program \nrequirements, guidance, process and procedures for students in the M.S. in Artificial Intelligence \nand Innovation (MSAII) program. A copy of this handbook is also available online at the \nprogram website .   \nThe University Student guide, The Word, which  details university-wide policies, is also \navailable online at www.cmu.edu\/student-affairs\/theword .     \nAdditional resources specific to graduate students can be found at \nwww.cmu.edu\/graduate\/policies\/     \n8.1 The MSAII Degree",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 1.txt"
        },
        "page_content":"PhD_Student_Handbook_2023-2024\n2 The Language Technologies Institute  \n2.1 Pittsburgh Campus Location  \nThe Language Technologies Institute is located primarily on the 5th and 6th floors of the  Gates \nHillman Complex (GHC) on Carnegie Mellon\u2019s Pittsburgh campus.  The address and contact \ninformation of the LTI are  shown below.  \nLanguage Technologies Institute  \nCarnegie Mellon University  \n5000 Forbes Avenue  \nGates Hillman Complex  \nPittsburgh, PA 15241 -3891  \nLTI Ph.D.  Graduate Student Handbook  Page 13 \n 412-268-6298 (fax)  \nhttp:\/\/www.lti.cs.cmu.edu\/",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"each of the following areas. In addition, MIIS -21 students must take two more LTI \ncourses (24 units total) in one of the following areas of concentration:  \n\u2022 Human language;  \n\u2022 Machine learning; and  \n\u2022 Language technology applications.  \n The department maintains and publishes a list of courses  that satisfy each of these \nrequirements (Sections 3. 2.5 \u2013 3.2.7). Some courses  used to satisfy a breadth requirement \ncan also satisfy qualifying course requirements.  A student should get approval from the \ndirector for the breadth courses , if not listed below.  \n4.4 Approved Qualifying Courses",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-700 LTI Colloquium.txt"
        },
        "page_content":"<start course metadata for 11-700 LTI Colloquium>\nSemester: Spring 2024 (aka S24)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Instructor TBA, Yonatan Bisk\nRooms: DNM DNM; SH 105\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"This handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing, \ndialogue systems, information retrieval, machine translation, speech processing,  video \nunderstanding, multimodal systems, automated reasoning, and other topics related to analysis \nand understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-700 LTI Colloquium.txt"
        },
        "page_content":"<start course metadata for 11-700 LTI Colloquium>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Yonatan Bisk\nRooms: POS A35\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/LTI Concentration.txt"
        },
        "page_content":"Students must complete a semester-long directed research project in the context of being registered for an independent study or thesis.  This should provide hands-on experience and an in-depth study of a topic in same area as a chosen elective.\nAdmission: Students interested in earning a minor in language technologies must apply for admission no later than September 30 of their senior year. An admission decision will usually be made within one month. Students may petition the LTI undergraduate program director to be admitted to the minor earlier or later in their undergraduate careers. To apply, contact the program's director, Carolyn Ros\u00e9.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"PhD_Student_Handbook_2023-2024\n1  Introduction  \nWelcome to the Language Technologies Institute, a graduate department in the School of \nComputer Science at Carnegie Mellon University. You have joined a Ph.D. program that focuses on excellence, creativity, and training the next generation of research leaders. While the next few \nyears will be a time of hard work and intense concentration, we hope that your time at the LTI \nwill also be rewarding professionally and personally.  \nObtaining a Ph.D. is a long and often intense journey. A healthy work -life balance helps to keep it",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 0.txt"
        },
        "page_content":"offered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MIIS degree provides advanced study \nand practical experience in areas of Computer Science focused on the processing and analysis \nof unstructured and semi -structured information, for example, text, image, video, speech, and \naudio information. It is a practice -oriented professional degree designed for students who \nwant to rapidly master advanced content -analysis, mining, and intelligent information \ntechnologies prior to beginning or resuming leadership careers in industry and government.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 0.txt"
        },
        "page_content":"Office of Graduate and Postdoc Affairs, the Office of the Dean of Student Affairs, and others, \nare included in Appendix A of this handbook.  \n1.2 The MLT Degree  \nThe Master of Language Technologies (MLT) is a research- oriented Master of Science degree \noffered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MLT program is a 24 -month program \nconsisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 7.txt"
        },
        "page_content":"Handbook-MSAII-2022-2023\n8 MSAII Policies \nThe Language Technologies Institute (LTI) ha s prepared this statement of policies, program \nrequirements, guidance, process and procedures for students in the M.S. in Artificial Intelligence \nand Innovation (MSAII) program. A copy of this handbook is also available online at the \nprogram website .   \nThe University Student guide, The Word, which  details university-wide policies, is also \navailable online at www.cmu.edu\/student-affairs\/theword .     \nAdditional resources specific to graduate students can be found at \nwww.cmu.edu\/graduate\/policies\/     \n8.1 The MSAII Degree",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 1.txt"
        },
        "page_content":"PhD_Student_Handbook_2023-2024\n2 The Language Technologies Institute  \n2.1 Pittsburgh Campus Location  \nThe Language Technologies Institute is located primarily on the 5th and 6th floors of the  Gates \nHillman Complex (GHC) on Carnegie Mellon\u2019s Pittsburgh campus.  The address and contact \ninformation of the LTI are  shown below.  \nLanguage Technologies Institute  \nCarnegie Mellon University  \n5000 Forbes Avenue  \nGates Hillman Complex  \nPittsburgh, PA 15241 -3891  \nLTI Ph.D.  Graduate Student Handbook  Page 13 \n 412-268-6298 (fax)  \nhttp:\/\/www.lti.cs.cmu.edu\/",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"each of the following areas. In addition, MIIS -21 students must take two more LTI \ncourses (24 units total) in one of the following areas of concentration:  \n\u2022 Human language;  \n\u2022 Machine learning; and  \n\u2022 Language technology applications.  \n The department maintains and publishes a list of courses  that satisfy each of these \nrequirements (Sections 3. 2.5 \u2013 3.2.7). Some courses  used to satisfy a breadth requirement \ncan also satisfy qualifying course requirements.  A student should get approval from the \ndirector for the breadth courses , if not listed below.  \n4.4 Approved Qualifying Courses",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-700 LTI Colloquium.txt"
        },
        "page_content":"<start course metadata for 11-700 LTI Colloquium>\nSemester: Spring 2024 (aka S24)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Instructor TBA, Yonatan Bisk\nRooms: DNM DNM; SH 105\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"This handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing, \ndialogue systems, information retrieval, machine translation, speech processing,  video \nunderstanding, multimodal systems, automated reasoning, and other topics related to analysis \nand understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-700 LTI Colloquium.txt"
        },
        "page_content":"<start course metadata for 11-700 LTI Colloquium>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Yonatan Bisk\nRooms: POS A35\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>",
        "type":"Document"
      }
    ],
    "model_output":"\nThe program director of LTI's Undergraduate Language Technologies Concentration is Carolyn Ros\u00e9.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who's the program directory of LTI's Undergraduate Language Technologies Concentration?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nStudents must complete a semester-long directed research project in the context of being registered for an independent study or thesis.  This should provide hands-on experience and an in-depth study of a topic in same area as a chosen elective.\nAdmission: Students interested in earning a minor in language technologies must apply for admission no later than September 30 of their senior year. An admission decision will usually be made within one month. Students may petition the LTI undergraduate program director to be admitted to the minor earlier or later in their undergraduate careers. To apply, contact the program's director, Carolyn Ros\u00e9.\n-----\nPhD_Student_Handbook_2023-2024\n1  Introduction  \nWelcome to the Language Technologies Institute, a graduate department in the School of \nComputer Science at Carnegie Mellon University. You have joined a Ph.D. program that focuses on excellence, creativity, and training the next generation of research leaders. While the next few \nyears will be a time of hard work and intense concentration, we hope that your time at the LTI \nwill also be rewarding professionally and personally.  \nObtaining a Ph.D. is a long and often intense journey. A healthy work -life balance helps to keep it\n-----\noffered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MIIS degree provides advanced study \nand practical experience in areas of Computer Science focused on the processing and analysis \nof unstructured and semi -structured information, for example, text, image, video, speech, and \naudio information. It is a practice -oriented professional degree designed for students who \nwant to rapidly master advanced content -analysis, mining, and intelligent information \ntechnologies prior to beginning or resuming leadership careers in industry and government.\n-----\nOffice of Graduate and Postdoc Affairs, the Office of the Dean of Student Affairs, and others, \nare included in Appendix A of this handbook.  \n1.2 The MLT Degree  \nThe Master of Language Technologies (MLT) is a research- oriented Master of Science degree \noffered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MLT program is a 24 -month program \nconsisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language\n-----\nHandbook-MSAII-2022-2023\n8 MSAII Policies \nThe Language Technologies Institute (LTI) ha s prepared this statement of policies, program \nrequirements, guidance, process and procedures for students in the M.S. in Artificial Intelligence \nand Innovation (MSAII) program. A copy of this handbook is also available online at the \nprogram website .   \nThe University Student guide, The Word, which  details university-wide policies, is also \navailable online at www.cmu.edu\/student-affairs\/theword .     \nAdditional resources specific to graduate students can be found at \nwww.cmu.edu\/graduate\/policies\/     \n8.1 The MSAII Degree\n-----\nPhD_Student_Handbook_2023-2024\n2 The Language Technologies Institute  \n2.1 Pittsburgh Campus Location  \nThe Language Technologies Institute is located primarily on the 5th and 6th floors of the  Gates \nHillman Complex (GHC) on Carnegie Mellon\u2019s Pittsburgh campus.  The address and contact \ninformation of the LTI are  shown below.  \nLanguage Technologies Institute  \nCarnegie Mellon University  \n5000 Forbes Avenue  \nGates Hillman Complex  \nPittsburgh, PA 15241 -3891  \nLTI Ph.D.  Graduate Student Handbook  Page 13 \n 412-268-6298 (fax)  \nhttp:\/\/www.lti.cs.cmu.edu\/\n-----\neach of the following areas. In addition, MIIS -21 students must take two more LTI \ncourses (24 units total) in one of the following areas of concentration:  \n\u2022 Human language;  \n\u2022 Machine learning; and  \n\u2022 Language technology applications.  \n The department maintains and publishes a list of courses  that satisfy each of these \nrequirements (Sections 3. 2.5 \u2013 3.2.7). Some courses  used to satisfy a breadth requirement \ncan also satisfy qualifying course requirements.  A student should get approval from the \ndirector for the breadth courses , if not listed below.  \n4.4 Approved Qualifying Courses\n-----\n<start course metadata for 11-700 LTI Colloquium>\nSemester: Spring 2024 (aka S24)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Instructor TBA, Yonatan Bisk\nRooms: DNM DNM; SH 105\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>\n-----\nThis handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing, \ndialogue systems, information retrieval, machine translation, speech processing,  video \nunderstanding, multimodal systems, automated reasoning, and other topics related to analysis \nand understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan\n-----\n<start course metadata for 11-700 LTI Colloquium>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Yonatan Bisk\nRooms: POS A35\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>\n-----\n\n### Response ###\n\nUser: Who's the program directory of LTI's Undergraduate Language Technologies Concentration?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"The Master of Computational Data Science (MCDS)",
    "index":11,
    "Q":"Which masters program at LTI focus on engineering and deploying large-scale information systems?",
    "A":"Master of Computational Data Science (MCDS)",
    "category":"programs",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Computational Data Science (MCDS).txt"
        },
        "page_content":"Overview: The MCDS degree focuses on engineering and deploying large-scale information systems. Our comprehensive curriculum equips you with the skills and knowledge to develop the layers of technology involved in the next generation of massive information system deployments and analyze the data these systems generate. When you graduate, you\u2019ll have a unified vision of these systems from your core courses; internship experience; and semester-long, group-oriented capstone project. MCDS graduates are sought-after software engineers, data scientists and project managers at leading information technology, software services and social media",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"This handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing, \ndialogue systems, information retrieval, machine translation, speech processing,  video \nunderstanding, multimodal systems, automated reasoning, and other topics related to analysis \nand understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"\u2022 Dual -Degree Ph.D. in Language and Information Technologies (CMU -PT Ph.D.)  \n\u2022 Masters in Language Technologies (MLT)  \n\u2022 Master of Science in Intelligent Information Systems (MIIS)  \n\u2022 Master of Computational Data Science  (MCDS)  \n\u2022 Master of Science in Artificial Intelligence and Innovation  (MSAII)  \nLTI Ph.D.  Graduate Student Handbook  Page 10 \n This handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Overview: The LTI offers a dual-degree Ph.D. in Language and Information Technologies in cooperation with:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 0.txt"
        },
        "page_content":"offered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MIIS degree provides advanced study \nand practical experience in areas of Computer Science focused on the processing and analysis \nof unstructured and semi -structured information, for example, text, image, video, speech, and \naudio information. It is a practice -oriented professional degree designed for students who \nwant to rapidly master advanced content -analysis, mining, and intelligent information \ntechnologies prior to beginning or resuming leadership careers in industry and government.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"and understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan  \nPh.D. Program Director  \nProfessor  \nGHC 5419 \ncallan@cs.cmu.edu  \n412-268-4525  Stacey Young  \nPh.D. Academic Program Manager  \nLTI Graduate Program Manager  \nGHC 6415  \nstaceyy@cs.cmu.edu   \n412-268-2623  \nMona Diab  \nLTI Director  \nProfessor  \nGHC 5723 \nmdiab@andrew.cmu.edu  \n412-268-3669  \n \nJoan Axelson  \nOffice Manager  \nGHC 5405  \njaxelson@andrew.cmu.edu  \n412-268-7517  \n Julie Nys",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 1.txt"
        },
        "page_content":"Ph.D. students are given access to the LTI\u2019s computer cluster on an as- needed basis, to be used for \ncourse assignments, directed study projects, and\/or capstone projects.  The LTI cluster provides \nstorage and computation for projects involving large datasets and\/or lengthy computation.  \nPh.D. students receive two types of user ids: An Andrew id and a CS id. All CMU students have \nan Andrew id. Computer Science students also have a CS id that provides access to SCS -specific \nresources (e.g., computer clusters). CS ids are being phased out very slowly, so it is likely that you will need both types of user id.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 0.txt"
        },
        "page_content":"of ideas, where research, creativity, innovation, and entrepreneurship can flourish; and (c) \nensuring  individuals can achieve their full potential.  \n \nTo impact society in a transformative way  \u2014 regionally, nationally, and globally \u2014  by engaging  \nwith partners outside the traditional borders of the university campus.  \n1.3 The MIIS Degree  \nThe Master of Science in Intelligent Information Systems (MIIS) is a professional degree \noffered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MIIS degree provides advanced study",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Ph.D. in Language and Information Technology.txt"
        },
        "page_content":"Overview: The Ph.D. in LTI focuses on developing the next generation of scientific and entrepreneurial leaders. The first two years of the Ph.D. program are similar to our MLT program. After the second year, you will spend most of your time working closely with your faculty advisor on research that advances the state-of-the-art in computer science.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 3.txt"
        },
        "page_content":"\u2022 11-747: Neural Networks for NLP  \n\u2022 11-751:  Speech Recognition  \n\u2022 11-775:  Large -Scale Multimedia  \n\u2022 11-776: Multimodal Affective Computing  \n\u2022 11-777: Multimodal Machine Learning  \n\u2022 11-785:  Deep Learning  \n\u2022 11-797: Question Answering  \n \nStudents may request to have other  LTI course s with a group engineering project component to \nbe added to this list.   \nFor definitions of quoted terms, see the section on \u201cDefinitions of LTI Terminology .\u201d \nUnless approved by the Program Director in advance, t he course requirements must be \nsatisfied by actual classroom courses, not credit given for research or independent study.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Computational Data Science (MCDS).txt"
        },
        "page_content":"Overview: The MCDS degree focuses on engineering and deploying large-scale information systems. Our comprehensive curriculum equips you with the skills and knowledge to develop the layers of technology involved in the next generation of massive information system deployments and analyze the data these systems generate. When you graduate, you\u2019ll have a unified vision of these systems from your core courses; internship experience; and semester-long, group-oriented capstone project. MCDS graduates are sought-after software engineers, data scientists and project managers at leading information technology, software services and social media",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"This handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing, \ndialogue systems, information retrieval, machine translation, speech processing,  video \nunderstanding, multimodal systems, automated reasoning, and other topics related to analysis \nand understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"\u2022 Dual -Degree Ph.D. in Language and Information Technologies (CMU -PT Ph.D.)  \n\u2022 Masters in Language Technologies (MLT)  \n\u2022 Master of Science in Intelligent Information Systems (MIIS)  \n\u2022 Master of Computational Data Science  (MCDS)  \n\u2022 Master of Science in Artificial Intelligence and Innovation  (MSAII)  \nLTI Ph.D.  Graduate Student Handbook  Page 10 \n This handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Overview: The LTI offers a dual-degree Ph.D. in Language and Information Technologies in cooperation with:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 0.txt"
        },
        "page_content":"offered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MIIS degree provides advanced study \nand practical experience in areas of Computer Science focused on the processing and analysis \nof unstructured and semi -structured information, for example, text, image, video, speech, and \naudio information. It is a practice -oriented professional degree designed for students who \nwant to rapidly master advanced content -analysis, mining, and intelligent information \ntechnologies prior to beginning or resuming leadership careers in industry and government.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"and understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan  \nPh.D. Program Director  \nProfessor  \nGHC 5419 \ncallan@cs.cmu.edu  \n412-268-4525  Stacey Young  \nPh.D. Academic Program Manager  \nLTI Graduate Program Manager  \nGHC 6415  \nstaceyy@cs.cmu.edu   \n412-268-2623  \nMona Diab  \nLTI Director  \nProfessor  \nGHC 5723 \nmdiab@andrew.cmu.edu  \n412-268-3669  \n \nJoan Axelson  \nOffice Manager  \nGHC 5405  \njaxelson@andrew.cmu.edu  \n412-268-7517  \n Julie Nys",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 1.txt"
        },
        "page_content":"Ph.D. students are given access to the LTI\u2019s computer cluster on an as- needed basis, to be used for \ncourse assignments, directed study projects, and\/or capstone projects.  The LTI cluster provides \nstorage and computation for projects involving large datasets and\/or lengthy computation.  \nPh.D. students receive two types of user ids: An Andrew id and a CS id. All CMU students have \nan Andrew id. Computer Science students also have a CS id that provides access to SCS -specific \nresources (e.g., computer clusters). CS ids are being phased out very slowly, so it is likely that you will need both types of user id.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 0.txt"
        },
        "page_content":"of ideas, where research, creativity, innovation, and entrepreneurship can flourish; and (c) \nensuring  individuals can achieve their full potential.  \n \nTo impact society in a transformative way  \u2014 regionally, nationally, and globally \u2014  by engaging  \nwith partners outside the traditional borders of the university campus.  \n1.3 The MIIS Degree  \nThe Master of Science in Intelligent Information Systems (MIIS) is a professional degree \noffered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MIIS degree provides advanced study",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Ph.D. in Language and Information Technology.txt"
        },
        "page_content":"Overview: The Ph.D. in LTI focuses on developing the next generation of scientific and entrepreneurial leaders. The first two years of the Ph.D. program are similar to our MLT program. After the second year, you will spend most of your time working closely with your faculty advisor on research that advances the state-of-the-art in computer science.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 3.txt"
        },
        "page_content":"\u2022 11-747: Neural Networks for NLP  \n\u2022 11-751:  Speech Recognition  \n\u2022 11-775:  Large -Scale Multimedia  \n\u2022 11-776: Multimodal Affective Computing  \n\u2022 11-777: Multimodal Machine Learning  \n\u2022 11-785:  Deep Learning  \n\u2022 11-797: Question Answering  \n \nStudents may request to have other  LTI course s with a group engineering project component to \nbe added to this list.   \nFor definitions of quoted terms, see the section on \u201cDefinitions of LTI Terminology .\u201d \nUnless approved by the Program Director in advance, t he course requirements must be \nsatisfied by actual classroom courses, not credit given for research or independent study.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe Master of Computational Data Science (MCDS) at LTI focuses on engineering and deploying large-scale information systems.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Which masters program at LTI focus on engineering and deploying large-scale information systems?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nOverview: The MCDS degree focuses on engineering and deploying large-scale information systems. Our comprehensive curriculum equips you with the skills and knowledge to develop the layers of technology involved in the next generation of massive information system deployments and analyze the data these systems generate. When you graduate, you\u2019ll have a unified vision of these systems from your core courses; internship experience; and semester-long, group-oriented capstone project. MCDS graduates are sought-after software engineers, data scientists and project managers at leading information technology, software services and social media\n-----\nThis handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing, \ndialogue systems, information retrieval, machine translation, speech processing,  video \nunderstanding, multimodal systems, automated reasoning, and other topics related to analysis \nand understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan\n-----\n\u2022 Dual -Degree Ph.D. in Language and Information Technologies (CMU -PT Ph.D.)  \n\u2022 Masters in Language Technologies (MLT)  \n\u2022 Master of Science in Intelligent Information Systems (MIIS)  \n\u2022 Master of Computational Data Science  (MCDS)  \n\u2022 Master of Science in Artificial Intelligence and Innovation  (MSAII)  \nLTI Ph.D.  Graduate Student Handbook  Page 10 \n This handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing,\n-----\nOverview: The LTI offers a dual-degree Ph.D. in Language and Information Technologies in cooperation with:\n-----\noffered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MIIS degree provides advanced study \nand practical experience in areas of Computer Science focused on the processing and analysis \nof unstructured and semi -structured information, for example, text, image, video, speech, and \naudio information. It is a practice -oriented professional degree designed for students who \nwant to rapidly master advanced content -analysis, mining, and intelligent information \ntechnologies prior to beginning or resuming leadership careers in industry and government.\n-----\nand understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan  \nPh.D. Program Director  \nProfessor  \nGHC 5419 \ncallan@cs.cmu.edu  \n412-268-4525  Stacey Young  \nPh.D. Academic Program Manager  \nLTI Graduate Program Manager  \nGHC 6415  \nstaceyy@cs.cmu.edu   \n412-268-2623  \nMona Diab  \nLTI Director  \nProfessor  \nGHC 5723 \nmdiab@andrew.cmu.edu  \n412-268-3669  \n \nJoan Axelson  \nOffice Manager  \nGHC 5405  \njaxelson@andrew.cmu.edu  \n412-268-7517  \n Julie Nys\n-----\nPh.D. students are given access to the LTI\u2019s computer cluster on an as- needed basis, to be used for \ncourse assignments, directed study projects, and\/or capstone projects.  The LTI cluster provides \nstorage and computation for projects involving large datasets and\/or lengthy computation.  \nPh.D. students receive two types of user ids: An Andrew id and a CS id. All CMU students have \nan Andrew id. Computer Science students also have a CS id that provides access to SCS -specific \nresources (e.g., computer clusters). CS ids are being phased out very slowly, so it is likely that you will need both types of user id.\n-----\nof ideas, where research, creativity, innovation, and entrepreneurship can flourish; and (c) \nensuring  individuals can achieve their full potential.  \n \nTo impact society in a transformative way  \u2014 regionally, nationally, and globally \u2014  by engaging  \nwith partners outside the traditional borders of the university campus.  \n1.3 The MIIS Degree  \nThe Master of Science in Intelligent Information Systems (MIIS) is a professional degree \noffered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MIIS degree provides advanced study\n-----\nOverview: The Ph.D. in LTI focuses on developing the next generation of scientific and entrepreneurial leaders. The first two years of the Ph.D. program are similar to our MLT program. After the second year, you will spend most of your time working closely with your faculty advisor on research that advances the state-of-the-art in computer science.\n-----\n\u2022 11-747: Neural Networks for NLP  \n\u2022 11-751:  Speech Recognition  \n\u2022 11-775:  Large -Scale Multimedia  \n\u2022 11-776: Multimodal Affective Computing  \n\u2022 11-777: Multimodal Machine Learning  \n\u2022 11-785:  Deep Learning  \n\u2022 11-797: Question Answering  \n \nStudents may request to have other  LTI course s with a group engineering project component to \nbe added to this list.   \nFor definitions of quoted terms, see the section on \u201cDefinitions of LTI Terminology .\u201d \nUnless approved by the Program Director in advance, t he course requirements must be \nsatisfied by actual classroom courses, not credit given for research or independent study.\n-----\n\n### Response ###\n\nUser: Which masters program at LTI focus on engineering and deploying large-scale information systems?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.0,
    "recall":0.0,
    "precision":0.0,
    "A_hat":"",
    "index":12,
    "Q":"Which program that LTI offers partners with universities in Portugal?",
    "A":"Dual-Degree Ph.D. in Language and Information Technologies",
    "category":"programs",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Universidade Nova de Lisboa, Faculdade de Ci\u00eancias e Tecnologia \u2013 FCTUNL (Ph.D. in Computer Science)\nUniversidade de Coimbra, Faculdade de Ci\u00eancias e Tecnologia \u2013 FCTUC (Ph.D. in Information Science and Technology)\nStudents jointly enrolled in the LTI Ph.D program spend a year in Portugal, then two years at Carnegie Mellon taking classes in linguistics, computer science, statistical learning and task orientation.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Overview: The LTI offers a dual-degree Ph.D. in Language and Information Technologies in cooperation with:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"In addition to the SCS guidelines, the LTI requires:\n\nA short (1-3 minute) video of yourself. There will be a prompt question that you will respond to. You will have three attempts. This is not a required part of the application process, but it's strongly suggested.\nAny outside funding you are receiving must be accompanied by an official award letter.\nNo incomplete applications will be eligible for consideration.\n\nFor specific application\/admissions questions, please contact Stacey Young.\nAdditional Info: For more information, see the CMU | Portugal website.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-700 LTI Colloquium.txt"
        },
        "page_content":"<start course metadata for 11-700 LTI Colloquium>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Yonatan Bisk\nRooms: POS A35\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-700 LTI Colloquium.txt"
        },
        "page_content":"<start course metadata for 11-700 LTI Colloquium>\nSemester: Spring 2024 (aka S24)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Instructor TBA, Yonatan Bisk\nRooms: DNM DNM; SH 105\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Requirements: Students participating in the dual-degree program will spend their first year in Portugal, followed by two years in Pittsburgh to complete their coursework. They will complete a maximum of eight courses with a proper balance of focus areas (linguistics, computer science, statistical\/learning and task orientation). After that, they will return to Portugal for their last two years, pursuing research and completing their dissertation. For more, see the Carnegie Mellon | Portugal page.\nCurriculum: While in the dual Ph.D. program, your schedule may look like this.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 5.txt"
        },
        "page_content":"Students that are already enrolled in an LTI degree  program are not required to retake GRE \nand TOEFL \/IELTS\/Duolingo  exams or to produce new transcripts from other universities.   \nThe MIIS program will conduct an expedited admissions process after receiving such a request.  The program will explicitly consider whether the coursework done prior to the \ntransfer will allow the student to be \u201con schedule\u201d by the end of the spring semest er, so that \nthe student can participate in a capstone project with other MIIS students during the next fall semester.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 3.txt"
        },
        "page_content":"4.1.7 Transferring Into the Ph.D.  Program  \nThe LTI does not allow direct transfers from its master\u2019s programs into its Ph.D.  program . The \nstudent must apply for the Ph.D.  at the usual time . However, students that are already enrolled in \nan LTI degree program are not required to retake GRE and TOEFL exams or to produce new \ntranscripts from other universities.  \n4.1.8 Transferring Out of the Ph.D.  Program  \nThe Ph.D.  program doe s not prevent students from transferring to another degree program . A \nstudent who is interested in transferring out of the Ph.D.  degree program should consult the",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Required Research\n\nYear 3\n(In Pittsburgh)\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 4\n(In Portugal)\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 5\n(In Portugal)\n\nDirected Research\n\nDirected Research\n\nDirected Research\nAdmission: Students applying to the dual degree program must apply through Carnegie Mellon's online application. In addition to the requirements listed below, prospective students must also contact Stacey Young when applying.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"An annual poster session helps spread information from MIIS students that recently completed internships to MIIS students that will soon seek internships; other LTI professional master\u2019s programs have similar internship- oriented poster sessions that MIIS students may attend. The \nuniversity offers resume -writing and interviewing workshops to help prepare students and fall \nand spring employment fairs to help students connect with companies.  The university\u2019s Career \n& Professional Development Center  https:\/\/www.cmu.edu\/career\/\n provides other services as \nwell.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Universidade Nova de Lisboa, Faculdade de Ci\u00eancias e Tecnologia \u2013 FCTUNL (Ph.D. in Computer Science)\nUniversidade de Coimbra, Faculdade de Ci\u00eancias e Tecnologia \u2013 FCTUC (Ph.D. in Information Science and Technology)\nStudents jointly enrolled in the LTI Ph.D program spend a year in Portugal, then two years at Carnegie Mellon taking classes in linguistics, computer science, statistical learning and task orientation.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Overview: The LTI offers a dual-degree Ph.D. in Language and Information Technologies in cooperation with:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"In addition to the SCS guidelines, the LTI requires:\n\nA short (1-3 minute) video of yourself. There will be a prompt question that you will respond to. You will have three attempts. This is not a required part of the application process, but it's strongly suggested.\nAny outside funding you are receiving must be accompanied by an official award letter.\nNo incomplete applications will be eligible for consideration.\n\nFor specific application\/admissions questions, please contact Stacey Young.\nAdditional Info: For more information, see the CMU | Portugal website.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-700 LTI Colloquium.txt"
        },
        "page_content":"<start course metadata for 11-700 LTI Colloquium>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Yonatan Bisk\nRooms: POS A35\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 11-700 LTI Colloquium.txt"
        },
        "page_content":"<start course metadata for 11-700 LTI Colloquium>\nSemester: Spring 2024 (aka S24)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Instructor TBA, Yonatan Bisk\nRooms: DNM DNM; SH 105\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Requirements: Students participating in the dual-degree program will spend their first year in Portugal, followed by two years in Pittsburgh to complete their coursework. They will complete a maximum of eight courses with a proper balance of focus areas (linguistics, computer science, statistical\/learning and task orientation). After that, they will return to Portugal for their last two years, pursuing research and completing their dissertation. For more, see the Carnegie Mellon | Portugal page.\nCurriculum: While in the dual Ph.D. program, your schedule may look like this.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 5.txt"
        },
        "page_content":"Students that are already enrolled in an LTI degree  program are not required to retake GRE \nand TOEFL \/IELTS\/Duolingo  exams or to produce new transcripts from other universities.   \nThe MIIS program will conduct an expedited admissions process after receiving such a request.  The program will explicitly consider whether the coursework done prior to the \ntransfer will allow the student to be \u201con schedule\u201d by the end of the spring semest er, so that \nthe student can participate in a capstone project with other MIIS students during the next fall semester.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 3.txt"
        },
        "page_content":"4.1.7 Transferring Into the Ph.D.  Program  \nThe LTI does not allow direct transfers from its master\u2019s programs into its Ph.D.  program . The \nstudent must apply for the Ph.D.  at the usual time . However, students that are already enrolled in \nan LTI degree program are not required to retake GRE and TOEFL exams or to produce new \ntranscripts from other universities.  \n4.1.8 Transferring Out of the Ph.D.  Program  \nThe Ph.D.  program doe s not prevent students from transferring to another degree program . A \nstudent who is interested in transferring out of the Ph.D.  degree program should consult the",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Required Research\n\nYear 3\n(In Pittsburgh)\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 4\n(In Portugal)\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 5\n(In Portugal)\n\nDirected Research\n\nDirected Research\n\nDirected Research\nAdmission: Students applying to the dual degree program must apply through Carnegie Mellon's online application. In addition to the requirements listed below, prospective students must also contact Stacey Young when applying.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"An annual poster session helps spread information from MIIS students that recently completed internships to MIIS students that will soon seek internships; other LTI professional master\u2019s programs have similar internship- oriented poster sessions that MIIS students may attend. The \nuniversity offers resume -writing and interviewing workshops to help prepare students and fall \nand spring employment fairs to help students connect with companies.  The university\u2019s Career \n& Professional Development Center  https:\/\/www.cmu.edu\/career\/\n provides other services as \nwell.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe program that LTI offers that partners with universities in Portugal is the dual-degree Ph.D. in Language and Information Technologies in cooperation with Universidade Nova de Lisboa, Faculdade de Ci\u00eancias e Tecnologia \u2013 FCTUNL (Ph.D. in Computer Science) and Universidade de Coimbra, Faculdade de Ci\u00eancias e Tecnologia \u2013 FCTUC (Ph.D. in Information",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Which program that LTI offers partners with universities in Portugal?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nUniversidade Nova de Lisboa, Faculdade de Ci\u00eancias e Tecnologia \u2013 FCTUNL (Ph.D. in Computer Science)\nUniversidade de Coimbra, Faculdade de Ci\u00eancias e Tecnologia \u2013 FCTUC (Ph.D. in Information Science and Technology)\nStudents jointly enrolled in the LTI Ph.D program spend a year in Portugal, then two years at Carnegie Mellon taking classes in linguistics, computer science, statistical learning and task orientation.\n-----\nOverview: The LTI offers a dual-degree Ph.D. in Language and Information Technologies in cooperation with:\n-----\nIn addition to the SCS guidelines, the LTI requires:\n\nA short (1-3 minute) video of yourself. There will be a prompt question that you will respond to. You will have three attempts. This is not a required part of the application process, but it's strongly suggested.\nAny outside funding you are receiving must be accompanied by an official award letter.\nNo incomplete applications will be eligible for consideration.\n\nFor specific application\/admissions questions, please contact Stacey Young.\nAdditional Info: For more information, see the CMU | Portugal website.\n-----\n<start course metadata for 11-700 LTI Colloquium>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Yonatan Bisk\nRooms: POS A35\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>\n-----\n<start course metadata for 11-700 LTI Colloquium>\nSemester: Spring 2024 (aka S24)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Instructor TBA, Yonatan Bisk\nRooms: DNM DNM; SH 105\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>\n-----\nRequirements: Students participating in the dual-degree program will spend their first year in Portugal, followed by two years in Pittsburgh to complete their coursework. They will complete a maximum of eight courses with a proper balance of focus areas (linguistics, computer science, statistical\/learning and task orientation). After that, they will return to Portugal for their last two years, pursuing research and completing their dissertation. For more, see the Carnegie Mellon | Portugal page.\nCurriculum: While in the dual Ph.D. program, your schedule may look like this.\n-----\nStudents that are already enrolled in an LTI degree  program are not required to retake GRE \nand TOEFL \/IELTS\/Duolingo  exams or to produce new transcripts from other universities.   \nThe MIIS program will conduct an expedited admissions process after receiving such a request.  The program will explicitly consider whether the coursework done prior to the \ntransfer will allow the student to be \u201con schedule\u201d by the end of the spring semest er, so that \nthe student can participate in a capstone project with other MIIS students during the next fall semester.\n-----\n4.1.7 Transferring Into the Ph.D.  Program  \nThe LTI does not allow direct transfers from its master\u2019s programs into its Ph.D.  program . The \nstudent must apply for the Ph.D.  at the usual time . However, students that are already enrolled in \nan LTI degree program are not required to retake GRE and TOEFL exams or to produce new \ntranscripts from other universities.  \n4.1.8 Transferring Out of the Ph.D.  Program  \nThe Ph.D.  program doe s not prevent students from transferring to another degree program . A \nstudent who is interested in transferring out of the Ph.D.  degree program should consult the\n-----\nRequired Research\n\nYear 3\n(In Pittsburgh)\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 4\n(In Portugal)\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 5\n(In Portugal)\n\nDirected Research\n\nDirected Research\n\nDirected Research\nAdmission: Students applying to the dual degree program must apply through Carnegie Mellon's online application. In addition to the requirements listed below, prospective students must also contact Stacey Young when applying.\n-----\nAn annual poster session helps spread information from MIIS students that recently completed internships to MIIS students that will soon seek internships; other LTI professional master\u2019s programs have similar internship- oriented poster sessions that MIIS students may attend. The \nuniversity offers resume -writing and interviewing workshops to help prepare students and fall \nand spring employment fairs to help students connect with companies.  The university\u2019s Career \n& Professional Development Center  https:\/\/www.cmu.edu\/career\/\n provides other services as \nwell.\n-----\n\n### Response ###\n\nUser: Which program that LTI offers partners with universities in Portugal?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.5,
    "recall":0.5,
    "precision":0.5,
    "A_hat":"36 units",
    "index":13,
    "Q":"What is the minimum number of units of coursework needed to complete a Master of Science in Artificial Intelligence and Innovation?",
    "A":"195 units",
    "category":"programs",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 9.txt"
        },
        "page_content":"\uf0b7 Artificial Intelligence and Future Markets (11-651) \u2013 No prerequisite. \n\uf0b7 AI Engineering (11-695) \u2013 Prerequisite is the completion of 11-651 with a grade of \u201cB\u201d or \nbetter. \n\uf0b7 LTI Practicum (11-935) \u2013 Three credit units for completing the required Internship. \n\uf0b7 AI Innovation (11-654) \u2013 Prerequisite is the completion of 11- 695 with a grade of \u201cB\u201d or \nbetter. \n\uf0b7 Capstone (11-699) \u2013 Prerequisite is the completion of 11-654 with a grade of \u201cB\u201d or better.  \nStudents are required to repeat any required course that they have completed with a grade less",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 17-737 Artificial Intelligence Methods for Social Good.txt"
        },
        "page_content":"should be of interest to students in several other departments, including ECE, EPP and SDS This 12-unit course is only open to graduate students (master and Ph.D. students) with previous programming experience and background knowledge in artificial intelligence. The students will work in groups on a research project with a research-style paper and an oral presentation delivered at the end of the semester. Please see the instructor if you are unsure whether your background is suitable for the course.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Artificial Intelligence and Innovation (MSAII).txt"
        },
        "page_content":"For full requirements and program details, read the MSAII Handbook.\nCurriculum: The MSAII degree generally takes four semesters. Here's an example of how your coursework might break down:\n\nSemester One\n\nSemester Two\n\nSemester Three\n\nSemester Four\n\nArtificial Intelligence and Future Markets\n\nLaw of Computer Technology\n\nCoding Bootcamp\n\nMachine Learning\n\nAI Engineering\n\nMachine Learning with Large Datasets\n\nCloud Computing*\n\nSoftware Engineering for Startups*\n\nAI Innovation\n\nNatural Language Processing\n\nApplied Machine Learning\n\nWeb Application Development*\n\nDeep Learning\n\nCapstone Project\n(36 units)\n\n*Elective course",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"4.2 Required Units for Degree Attainment  \nTo complete the Master of Science in Intelligent Information Systems, a student must satisfy \nthree types of requirements. Curricular requirements ensure that MIIS students receive \ninstruction in core intelligent information systems technologies while also allowing an \nopportunity to specialize in areas of personal interest.  Practice requirements are opportunities \nto apply and hone new skills while building state -of-the-art systems. Grade  requirements ensure \nthat students have demonstrated a certain level of skill while completing degree requirements.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Artificial Intelligence and Innovation (MSAII).txt"
        },
        "page_content":"Overview: The Master of Science in Artificial Intelligence and Innovation (MSAII) program is a successor to the M.S. in Biotechnology, Innovation and Computing (MSBIC). It combines a rigorous AI and machine learning curriculum with real-world team experience in identifying an AI market niche and developing a responsive product in cooperation with external stakeholders. The core program, which lasts four semesters and leads to a capstone project, focuses on both intrapreneurship and entrepreneurship, equipping graduates to either begin a startup or develop a new organization within an existing company. Students will also gain critical",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 9.txt"
        },
        "page_content":"the Knowledge Area Courses, students must maintain a B average .  No grade lower than C (or \nPass in the case of Pass\/No Pass courses) shall be used for credit applied toward graduation.  \nUnder SCS policy, only a grade of C or higher will be regarded as a Pass in a Pass\/No Pass \ncourse.  No undergraduate courses count toward the 195-unit requirement. \nAll Core courses are organized in sequence, and must be taken in the following order: \n\uf0b7 Artificial Intelligence and Future Markets (11-651) \u2013 No prerequisite. \n\uf0b7 AI Engineering (11-695) \u2013 Prerequisite is the completion of 11-651 with a grade of \u201cB\u201d or \nbetter.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 15-281 Artificial Intelligence_ Representation and Problem Solving.txt"
        },
        "page_content":"<start course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>\nSemester: Spring 2024 (aka S24)\nCourse Name: Artificial Intelligence: Representation and Problem Solving\nCourse Number: 15-281\nDepartment: Computer Science\nNumber of Units: 12\nPrerequisites: (15-122) and (21-240 or 21-241 or 18-202 or 21-254) and (15-151 or 21-127 or 21-128)\nInstructors: Nihar Shah, Tuomas Sandholm\nRooms: HOA 160\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 49-779 Applied AI (Artificial Intelligence).txt"
        },
        "page_content":"<start course metadata for 49-779 Applied AI (Artificial Intelligence)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Applied AI (Artificial Intelligence)\nCourse Number: 49-779\nDepartment: Integrated Innovation Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Lake Dai\nRooms: B23 118\nLocations: San Jose, California\n<\/end course metadata for 49-779 Applied AI (Artificial Intelligence)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 15-281 Artificial Intelligence_ Representation and Problem Solving.txt"
        },
        "page_content":"<start course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>\nSemester: Fall 2023 (aka F23)\nCourse Name: Artificial Intelligence: Representation and Problem Solving\nCourse Number: 15-281\nDepartment: Computer Science\nNumber of Units: 12\nPrerequisites: (15-122) and (21-240 or 21-241 or 18-202 or 21-254) and (15-151 or 21-127 or 21-128)\nInstructors: Aditi Raghunathan, Vincent Conitzer\nRooms: DH 2210\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 9.txt"
        },
        "page_content":"summer prior to entrance.    \n10.3.2  Monitoring Progress  \nThe advisor meets with the student at least twice a year, providing guidance and monitoring the \nstudent\u2019s overall progress.   \n10.3.3  Degree Certification  \nStudents who graduate having met all the requirements for the degree will receive a diploma \nstating that they have received a \u201cMaster of Science in Artificial Intelligence and Innovation.\u201d \n18 \n\u00a010.4 Internship   \nStudents must obtain an internship during the summer between the first and second years of the \nprogram.  This is a requirement.  An internship will provide students with the opportunity to",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 9.txt"
        },
        "page_content":"\uf0b7 Artificial Intelligence and Future Markets (11-651) \u2013 No prerequisite. \n\uf0b7 AI Engineering (11-695) \u2013 Prerequisite is the completion of 11-651 with a grade of \u201cB\u201d or \nbetter. \n\uf0b7 LTI Practicum (11-935) \u2013 Three credit units for completing the required Internship. \n\uf0b7 AI Innovation (11-654) \u2013 Prerequisite is the completion of 11- 695 with a grade of \u201cB\u201d or \nbetter. \n\uf0b7 Capstone (11-699) \u2013 Prerequisite is the completion of 11-654 with a grade of \u201cB\u201d or better.  \nStudents are required to repeat any required course that they have completed with a grade less",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 17-737 Artificial Intelligence Methods for Social Good.txt"
        },
        "page_content":"should be of interest to students in several other departments, including ECE, EPP and SDS This 12-unit course is only open to graduate students (master and Ph.D. students) with previous programming experience and background knowledge in artificial intelligence. The students will work in groups on a research project with a research-style paper and an oral presentation delivered at the end of the semester. Please see the instructor if you are unsure whether your background is suitable for the course.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Artificial Intelligence and Innovation (MSAII).txt"
        },
        "page_content":"For full requirements and program details, read the MSAII Handbook.\nCurriculum: The MSAII degree generally takes four semesters. Here's an example of how your coursework might break down:\n\nSemester One\n\nSemester Two\n\nSemester Three\n\nSemester Four\n\nArtificial Intelligence and Future Markets\n\nLaw of Computer Technology\n\nCoding Bootcamp\n\nMachine Learning\n\nAI Engineering\n\nMachine Learning with Large Datasets\n\nCloud Computing*\n\nSoftware Engineering for Startups*\n\nAI Innovation\n\nNatural Language Processing\n\nApplied Machine Learning\n\nWeb Application Development*\n\nDeep Learning\n\nCapstone Project\n(36 units)\n\n*Elective course",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"4.2 Required Units for Degree Attainment  \nTo complete the Master of Science in Intelligent Information Systems, a student must satisfy \nthree types of requirements. Curricular requirements ensure that MIIS students receive \ninstruction in core intelligent information systems technologies while also allowing an \nopportunity to specialize in areas of personal interest.  Practice requirements are opportunities \nto apply and hone new skills while building state -of-the-art systems. Grade  requirements ensure \nthat students have demonstrated a certain level of skill while completing degree requirements.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Artificial Intelligence and Innovation (MSAII).txt"
        },
        "page_content":"Overview: The Master of Science in Artificial Intelligence and Innovation (MSAII) program is a successor to the M.S. in Biotechnology, Innovation and Computing (MSBIC). It combines a rigorous AI and machine learning curriculum with real-world team experience in identifying an AI market niche and developing a responsive product in cooperation with external stakeholders. The core program, which lasts four semesters and leads to a capstone project, focuses on both intrapreneurship and entrepreneurship, equipping graduates to either begin a startup or develop a new organization within an existing company. Students will also gain critical",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 9.txt"
        },
        "page_content":"the Knowledge Area Courses, students must maintain a B average .  No grade lower than C (or \nPass in the case of Pass\/No Pass courses) shall be used for credit applied toward graduation.  \nUnder SCS policy, only a grade of C or higher will be regarded as a Pass in a Pass\/No Pass \ncourse.  No undergraduate courses count toward the 195-unit requirement. \nAll Core courses are organized in sequence, and must be taken in the following order: \n\uf0b7 Artificial Intelligence and Future Markets (11-651) \u2013 No prerequisite. \n\uf0b7 AI Engineering (11-695) \u2013 Prerequisite is the completion of 11-651 with a grade of \u201cB\u201d or \nbetter.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 15-281 Artificial Intelligence_ Representation and Problem Solving.txt"
        },
        "page_content":"<start course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>\nSemester: Spring 2024 (aka S24)\nCourse Name: Artificial Intelligence: Representation and Problem Solving\nCourse Number: 15-281\nDepartment: Computer Science\nNumber of Units: 12\nPrerequisites: (15-122) and (21-240 or 21-241 or 18-202 or 21-254) and (15-151 or 21-127 or 21-128)\nInstructors: Nihar Shah, Tuomas Sandholm\nRooms: HOA 160\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 49-779 Applied AI (Artificial Intelligence).txt"
        },
        "page_content":"<start course metadata for 49-779 Applied AI (Artificial Intelligence)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Applied AI (Artificial Intelligence)\nCourse Number: 49-779\nDepartment: Integrated Innovation Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Lake Dai\nRooms: B23 118\nLocations: San Jose, California\n<\/end course metadata for 49-779 Applied AI (Artificial Intelligence)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 15-281 Artificial Intelligence_ Representation and Problem Solving.txt"
        },
        "page_content":"<start course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>\nSemester: Fall 2023 (aka F23)\nCourse Name: Artificial Intelligence: Representation and Problem Solving\nCourse Number: 15-281\nDepartment: Computer Science\nNumber of Units: 12\nPrerequisites: (15-122) and (21-240 or 21-241 or 18-202 or 21-254) and (15-151 or 21-127 or 21-128)\nInstructors: Aditi Raghunathan, Vincent Conitzer\nRooms: DH 2210\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 9.txt"
        },
        "page_content":"summer prior to entrance.    \n10.3.2  Monitoring Progress  \nThe advisor meets with the student at least twice a year, providing guidance and monitoring the \nstudent\u2019s overall progress.   \n10.3.3  Degree Certification  \nStudents who graduate having met all the requirements for the degree will receive a diploma \nstating that they have received a \u201cMaster of Science in Artificial Intelligence and Innovation.\u201d \n18 \n\u00a010.4 Internship   \nStudents must obtain an internship during the summer between the first and second years of the \nprogram.  This is a requirement.  An internship will provide students with the opportunity to",
        "type":"Document"
      }
    ],
    "model_output":"\nThe minimum number of units of coursework needed to complete a Master of Science in Artificial Intelligence and Innovation is 36 units.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"What is the minimum number of units of coursework needed to complete a Master of Science in Artificial Intelligence and Innovation?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n\uf0b7 Artificial Intelligence and Future Markets (11-651) \u2013 No prerequisite. \n\uf0b7 AI Engineering (11-695) \u2013 Prerequisite is the completion of 11-651 with a grade of \u201cB\u201d or \nbetter. \n\uf0b7 LTI Practicum (11-935) \u2013 Three credit units for completing the required Internship. \n\uf0b7 AI Innovation (11-654) \u2013 Prerequisite is the completion of 11- 695 with a grade of \u201cB\u201d or \nbetter. \n\uf0b7 Capstone (11-699) \u2013 Prerequisite is the completion of 11-654 with a grade of \u201cB\u201d or better.  \nStudents are required to repeat any required course that they have completed with a grade less\n-----\nshould be of interest to students in several other departments, including ECE, EPP and SDS This 12-unit course is only open to graduate students (master and Ph.D. students) with previous programming experience and background knowledge in artificial intelligence. The students will work in groups on a research project with a research-style paper and an oral presentation delivered at the end of the semester. Please see the instructor if you are unsure whether your background is suitable for the course.\n-----\nFor full requirements and program details, read the MSAII Handbook.\nCurriculum: The MSAII degree generally takes four semesters. Here's an example of how your coursework might break down:\n\nSemester One\n\nSemester Two\n\nSemester Three\n\nSemester Four\n\nArtificial Intelligence and Future Markets\n\nLaw of Computer Technology\n\nCoding Bootcamp\n\nMachine Learning\n\nAI Engineering\n\nMachine Learning with Large Datasets\n\nCloud Computing*\n\nSoftware Engineering for Startups*\n\nAI Innovation\n\nNatural Language Processing\n\nApplied Machine Learning\n\nWeb Application Development*\n\nDeep Learning\n\nCapstone Project\n(36 units)\n\n*Elective course\n-----\n4.2 Required Units for Degree Attainment  \nTo complete the Master of Science in Intelligent Information Systems, a student must satisfy \nthree types of requirements. Curricular requirements ensure that MIIS students receive \ninstruction in core intelligent information systems technologies while also allowing an \nopportunity to specialize in areas of personal interest.  Practice requirements are opportunities \nto apply and hone new skills while building state -of-the-art systems. Grade  requirements ensure \nthat students have demonstrated a certain level of skill while completing degree requirements.\n-----\nOverview: The Master of Science in Artificial Intelligence and Innovation (MSAII) program is a successor to the M.S. in Biotechnology, Innovation and Computing (MSBIC). It combines a rigorous AI and machine learning curriculum with real-world team experience in identifying an AI market niche and developing a responsive product in cooperation with external stakeholders. The core program, which lasts four semesters and leads to a capstone project, focuses on both intrapreneurship and entrepreneurship, equipping graduates to either begin a startup or develop a new organization within an existing company. Students will also gain critical\n-----\nthe Knowledge Area Courses, students must maintain a B average .  No grade lower than C (or \nPass in the case of Pass\/No Pass courses) shall be used for credit applied toward graduation.  \nUnder SCS policy, only a grade of C or higher will be regarded as a Pass in a Pass\/No Pass \ncourse.  No undergraduate courses count toward the 195-unit requirement. \nAll Core courses are organized in sequence, and must be taken in the following order: \n\uf0b7 Artificial Intelligence and Future Markets (11-651) \u2013 No prerequisite. \n\uf0b7 AI Engineering (11-695) \u2013 Prerequisite is the completion of 11-651 with a grade of \u201cB\u201d or \nbetter.\n-----\n<start course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>\nSemester: Spring 2024 (aka S24)\nCourse Name: Artificial Intelligence: Representation and Problem Solving\nCourse Number: 15-281\nDepartment: Computer Science\nNumber of Units: 12\nPrerequisites: (15-122) and (21-240 or 21-241 or 18-202 or 21-254) and (15-151 or 21-127 or 21-128)\nInstructors: Nihar Shah, Tuomas Sandholm\nRooms: HOA 160\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>\n-----\n<start course metadata for 49-779 Applied AI (Artificial Intelligence)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Applied AI (Artificial Intelligence)\nCourse Number: 49-779\nDepartment: Integrated Innovation Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Lake Dai\nRooms: B23 118\nLocations: San Jose, California\n<\/end course metadata for 49-779 Applied AI (Artificial Intelligence)>\n-----\n<start course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>\nSemester: Fall 2023 (aka F23)\nCourse Name: Artificial Intelligence: Representation and Problem Solving\nCourse Number: 15-281\nDepartment: Computer Science\nNumber of Units: 12\nPrerequisites: (15-122) and (21-240 or 21-241 or 18-202 or 21-254) and (15-151 or 21-127 or 21-128)\nInstructors: Aditi Raghunathan, Vincent Conitzer\nRooms: DH 2210\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 15-281 Artificial Intelligence: Representation and Problem Solving>\n-----\nsummer prior to entrance.    \n10.3.2  Monitoring Progress  \nThe advisor meets with the student at least twice a year, providing guidance and monitoring the \nstudent\u2019s overall progress.   \n10.3.3  Degree Certification  \nStudents who graduate having met all the requirements for the degree will receive a diploma \nstating that they have received a \u201cMaster of Science in Artificial Intelligence and Innovation.\u201d \n18 \n\u00a010.4 Internship   \nStudents must obtain an internship during the summer between the first and second years of the \nprogram.  This is a requirement.  An internship will provide students with the opportunity to\n-----\n\n### Response ###\n\nUser: What is the minimum number of units of coursework needed to complete a Master of Science in Artificial Intelligence and Innovation?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Jennifer M. Lucas",
    "index":14,
    "Q":"Who's the Academic Program Manager of the Master of Computational Data Science Program?",
    "A":"Jennifer M Lucas",
    "category":"programs",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"university campus. \n1.4 MCDS Contact Information \nThe people responsible for administering the MCDS degree are: \n \nJennifer M Lucas  \nAcademic Program Manager \nMaster of Computational Data Science  \nLanguage Technologies Institute \nSchool of Computer Science  \nCarnegie Mellon University \nGates-Hillman Center 6415 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268-9870 \nFax: (412) 268-7287 \n  Carolyn Penstein Ros\u00e9, Director  \nMaster of Computational Data Science  \nLanguage Technologies Institute \nSchool of Computer Science \nCarnegie Mellon University \nGates-Hillman Center 5419 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268-4525",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"Carolyn Penstein Ros\u00e9, Director  \nMaster of Computational Data Science  \nLanguage Technologies Institute \nSchool of Computer Science \nCarnegie Mellon University \nGates-Hillman Center 5419 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268-4525 \nFax: (412) 268-7287 \nRobert Frederking  \nGraduate Program Chair \nLanguage Technologies Institute \nSchool of Computer Science  \nCarnegie Mellon University \nGates-Hillman Center 6515 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268 -6656 Mona Diab, LTI Director  \nLanguage Technologies Institute \nSchool of Computer Science  \nCarnegie Mellon University \nGates-Hillman Center 5723",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"attracting and retaining diverse, world-class talent; (b) creating a \ncollaborative environment open to the free exchange of ideas, where \nresearch, creativity, innovation, and entrepreneurship can flourish; and \n(c) ensuring individuals can achieve their full potential. \nTo impact society in a transformative way  \u2014 regionally, nationally, and \nglobally \u2014 by engaging with partners outside the traditional borders of the \nuniversity campus. \n1.4 MCDS Contact Information \nThe people responsible for administering the MCDS degree are: \n \nJennifer M Lucas  \nAcademic Program Manager \nMaster of Computational Data Science",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"MCDS Handbook 23-24 AY\n1 Welcome \nWelcome to the Language Technologies Institute, Master of \nComputational Data Science Program. While this handbook is specific to \nyour academic experience in the department, there are several other \nresources and offices graduate students are encouraged to consult during \ntheir tenure at Carnegie Mellon University. Information about The Word, \nthe student handbook, the Office of Graduate and Postdoctoral Affairs, the \nOffice of the Dean of Students, and others are included in Appendix A of \nthis handbook. \n1.1 The MCDS Degree \nThe MCDS Degree The Master of Computational Data Science (MCDS)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"Office of the Dean of Students, and others are included in Appendix A of \nthis handbook. \n1.1 The MCDS Degree \nThe MCDS Degree The Master of Computational Data Science (MCDS) \ndegree is a professional Master of Science degree offered by the Language \nTechnologies Institute (LTI), a department in the School of Computer \nScience at Carnegie Mellon University. The MCDS degree offers students \nwith a Bachelor's degree the opportunity to improve their training with \nadvanced study in Computer Science and Machine Learning. We cater to \nstudents with basic analytic skills and a strong aptitude for mathematics,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"This handbook describes the policies, procedures, and requirements for \nthe Master of Computational Data Science (MCDS) degree. \nAll policies not explicitly described in this document conform to School of \nComputer Science (SCS) policies and university policies described in The \nWord, Carnegie Mellon University Student Handbook and at the \nUniversity Policies website. \n1.2 Vision \nCarnegie Mellon University will have a transformative impact on society \nthrough continual innovation in education, research, creativity, and \nentrepreneurship. \n1.3 Mission \nTo create a transformative educational experience  for students focused on",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"preferential treatment. \n \nThere are significant differences between CMU's different departments \nand degree programs in philosophical approach, procedures, policies and \nregulations. Each department issues a handbook that informs graduate \nstudents of their program requirements and procedures and ensures that \nstudents have written access to the standard information outlined below. \nThis handbook describes the policies, procedures, and requirements for \nthe Master of Computational Data Science (MCDS) degree. \nAll policies not explicitly described in this document conform to School of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 2.txt"
        },
        "page_content":"All MCDS students are expected to pass the 11-637 Foundations of Computational Data \nScience course by the end of their first semester. Each student must pass 11-637 with a \ngrade of \u201cB\u201d or better.  \n3.3.5 Plan of study \nThe degree consists of two timing options based on the length of time the student spends \nworking on the degree. The student chooses their timing at the start of the degree \nprogram (for visa requirements). Changes in timing are possible with the approval of the \nDirector of the degree program and successful visa extension application with CMU\u2019s",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"and understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan  \nPh.D. Program Director  \nProfessor  \nGHC 5419 \ncallan@cs.cmu.edu  \n412-268-4525  Stacey Young  \nPh.D. Academic Program Manager  \nLTI Graduate Program Manager  \nGHC 6415  \nstaceyy@cs.cmu.edu   \n412-268-2623  \nMona Diab  \nLTI Director  \nProfessor  \nGHC 5723 \nmdiab@andrew.cmu.edu  \n412-268-3669  \n \nJoan Axelson  \nOffice Manager  \nGHC 5405  \njaxelson@andrew.cmu.edu  \n412-268-7517  \n Julie Nys",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 02-500 Undergraduate Research in Computational Biology.txt"
        },
        "page_content":"Semester: Spring 2024 (aka S24)\nCourse Description: This course is for undergraduate students who wish to do supervised research for academic credit with a computational biology faculty member. Interested students should first contact the Professor with whom they would like to work. If there is mutual interest, please get in touch with the undergraduate academic program coordinator and the undergraduate program director, who can add you to the course.     Students completing 02-500 should write a short essay summarizing their research experience as well as present their work at a departmental research gathering at the end of the semester.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"university campus. \n1.4 MCDS Contact Information \nThe people responsible for administering the MCDS degree are: \n \nJennifer M Lucas  \nAcademic Program Manager \nMaster of Computational Data Science  \nLanguage Technologies Institute \nSchool of Computer Science  \nCarnegie Mellon University \nGates-Hillman Center 6415 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268-9870 \nFax: (412) 268-7287 \n  Carolyn Penstein Ros\u00e9, Director  \nMaster of Computational Data Science  \nLanguage Technologies Institute \nSchool of Computer Science \nCarnegie Mellon University \nGates-Hillman Center 5419 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268-4525",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"Carolyn Penstein Ros\u00e9, Director  \nMaster of Computational Data Science  \nLanguage Technologies Institute \nSchool of Computer Science \nCarnegie Mellon University \nGates-Hillman Center 5419 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268-4525 \nFax: (412) 268-7287 \nRobert Frederking  \nGraduate Program Chair \nLanguage Technologies Institute \nSchool of Computer Science  \nCarnegie Mellon University \nGates-Hillman Center 6515 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268 -6656 Mona Diab, LTI Director  \nLanguage Technologies Institute \nSchool of Computer Science  \nCarnegie Mellon University \nGates-Hillman Center 5723",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"attracting and retaining diverse, world-class talent; (b) creating a \ncollaborative environment open to the free exchange of ideas, where \nresearch, creativity, innovation, and entrepreneurship can flourish; and \n(c) ensuring individuals can achieve their full potential. \nTo impact society in a transformative way  \u2014 regionally, nationally, and \nglobally \u2014 by engaging with partners outside the traditional borders of the \nuniversity campus. \n1.4 MCDS Contact Information \nThe people responsible for administering the MCDS degree are: \n \nJennifer M Lucas  \nAcademic Program Manager \nMaster of Computational Data Science",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"MCDS Handbook 23-24 AY\n1 Welcome \nWelcome to the Language Technologies Institute, Master of \nComputational Data Science Program. While this handbook is specific to \nyour academic experience in the department, there are several other \nresources and offices graduate students are encouraged to consult during \ntheir tenure at Carnegie Mellon University. Information about The Word, \nthe student handbook, the Office of Graduate and Postdoctoral Affairs, the \nOffice of the Dean of Students, and others are included in Appendix A of \nthis handbook. \n1.1 The MCDS Degree \nThe MCDS Degree The Master of Computational Data Science (MCDS)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"Office of the Dean of Students, and others are included in Appendix A of \nthis handbook. \n1.1 The MCDS Degree \nThe MCDS Degree The Master of Computational Data Science (MCDS) \ndegree is a professional Master of Science degree offered by the Language \nTechnologies Institute (LTI), a department in the School of Computer \nScience at Carnegie Mellon University. The MCDS degree offers students \nwith a Bachelor's degree the opportunity to improve their training with \nadvanced study in Computer Science and Machine Learning. We cater to \nstudents with basic analytic skills and a strong aptitude for mathematics,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"This handbook describes the policies, procedures, and requirements for \nthe Master of Computational Data Science (MCDS) degree. \nAll policies not explicitly described in this document conform to School of \nComputer Science (SCS) policies and university policies described in The \nWord, Carnegie Mellon University Student Handbook and at the \nUniversity Policies website. \n1.2 Vision \nCarnegie Mellon University will have a transformative impact on society \nthrough continual innovation in education, research, creativity, and \nentrepreneurship. \n1.3 Mission \nTo create a transformative educational experience  for students focused on",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 0.txt"
        },
        "page_content":"preferential treatment. \n \nThere are significant differences between CMU's different departments \nand degree programs in philosophical approach, procedures, policies and \nregulations. Each department issues a handbook that informs graduate \nstudents of their program requirements and procedures and ensures that \nstudents have written access to the standard information outlined below. \nThis handbook describes the policies, procedures, and requirements for \nthe Master of Computational Data Science (MCDS) degree. \nAll policies not explicitly described in this document conform to School of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 2.txt"
        },
        "page_content":"All MCDS students are expected to pass the 11-637 Foundations of Computational Data \nScience course by the end of their first semester. Each student must pass 11-637 with a \ngrade of \u201cB\u201d or better.  \n3.3.5 Plan of study \nThe degree consists of two timing options based on the length of time the student spends \nworking on the degree. The student chooses their timing at the start of the degree \nprogram (for visa requirements). Changes in timing are possible with the approval of the \nDirector of the degree program and successful visa extension application with CMU\u2019s",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"and understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan  \nPh.D. Program Director  \nProfessor  \nGHC 5419 \ncallan@cs.cmu.edu  \n412-268-4525  Stacey Young  \nPh.D. Academic Program Manager  \nLTI Graduate Program Manager  \nGHC 6415  \nstaceyy@cs.cmu.edu   \n412-268-2623  \nMona Diab  \nLTI Director  \nProfessor  \nGHC 5723 \nmdiab@andrew.cmu.edu  \n412-268-3669  \n \nJoan Axelson  \nOffice Manager  \nGHC 5405  \njaxelson@andrew.cmu.edu  \n412-268-7517  \n Julie Nys",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 02-500 Undergraduate Research in Computational Biology.txt"
        },
        "page_content":"Semester: Spring 2024 (aka S24)\nCourse Description: This course is for undergraduate students who wish to do supervised research for academic credit with a computational biology faculty member. Interested students should first contact the Professor with whom they would like to work. If there is mutual interest, please get in touch with the undergraduate academic program coordinator and the undergraduate program director, who can add you to the course.     Students completing 02-500 should write a short essay summarizing their research experience as well as present their work at a departmental research gathering at the end of the semester.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe Academic Program Manager of the Master of Computational Data Science Program is Jennifer M. Lucas.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Who's the Academic Program Manager of the Master of Computational Data Science Program?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nuniversity campus. \n1.4 MCDS Contact Information \nThe people responsible for administering the MCDS degree are: \n \nJennifer M Lucas  \nAcademic Program Manager \nMaster of Computational Data Science  \nLanguage Technologies Institute \nSchool of Computer Science  \nCarnegie Mellon University \nGates-Hillman Center 6415 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268-9870 \nFax: (412) 268-7287 \n  Carolyn Penstein Ros\u00e9, Director  \nMaster of Computational Data Science  \nLanguage Technologies Institute \nSchool of Computer Science \nCarnegie Mellon University \nGates-Hillman Center 5419 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268-4525\n-----\nCarolyn Penstein Ros\u00e9, Director  \nMaster of Computational Data Science  \nLanguage Technologies Institute \nSchool of Computer Science \nCarnegie Mellon University \nGates-Hillman Center 5419 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268-4525 \nFax: (412) 268-7287 \nRobert Frederking  \nGraduate Program Chair \nLanguage Technologies Institute \nSchool of Computer Science  \nCarnegie Mellon University \nGates-Hillman Center 6515 \n5000 Forbes Avenue, Pgh, PA 15213 \nPhone: (412) 268 -6656 Mona Diab, LTI Director  \nLanguage Technologies Institute \nSchool of Computer Science  \nCarnegie Mellon University \nGates-Hillman Center 5723\n-----\nattracting and retaining diverse, world-class talent; (b) creating a \ncollaborative environment open to the free exchange of ideas, where \nresearch, creativity, innovation, and entrepreneurship can flourish; and \n(c) ensuring individuals can achieve their full potential. \nTo impact society in a transformative way  \u2014 regionally, nationally, and \nglobally \u2014 by engaging with partners outside the traditional borders of the \nuniversity campus. \n1.4 MCDS Contact Information \nThe people responsible for administering the MCDS degree are: \n \nJennifer M Lucas  \nAcademic Program Manager \nMaster of Computational Data Science\n-----\nMCDS Handbook 23-24 AY\n1 Welcome \nWelcome to the Language Technologies Institute, Master of \nComputational Data Science Program. While this handbook is specific to \nyour academic experience in the department, there are several other \nresources and offices graduate students are encouraged to consult during \ntheir tenure at Carnegie Mellon University. Information about The Word, \nthe student handbook, the Office of Graduate and Postdoctoral Affairs, the \nOffice of the Dean of Students, and others are included in Appendix A of \nthis handbook. \n1.1 The MCDS Degree \nThe MCDS Degree The Master of Computational Data Science (MCDS)\n-----\nOffice of the Dean of Students, and others are included in Appendix A of \nthis handbook. \n1.1 The MCDS Degree \nThe MCDS Degree The Master of Computational Data Science (MCDS) \ndegree is a professional Master of Science degree offered by the Language \nTechnologies Institute (LTI), a department in the School of Computer \nScience at Carnegie Mellon University. The MCDS degree offers students \nwith a Bachelor's degree the opportunity to improve their training with \nadvanced study in Computer Science and Machine Learning. We cater to \nstudents with basic analytic skills and a strong aptitude for mathematics,\n-----\nThis handbook describes the policies, procedures, and requirements for \nthe Master of Computational Data Science (MCDS) degree. \nAll policies not explicitly described in this document conform to School of \nComputer Science (SCS) policies and university policies described in The \nWord, Carnegie Mellon University Student Handbook and at the \nUniversity Policies website. \n1.2 Vision \nCarnegie Mellon University will have a transformative impact on society \nthrough continual innovation in education, research, creativity, and \nentrepreneurship. \n1.3 Mission \nTo create a transformative educational experience  for students focused on\n-----\npreferential treatment. \n \nThere are significant differences between CMU's different departments \nand degree programs in philosophical approach, procedures, policies and \nregulations. Each department issues a handbook that informs graduate \nstudents of their program requirements and procedures and ensures that \nstudents have written access to the standard information outlined below. \nThis handbook describes the policies, procedures, and requirements for \nthe Master of Computational Data Science (MCDS) degree. \nAll policies not explicitly described in this document conform to School of\n-----\nAll MCDS students are expected to pass the 11-637 Foundations of Computational Data \nScience course by the end of their first semester. Each student must pass 11-637 with a \ngrade of \u201cB\u201d or better.  \n3.3.5 Plan of study \nThe degree consists of two timing options based on the length of time the student spends \nworking on the degree. The student chooses their timing at the start of the degree \nprogram (for visa requirements). Changes in timing are possible with the approval of the \nDirector of the degree program and successful visa extension application with CMU\u2019s\n-----\nand understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan  \nPh.D. Program Director  \nProfessor  \nGHC 5419 \ncallan@cs.cmu.edu  \n412-268-4525  Stacey Young  \nPh.D. Academic Program Manager  \nLTI Graduate Program Manager  \nGHC 6415  \nstaceyy@cs.cmu.edu   \n412-268-2623  \nMona Diab  \nLTI Director  \nProfessor  \nGHC 5723 \nmdiab@andrew.cmu.edu  \n412-268-3669  \n \nJoan Axelson  \nOffice Manager  \nGHC 5405  \njaxelson@andrew.cmu.edu  \n412-268-7517  \n Julie Nys\n-----\nSemester: Spring 2024 (aka S24)\nCourse Description: This course is for undergraduate students who wish to do supervised research for academic credit with a computational biology faculty member. Interested students should first contact the Professor with whom they would like to work. If there is mutual interest, please get in touch with the undergraduate academic program coordinator and the undergraduate program director, who can add you to the course.     Students completing 02-500 should write a short essay summarizing their research experience as well as present their work at a departmental research gathering at the end of the semester.\n-----\n\n### Response ###\n\nUser: Who's the Academic Program Manager of the Master of Computational Data Science Program?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.0,
    "recall":0.0,
    "precision":0.0,
    "A_hat":"3.0",
    "index":15,
    "Q":"What is the minimum letter grade needed for a course to count towards a Master of Language Technologies degree?",
    "A":"C",
    "category":"programs",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/LTI Concentration.txt"
        },
        "page_content":"Requirements: Students interested in the language technologies minor must complete our prerequisite courses with an average grade of B (3.0) or better before applying to the program. (Students who do not meet this average must submit a letter of explanation along with their application.) Prerequisites include:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 3.txt"
        },
        "page_content":"MLT Student Handbook 2023 - 2024\n4 MLT Degree Attainment  \n4.1 Course Requirements  \nIn order to  complete the Master of Language Technologies degree, the student must pass 120 \nor more course units of senior- to-graduate courses, and meet the following criteria:  \n\u2022 within those 120 units, at least 72 units of \u201cLTI\u201d courses and 24 units of \u201cSCS\u201d courses, \n\u2022 within those 72 units, 11 -711, 11- 791 (or an equivalent , see below ), and one ``Task \nOrientation Focus'' class, and  \n\u2022 within those 72 units, at least one of the following:  \no an LTI lab course,  \no 11-792, or  \no project -oriented Masters \u2019 thesis;",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"can also satisfy qualifying course requirements.  A student should get approval from the \ndirector for the breadth courses , if not listed below.  \n4.4 Approved Qualifying Courses  \nAny graduate course  (600 -level or higher) offered by the Language Technologies Institute is \na qualifying course.  \nAny two graduate courses (600 -level or higher) offered by departments within the SCS  \nrelevant to the MIIS degree other than LTI (Machine Learning or Computer Science departments, etc.) may be counted as approved qualifying courses .  \nMIIS Graduate Student Handbook  Page 15",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 3.txt"
        },
        "page_content":"readers, to be chosen by the student in consultation with the advisor, during the Fall \nMasters \u2019 Thesis I course. At least 2  of the 3 committee members must be SCS faculty \nworking in Language Technologies.  \n\u2022 To receive a final grade for the first semester's course, the student must have prepared a written proposal of at least five pages, describing the scientific thesis to be investigated, any relevant research already completed by the student, a comparison \nwith related work by others, and a detailed description of the work to be done in the \nnext semester. The proposal MUST be accepted by the committee by the end of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"a. Any graduate course (600 -level or higher) offered by the Language Technologies \nInstitute; and  \nb. Any graduate course (600 -level or higher) from the  list of approved qualifying \ncourses  (Section 3. 2.4). \n2. Free elective:  Students must pass 12 units (typically 1 course) in elective master\u2019s  \ncourse(s). A free elective is defined as:  \na. A graduate course (600 -level or higher)  with content relevant to the MIIS \nprogram objectives offered  by the School of Computer Science ; and  \nb. A course approved by the student's advisor and the degree Program Director.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 2.txt"
        },
        "page_content":"3.6 Completing a n M.S. Degree Enroute t o a Ph.D. \nCourses that satisfy LTI Ph.D. degree requirements may also be used to satisfy requirements for \none M.S. degree. The most common choice is the LTI\u2019s Master of Language Technologies (MLT) \ndegree because its requirements are similar (but not identical) to the Ph.D. requirements. Other M.S. degrees within the LTI and outside of the LTI are also possible.  \nLTI Ph.D.  Graduate Student Handbook  Page 20 \n Students interested in an M.S. degree other than the MLT degree should  discuss their plans with \ntheir Ph.D. advisor due to the additional courses and project work that may be involved.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"to apply and hone new skills while building state -of-the-art systems. Grade  requirements ensure \nthat students have demonstrated a certain level of skill while completing degree requirements. \nAll three types of requirements are described below.  \nMIIS -16 students must take at least 84 units (typically 7 12 -unit courses) of qualifying and \nelective courses that satisfy human language, machine learning, and language technology \napplications breadth requirements and 66 practice units for a total of 150 units to attain the \nStandard MIIS degree.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 2.txt"
        },
        "page_content":"PhD_Student_Handbook_2023-2024\n3 Standard Degree Requirements & Degree Certification                                        \n3.1 LTI Ph.D. Degree Requirements  \nTo complete the Ph.D.  in Language and Information Technologies degree, the student must satisfy \nthe following requirements:  \n\u2022 Pass at least 96  units of graduate level courses, with additional requirements detailed \nbelow ; \n\u2022 Satisfy proficiencies in Writing, Presentation, Programming, and Teaching ; \n\u2022 Propose , write, and defend a Ph.D.  dissertation (thesis) ; \n\u2022 Attend the LTI Colloquium (11 -700) each semester ; and \n\u2022 Satisfy the Research Speaking Requirement.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"4.3 Core Requirements  \nMIIS Graduate Student Handbook  Page 14  \n A MIIS  student must complete the following curricular requirements:  \n1. Qualifying courses:   \nMIIS -16 students must pass 72 units (typically 6 12 -unit courses) and MIIS -21 students \nmust complete 96 units (typically 8 12 -unit courses) in qualifying master\u2019s  courses.  \nA qualifying master\u2019s  course is defined as:  \na. Any graduate course (600 -level or higher) offered by the Language Technologies \nInstitute; and  \nb. Any graduate course (600 -level or higher) from the  list of approved qualifying \ncourses  (Section 3. 2.4).",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Human Language for Language Technologies\nLanguage Technology Application\nMachine Learning for Language Technologies\nPart-time education option is available in some cases. \n\nMIIS-16 students must take at least 84 units (typically 7 courses) of qualifying and elective courses that satisfy human language, machine learning, and language technology applications breadth requirements. MIIS-21 students have to take at least two more courses from the selected concentration area to satisfy their degree requirements, making it total of 108 units (typically 9 courses) of qualifying and elective courses, that also satisfy breadth requirements.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/LTI Concentration.txt"
        },
        "page_content":"Requirements: Students interested in the language technologies minor must complete our prerequisite courses with an average grade of B (3.0) or better before applying to the program. (Students who do not meet this average must submit a letter of explanation along with their application.) Prerequisites include:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 3.txt"
        },
        "page_content":"MLT Student Handbook 2023 - 2024\n4 MLT Degree Attainment  \n4.1 Course Requirements  \nIn order to  complete the Master of Language Technologies degree, the student must pass 120 \nor more course units of senior- to-graduate courses, and meet the following criteria:  \n\u2022 within those 120 units, at least 72 units of \u201cLTI\u201d courses and 24 units of \u201cSCS\u201d courses, \n\u2022 within those 72 units, 11 -711, 11- 791 (or an equivalent , see below ), and one ``Task \nOrientation Focus'' class, and  \n\u2022 within those 72 units, at least one of the following:  \no an LTI lab course,  \no 11-792, or  \no project -oriented Masters \u2019 thesis;",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"can also satisfy qualifying course requirements.  A student should get approval from the \ndirector for the breadth courses , if not listed below.  \n4.4 Approved Qualifying Courses  \nAny graduate course  (600 -level or higher) offered by the Language Technologies Institute is \na qualifying course.  \nAny two graduate courses (600 -level or higher) offered by departments within the SCS  \nrelevant to the MIIS degree other than LTI (Machine Learning or Computer Science departments, etc.) may be counted as approved qualifying courses .  \nMIIS Graduate Student Handbook  Page 15",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 3.txt"
        },
        "page_content":"readers, to be chosen by the student in consultation with the advisor, during the Fall \nMasters \u2019 Thesis I course. At least 2  of the 3 committee members must be SCS faculty \nworking in Language Technologies.  \n\u2022 To receive a final grade for the first semester's course, the student must have prepared a written proposal of at least five pages, describing the scientific thesis to be investigated, any relevant research already completed by the student, a comparison \nwith related work by others, and a detailed description of the work to be done in the \nnext semester. The proposal MUST be accepted by the committee by the end of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"a. Any graduate course (600 -level or higher) offered by the Language Technologies \nInstitute; and  \nb. Any graduate course (600 -level or higher) from the  list of approved qualifying \ncourses  (Section 3. 2.4). \n2. Free elective:  Students must pass 12 units (typically 1 course) in elective master\u2019s  \ncourse(s). A free elective is defined as:  \na. A graduate course (600 -level or higher)  with content relevant to the MIIS \nprogram objectives offered  by the School of Computer Science ; and  \nb. A course approved by the student's advisor and the degree Program Director.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 2.txt"
        },
        "page_content":"3.6 Completing a n M.S. Degree Enroute t o a Ph.D. \nCourses that satisfy LTI Ph.D. degree requirements may also be used to satisfy requirements for \none M.S. degree. The most common choice is the LTI\u2019s Master of Language Technologies (MLT) \ndegree because its requirements are similar (but not identical) to the Ph.D. requirements. Other M.S. degrees within the LTI and outside of the LTI are also possible.  \nLTI Ph.D.  Graduate Student Handbook  Page 20 \n Students interested in an M.S. degree other than the MLT degree should  discuss their plans with \ntheir Ph.D. advisor due to the additional courses and project work that may be involved.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"to apply and hone new skills while building state -of-the-art systems. Grade  requirements ensure \nthat students have demonstrated a certain level of skill while completing degree requirements. \nAll three types of requirements are described below.  \nMIIS -16 students must take at least 84 units (typically 7 12 -unit courses) of qualifying and \nelective courses that satisfy human language, machine learning, and language technology \napplications breadth requirements and 66 practice units for a total of 150 units to attain the \nStandard MIIS degree.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 2.txt"
        },
        "page_content":"PhD_Student_Handbook_2023-2024\n3 Standard Degree Requirements & Degree Certification                                        \n3.1 LTI Ph.D. Degree Requirements  \nTo complete the Ph.D.  in Language and Information Technologies degree, the student must satisfy \nthe following requirements:  \n\u2022 Pass at least 96  units of graduate level courses, with additional requirements detailed \nbelow ; \n\u2022 Satisfy proficiencies in Writing, Presentation, Programming, and Teaching ; \n\u2022 Propose , write, and defend a Ph.D.  dissertation (thesis) ; \n\u2022 Attend the LTI Colloquium (11 -700) each semester ; and \n\u2022 Satisfy the Research Speaking Requirement.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"4.3 Core Requirements  \nMIIS Graduate Student Handbook  Page 14  \n A MIIS  student must complete the following curricular requirements:  \n1. Qualifying courses:   \nMIIS -16 students must pass 72 units (typically 6 12 -unit courses) and MIIS -21 students \nmust complete 96 units (typically 8 12 -unit courses) in qualifying master\u2019s  courses.  \nA qualifying master\u2019s  course is defined as:  \na. Any graduate course (600 -level or higher) offered by the Language Technologies \nInstitute; and  \nb. Any graduate course (600 -level or higher) from the  list of approved qualifying \ncourses  (Section 3. 2.4).",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Human Language for Language Technologies\nLanguage Technology Application\nMachine Learning for Language Technologies\nPart-time education option is available in some cases. \n\nMIIS-16 students must take at least 84 units (typically 7 courses) of qualifying and elective courses that satisfy human language, machine learning, and language technology applications breadth requirements. MIIS-21 students have to take at least two more courses from the selected concentration area to satisfy their degree requirements, making it total of 108 units (typically 9 courses) of qualifying and elective courses, that also satisfy breadth requirements.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe minimum letter grade needed for a course to count towards a Master of Language Technologies degree is B (3.0). Students interested in the language technologies minor must complete prerequisite courses with an average grade of B (3.0) or better before applying to the program.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"What is the minimum letter grade needed for a course to count towards a Master of Language Technologies degree?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nRequirements: Students interested in the language technologies minor must complete our prerequisite courses with an average grade of B (3.0) or better before applying to the program. (Students who do not meet this average must submit a letter of explanation along with their application.) Prerequisites include:\n-----\nMLT Student Handbook 2023 - 2024\n4 MLT Degree Attainment  \n4.1 Course Requirements  \nIn order to  complete the Master of Language Technologies degree, the student must pass 120 \nor more course units of senior- to-graduate courses, and meet the following criteria:  \n\u2022 within those 120 units, at least 72 units of \u201cLTI\u201d courses and 24 units of \u201cSCS\u201d courses, \n\u2022 within those 72 units, 11 -711, 11- 791 (or an equivalent , see below ), and one ``Task \nOrientation Focus'' class, and  \n\u2022 within those 72 units, at least one of the following:  \no an LTI lab course,  \no 11-792, or  \no project -oriented Masters \u2019 thesis;\n-----\ncan also satisfy qualifying course requirements.  A student should get approval from the \ndirector for the breadth courses , if not listed below.  \n4.4 Approved Qualifying Courses  \nAny graduate course  (600 -level or higher) offered by the Language Technologies Institute is \na qualifying course.  \nAny two graduate courses (600 -level or higher) offered by departments within the SCS  \nrelevant to the MIIS degree other than LTI (Machine Learning or Computer Science departments, etc.) may be counted as approved qualifying courses .  \nMIIS Graduate Student Handbook  Page 15\n-----\nreaders, to be chosen by the student in consultation with the advisor, during the Fall \nMasters \u2019 Thesis I course. At least 2  of the 3 committee members must be SCS faculty \nworking in Language Technologies.  \n\u2022 To receive a final grade for the first semester's course, the student must have prepared a written proposal of at least five pages, describing the scientific thesis to be investigated, any relevant research already completed by the student, a comparison \nwith related work by others, and a detailed description of the work to be done in the \nnext semester. The proposal MUST be accepted by the committee by the end of\n-----\na. Any graduate course (600 -level or higher) offered by the Language Technologies \nInstitute; and  \nb. Any graduate course (600 -level or higher) from the  list of approved qualifying \ncourses  (Section 3. 2.4). \n2. Free elective:  Students must pass 12 units (typically 1 course) in elective master\u2019s  \ncourse(s). A free elective is defined as:  \na. A graduate course (600 -level or higher)  with content relevant to the MIIS \nprogram objectives offered  by the School of Computer Science ; and  \nb. A course approved by the student's advisor and the degree Program Director.\n-----\n3.6 Completing a n M.S. Degree Enroute t o a Ph.D. \nCourses that satisfy LTI Ph.D. degree requirements may also be used to satisfy requirements for \none M.S. degree. The most common choice is the LTI\u2019s Master of Language Technologies (MLT) \ndegree because its requirements are similar (but not identical) to the Ph.D. requirements. Other M.S. degrees within the LTI and outside of the LTI are also possible.  \nLTI Ph.D.  Graduate Student Handbook  Page 20 \n Students interested in an M.S. degree other than the MLT degree should  discuss their plans with \ntheir Ph.D. advisor due to the additional courses and project work that may be involved.\n-----\nto apply and hone new skills while building state -of-the-art systems. Grade  requirements ensure \nthat students have demonstrated a certain level of skill while completing degree requirements. \nAll three types of requirements are described below.  \nMIIS -16 students must take at least 84 units (typically 7 12 -unit courses) of qualifying and \nelective courses that satisfy human language, machine learning, and language technology \napplications breadth requirements and 66 practice units for a total of 150 units to attain the \nStandard MIIS degree.\n-----\nPhD_Student_Handbook_2023-2024\n3 Standard Degree Requirements & Degree Certification                                        \n3.1 LTI Ph.D. Degree Requirements  \nTo complete the Ph.D.  in Language and Information Technologies degree, the student must satisfy \nthe following requirements:  \n\u2022 Pass at least 96  units of graduate level courses, with additional requirements detailed \nbelow ; \n\u2022 Satisfy proficiencies in Writing, Presentation, Programming, and Teaching ; \n\u2022 Propose , write, and defend a Ph.D.  dissertation (thesis) ; \n\u2022 Attend the LTI Colloquium (11 -700) each semester ; and \n\u2022 Satisfy the Research Speaking Requirement.\n-----\n4.3 Core Requirements  \nMIIS Graduate Student Handbook  Page 14  \n A MIIS  student must complete the following curricular requirements:  \n1. Qualifying courses:   \nMIIS -16 students must pass 72 units (typically 6 12 -unit courses) and MIIS -21 students \nmust complete 96 units (typically 8 12 -unit courses) in qualifying master\u2019s  courses.  \nA qualifying master\u2019s  course is defined as:  \na. Any graduate course (600 -level or higher) offered by the Language Technologies \nInstitute; and  \nb. Any graduate course (600 -level or higher) from the  list of approved qualifying \ncourses  (Section 3. 2.4).\n-----\nHuman Language for Language Technologies\nLanguage Technology Application\nMachine Learning for Language Technologies\nPart-time education option is available in some cases. \n\nMIIS-16 students must take at least 84 units (typically 7 courses) of qualifying and elective courses that satisfy human language, machine learning, and language technology applications breadth requirements. MIIS-21 students have to take at least two more courses from the selected concentration area to satisfy their degree requirements, making it total of 108 units (typically 9 courses) of qualifying and elective courses, that also satisfy breadth requirements.\n-----\n\n### Response ###\n\nUser: What is the minimum letter grade needed for a course to count towards a Master of Language Technologies degree?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"GHC 5404.",
    "index":16,
    "Q":"Which room can Ph.D. students in Language and Information Technologies find mailboxes and office supplies",
    "A":"GHC 5404",
    "category":"programs",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 1.txt"
        },
        "page_content":"and do research. Typically, offices are shared with other Ph.D. students, but they may also be shared with staff, visitors, or other members of the LTI. \nOffices are assigned by the LTI\u2019s Office Manager (see Section 1.2 , Department Personnel, for \ncontact information).  \n2.3 Mailboxes and Office Supplies  \nMailboxes and office supplies are in GHC 5404.  \n2.4 Photocopies and Printers  \nPrinters and photocopies are available to LTI students. The use of a photocopier or printer \nrequires you to log in with your CMU ID card. LTI students may use printers\/photocopiers",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 1.txt"
        },
        "page_content":"MIIS Handbook_2023 - 2024\n2 The Language Technologies Institute \n2.1.1 Mailboxes & Office Supplies  \nThe LTI mailboxes, printers, copiers, and other departmental resources are in GHC 5404 . \n2.1.2 Photocopies and Printers  \nThe use of a photocopier or printer requires you to log in with your CMU ID card. LTI\u2019s printers \nare located in GHC 5404 and GHC 6604. The School of Computer Science provides a number of \nblack -and-white and color printers for use by students. The SCS Computer Facilities publishes a \nlist of printers online at http:\/\/www.cs.cmu.edu\/~help\/printing\/.  \n2.1.3 Office Space for MS Students",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 1.txt"
        },
        "page_content":"MLT Student Handbook 2023 - 2024\n2 The Language Technologies Institute  \n2.1 Mailboxes & Office Supplies  \nMailboxes, printers, copiers, and other departmental resources are  in GHC 5404.  \n2.2 Photocopies and Printers  \nThe use of a photocopier or printer requires you to log in with your CMU ID card. LTI\u2019s printers are located in GHC 5404 and GHC 66 04. The School of Computer Science provides a number of \nblack -and- white and color printers for use by students.  The  SCS Computer Facilities publishes a \nlist of printers online at http:\/\/www.cs.cmu.edu\/~help\/printing\/\n.  \n \nMLT Graduate Student Handbook  Page 11",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 1.txt"
        },
        "page_content":"Language Technologies Institute  \nCarnegie Mellon University  \n5000 Forbes Avenue  \nGates Hillman Complex  \nPittsburgh, PA 15241 -3891  \nLTI Ph.D.  Graduate Student Handbook  Page 13 \n 412-268-6298 (fax)  \nhttp:\/\/www.lti.cs.cmu.edu\/   \n \nOffice locations for faculty, staff, and Ph.D. students can be found on the LTI website.  \n2.2 Office Space \nMost Ph.D. students in residence on the Pittsburgh campus are given an office in which to study \nand do research. Typically, offices are shared with other Ph.D. students, but they may also be shared with staff, visitors, or other members of the LTI.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 1.txt"
        },
        "page_content":"MCDS Handbook 23-24 AY\n2 The Language Technologies Institute  \n2.1 Main Office \nThe Gates Hillman Complex: Mailboxes, printers, copiers, and other departmental \nresources are in GHC 5404. \n2.2 Photocopies and Printers \nThe use of a printer\/copier requires a CS user id (see the \u2018Computers\u2019 section). The School \nof Computer Science provides several black-and-white and color printers for use by \nstudents. SCS Computing Facilities maintains a list of printers:  \nhttp:\/\/www.cs.cmu.edu\/~help\/printing\/.  \n2.3 Office Space for MS Students \nFull-time students in the LTI\u2019s MS degree programs on the Pittsburgh campus have",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 8.txt"
        },
        "page_content":"Handbook-MSAII-2022-2023\n9 The Language Technologies Institute \n9.1 Working Space for MS Students \nExcept for restrictions due to COVID, full-time students in the LTI\u2019s MS degree programs on the \nPittsburgh campus have access to a shared working space to create a sense of community and \nprovide space for working when on campus. \n9.2 Photocopies and Printers \nMailboxes, printers, copiers, and other departmental resources are located in GHC 5404 \nThe use of a photocopier requires only a CMU ID card.  The School of Computer Science \nprovides a number of black-and-white and color printers for use by students.  The SCS",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":", the Office of Graduate and Postdoctoral \nAffairs web page , the Office of the Dean of Students web page , and other resources contained in \nAppendix A of this handbook.  \nWelcome! We hope that your time here is a life -changing experience.  \n1.1 Degrees Offered  \nThe Language Technologies Institute offers two Ph.D. programs and four Master degrees.  \n\u2022 Ph.D.  in Language and Information Technologies (LTI Ph.D. ) \n\u2022 Dual -Degree Ph.D. in Language and Information Technologies (CMU -PT Ph.D.)  \n\u2022 Masters in Language Technologies (MLT)  \n\u2022 Master of Science in Intelligent Information Systems (MIIS)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"ensures that students have written access to standard information. This handbook describes the \npolicies, procedures, and requirements for the Ph.D.  in Language and Information Technologies.  \nAll policies not explicitly described in this document conform to School of Computer Science (SCS) policies and university policies. For information about Carnegie Mellon requirements and policies, please see the university\u2019s handbook The Word\n, the Office of Graduate and Postdoctoral \nAffairs web page , the Office of the Dean of Students web page , and other resources contained in \nAppendix A of this handbook.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 1.txt"
        },
        "page_content":"PhD_Student_Handbook_2023-2024\n2 The Language Technologies Institute  \n2.1 Pittsburgh Campus Location  \nThe Language Technologies Institute is located primarily on the 5th and 6th floors of the  Gates \nHillman Complex (GHC) on Carnegie Mellon\u2019s Pittsburgh campus.  The address and contact \ninformation of the LTI are  shown below.  \nLanguage Technologies Institute  \nCarnegie Mellon University  \n5000 Forbes Avenue  \nGates Hillman Complex  \nPittsburgh, PA 15241 -3891  \nLTI Ph.D.  Graduate Student Handbook  Page 13 \n 412-268-6298 (fax)  \nhttp:\/\/www.lti.cs.cmu.edu\/",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"This handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing, \ndialogue systems, information retrieval, machine translation, speech processing,  video \nunderstanding, multimodal systems, automated reasoning, and other topics related to analysis \nand understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 1.txt"
        },
        "page_content":"and do research. Typically, offices are shared with other Ph.D. students, but they may also be shared with staff, visitors, or other members of the LTI. \nOffices are assigned by the LTI\u2019s Office Manager (see Section 1.2 , Department Personnel, for \ncontact information).  \n2.3 Mailboxes and Office Supplies  \nMailboxes and office supplies are in GHC 5404.  \n2.4 Photocopies and Printers  \nPrinters and photocopies are available to LTI students. The use of a photocopier or printer \nrequires you to log in with your CMU ID card. LTI students may use printers\/photocopiers",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 1.txt"
        },
        "page_content":"MIIS Handbook_2023 - 2024\n2 The Language Technologies Institute \n2.1.1 Mailboxes & Office Supplies  \nThe LTI mailboxes, printers, copiers, and other departmental resources are in GHC 5404 . \n2.1.2 Photocopies and Printers  \nThe use of a photocopier or printer requires you to log in with your CMU ID card. LTI\u2019s printers \nare located in GHC 5404 and GHC 6604. The School of Computer Science provides a number of \nblack -and-white and color printers for use by students. The SCS Computer Facilities publishes a \nlist of printers online at http:\/\/www.cs.cmu.edu\/~help\/printing\/.  \n2.1.3 Office Space for MS Students",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 1.txt"
        },
        "page_content":"MLT Student Handbook 2023 - 2024\n2 The Language Technologies Institute  \n2.1 Mailboxes & Office Supplies  \nMailboxes, printers, copiers, and other departmental resources are  in GHC 5404.  \n2.2 Photocopies and Printers  \nThe use of a photocopier or printer requires you to log in with your CMU ID card. LTI\u2019s printers are located in GHC 5404 and GHC 66 04. The School of Computer Science provides a number of \nblack -and- white and color printers for use by students.  The  SCS Computer Facilities publishes a \nlist of printers online at http:\/\/www.cs.cmu.edu\/~help\/printing\/\n.  \n \nMLT Graduate Student Handbook  Page 11",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 1.txt"
        },
        "page_content":"Language Technologies Institute  \nCarnegie Mellon University  \n5000 Forbes Avenue  \nGates Hillman Complex  \nPittsburgh, PA 15241 -3891  \nLTI Ph.D.  Graduate Student Handbook  Page 13 \n 412-268-6298 (fax)  \nhttp:\/\/www.lti.cs.cmu.edu\/   \n \nOffice locations for faculty, staff, and Ph.D. students can be found on the LTI website.  \n2.2 Office Space \nMost Ph.D. students in residence on the Pittsburgh campus are given an office in which to study \nand do research. Typically, offices are shared with other Ph.D. students, but they may also be shared with staff, visitors, or other members of the LTI.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 1.txt"
        },
        "page_content":"MCDS Handbook 23-24 AY\n2 The Language Technologies Institute  \n2.1 Main Office \nThe Gates Hillman Complex: Mailboxes, printers, copiers, and other departmental \nresources are in GHC 5404. \n2.2 Photocopies and Printers \nThe use of a printer\/copier requires a CS user id (see the \u2018Computers\u2019 section). The School \nof Computer Science provides several black-and-white and color printers for use by \nstudents. SCS Computing Facilities maintains a list of printers:  \nhttp:\/\/www.cs.cmu.edu\/~help\/printing\/.  \n2.3 Office Space for MS Students \nFull-time students in the LTI\u2019s MS degree programs on the Pittsburgh campus have",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 8.txt"
        },
        "page_content":"Handbook-MSAII-2022-2023\n9 The Language Technologies Institute \n9.1 Working Space for MS Students \nExcept for restrictions due to COVID, full-time students in the LTI\u2019s MS degree programs on the \nPittsburgh campus have access to a shared working space to create a sense of community and \nprovide space for working when on campus. \n9.2 Photocopies and Printers \nMailboxes, printers, copiers, and other departmental resources are located in GHC 5404 \nThe use of a photocopier requires only a CMU ID card.  The School of Computer Science \nprovides a number of black-and-white and color printers for use by students.  The SCS",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":", the Office of Graduate and Postdoctoral \nAffairs web page , the Office of the Dean of Students web page , and other resources contained in \nAppendix A of this handbook.  \nWelcome! We hope that your time here is a life -changing experience.  \n1.1 Degrees Offered  \nThe Language Technologies Institute offers two Ph.D. programs and four Master degrees.  \n\u2022 Ph.D.  in Language and Information Technologies (LTI Ph.D. ) \n\u2022 Dual -Degree Ph.D. in Language and Information Technologies (CMU -PT Ph.D.)  \n\u2022 Masters in Language Technologies (MLT)  \n\u2022 Master of Science in Intelligent Information Systems (MIIS)",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"ensures that students have written access to standard information. This handbook describes the \npolicies, procedures, and requirements for the Ph.D.  in Language and Information Technologies.  \nAll policies not explicitly described in this document conform to School of Computer Science (SCS) policies and university policies. For information about Carnegie Mellon requirements and policies, please see the university\u2019s handbook The Word\n, the Office of Graduate and Postdoctoral \nAffairs web page , the Office of the Dean of Students web page , and other resources contained in \nAppendix A of this handbook.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 1.txt"
        },
        "page_content":"PhD_Student_Handbook_2023-2024\n2 The Language Technologies Institute  \n2.1 Pittsburgh Campus Location  \nThe Language Technologies Institute is located primarily on the 5th and 6th floors of the  Gates \nHillman Complex (GHC) on Carnegie Mellon\u2019s Pittsburgh campus.  The address and contact \ninformation of the LTI are  shown below.  \nLanguage Technologies Institute  \nCarnegie Mellon University  \n5000 Forbes Avenue  \nGates Hillman Complex  \nPittsburgh, PA 15241 -3891  \nLTI Ph.D.  Graduate Student Handbook  Page 13 \n 412-268-6298 (fax)  \nhttp:\/\/www.lti.cs.cmu.edu\/",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 0.txt"
        },
        "page_content":"This handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing, \ndialogue systems, information retrieval, machine translation, speech processing,  video \nunderstanding, multimodal systems, automated reasoning, and other topics related to analysis \nand understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan",
        "type":"Document"
      }
    ],
    "model_output":"\nGHC 5404.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Which room can Ph.D. students in Language and Information Technologies find mailboxes and office supplies\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nand do research. Typically, offices are shared with other Ph.D. students, but they may also be shared with staff, visitors, or other members of the LTI. \nOffices are assigned by the LTI\u2019s Office Manager (see Section 1.2 , Department Personnel, for \ncontact information).  \n2.3 Mailboxes and Office Supplies  \nMailboxes and office supplies are in GHC 5404.  \n2.4 Photocopies and Printers  \nPrinters and photocopies are available to LTI students. The use of a photocopier or printer \nrequires you to log in with your CMU ID card. LTI students may use printers\/photocopiers\n-----\nMIIS Handbook_2023 - 2024\n2 The Language Technologies Institute \n2.1.1 Mailboxes & Office Supplies  \nThe LTI mailboxes, printers, copiers, and other departmental resources are in GHC 5404 . \n2.1.2 Photocopies and Printers  \nThe use of a photocopier or printer requires you to log in with your CMU ID card. LTI\u2019s printers \nare located in GHC 5404 and GHC 6604. The School of Computer Science provides a number of \nblack -and-white and color printers for use by students. The SCS Computer Facilities publishes a \nlist of printers online at http:\/\/www.cs.cmu.edu\/~help\/printing\/.  \n2.1.3 Office Space for MS Students\n-----\nMLT Student Handbook 2023 - 2024\n2 The Language Technologies Institute  \n2.1 Mailboxes & Office Supplies  \nMailboxes, printers, copiers, and other departmental resources are  in GHC 5404.  \n2.2 Photocopies and Printers  \nThe use of a photocopier or printer requires you to log in with your CMU ID card. LTI\u2019s printers are located in GHC 5404 and GHC 66 04. The School of Computer Science provides a number of \nblack -and- white and color printers for use by students.  The  SCS Computer Facilities publishes a \nlist of printers online at http:\/\/www.cs.cmu.edu\/~help\/printing\/\n.  \n \nMLT Graduate Student Handbook  Page 11\n-----\nLanguage Technologies Institute  \nCarnegie Mellon University  \n5000 Forbes Avenue  \nGates Hillman Complex  \nPittsburgh, PA 15241 -3891  \nLTI Ph.D.  Graduate Student Handbook  Page 13 \n 412-268-6298 (fax)  \nhttp:\/\/www.lti.cs.cmu.edu\/   \n \nOffice locations for faculty, staff, and Ph.D. students can be found on the LTI website.  \n2.2 Office Space \nMost Ph.D. students in residence on the Pittsburgh campus are given an office in which to study \nand do research. Typically, offices are shared with other Ph.D. students, but they may also be shared with staff, visitors, or other members of the LTI.\n-----\nMCDS Handbook 23-24 AY\n2 The Language Technologies Institute  \n2.1 Main Office \nThe Gates Hillman Complex: Mailboxes, printers, copiers, and other departmental \nresources are in GHC 5404. \n2.2 Photocopies and Printers \nThe use of a printer\/copier requires a CS user id (see the \u2018Computers\u2019 section). The School \nof Computer Science provides several black-and-white and color printers for use by \nstudents. SCS Computing Facilities maintains a list of printers:  \nhttp:\/\/www.cs.cmu.edu\/~help\/printing\/.  \n2.3 Office Space for MS Students \nFull-time students in the LTI\u2019s MS degree programs on the Pittsburgh campus have\n-----\nHandbook-MSAII-2022-2023\n9 The Language Technologies Institute \n9.1 Working Space for MS Students \nExcept for restrictions due to COVID, full-time students in the LTI\u2019s MS degree programs on the \nPittsburgh campus have access to a shared working space to create a sense of community and \nprovide space for working when on campus. \n9.2 Photocopies and Printers \nMailboxes, printers, copiers, and other departmental resources are located in GHC 5404 \nThe use of a photocopier requires only a CMU ID card.  The School of Computer Science \nprovides a number of black-and-white and color printers for use by students.  The SCS\n-----\n, the Office of Graduate and Postdoctoral \nAffairs web page , the Office of the Dean of Students web page , and other resources contained in \nAppendix A of this handbook.  \nWelcome! We hope that your time here is a life -changing experience.  \n1.1 Degrees Offered  \nThe Language Technologies Institute offers two Ph.D. programs and four Master degrees.  \n\u2022 Ph.D.  in Language and Information Technologies (LTI Ph.D. ) \n\u2022 Dual -Degree Ph.D. in Language and Information Technologies (CMU -PT Ph.D.)  \n\u2022 Masters in Language Technologies (MLT)  \n\u2022 Master of Science in Intelligent Information Systems (MIIS)\n-----\nensures that students have written access to standard information. This handbook describes the \npolicies, procedures, and requirements for the Ph.D.  in Language and Information Technologies.  \nAll policies not explicitly described in this document conform to School of Computer Science (SCS) policies and university policies. For information about Carnegie Mellon requirements and policies, please see the university\u2019s handbook The Word\n, the Office of Graduate and Postdoctoral \nAffairs web page , the Office of the Dean of Students web page , and other resources contained in \nAppendix A of this handbook.\n-----\nPhD_Student_Handbook_2023-2024\n2 The Language Technologies Institute  \n2.1 Pittsburgh Campus Location  \nThe Language Technologies Institute is located primarily on the 5th and 6th floors of the  Gates \nHillman Complex (GHC) on Carnegie Mellon\u2019s Pittsburgh campus.  The address and contact \ninformation of the LTI are  shown below.  \nLanguage Technologies Institute  \nCarnegie Mellon University  \n5000 Forbes Avenue  \nGates Hillman Complex  \nPittsburgh, PA 15241 -3891  \nLTI Ph.D.  Graduate Student Handbook  Page 13 \n 412-268-6298 (fax)  \nhttp:\/\/www.lti.cs.cmu.edu\/\n-----\nThis handbook applies to the LTI Ph.D.  \nThe Ph.D.  in Language and Information Technologies (LTI Ph.D. ) is focused on understanding \nand extending the state of the art in computational linguistics, natural language processing, \ndialogue systems, information retrieval, machine translation, speech processing,  video \nunderstanding, multimodal systems, automated reasoning, and other topics related to analysis \nand understanding of unstructured information  (e.g., machine learning, and software engineering \nof intelligent systems).  \n1.2 Department Personnel \nThe people responsible for administering the LTI Ph.D.  degree are:  \nJamie Callan\n-----\n\n### Response ###\n\nUser: Which room can Ph.D. students in Language and Information Technologies find mailboxes and office supplies\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.0,
    "recall":0.0,
    "precision":0.0,
    "A_hat":"5 years",
    "index":17,
    "Q":"For which year or years is full funding (i.e. tuition and stipend) guaranteed for a Ph.D. student at LTI?",
    "A":"The first year",
    "category":"programs",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 4.txt"
        },
        "page_content":"PhD_Student_Handbook_2023-2024 \n5 Financial Support  \n5.1 Graduate Student Funding  \nFor all LTI Ph.D.  students, full funding (tuition plus stipend) is guaranteed for the first year . This \nsupport is normally continued for at least 5 years, with possibility of further continuance, subject to continuing satisfactory progress and availability of funding. The fellowship includes full tuition \nand fees, and a monthly Ph.D.  stipend that is fixed across SCS. In addition, the LTI pays a \ndependency allowance of 10% of the student's monthly stipend to any student with a child, unless they have a spouse who earns more than $200 per month.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 5.txt"
        },
        "page_content":"MLT Student Handbook 2023 - 2024\n6 Financial Issues  \n6.1 Graduate Student Funding  \nFor all LTI MLT students, full funding (tuition plus stipend) is guaranteed for the first year. This support is normally continued for the duration of the program, subject to continuing satisfactory progress and availability of funding. The fellowship includes full tuition and fees, \nand a monthly MLT stipend. In addition, the LTI pays a dependency allowance of 10% of the \nstudent's monthly stipend to any student with a child, unless they have a spouse who earns \nmore than $200 per month.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 3.txt"
        },
        "page_content":"Accommodation for Gestational Parents or during a Formal Leave of Absence. Continued \nLTI Ph.D.  Graduate Student Handbook  Page 32 \n academic stipend funding may be extended by two (2) weeks, for a total of eight (8) weeks, if an \nabsence longer than six weeks is medically necessary.   \nDoctoral Stipend Continuation (Non- gestational Parents) \u2013 Doctoral students who receive an \nacademic stipend funded by Carnegie Mellon and are becoming a parent by adoption, birth, or through guardianship are eligible to continue to receive stipend funding for up to fo ur (4) weeks \nduring a Short- Term Parental Accommodation.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 3.txt"
        },
        "page_content":"free parental loan  (https:\/\/www.cmu.edu\/student -affairs\/dean\/loans\/ ) from the Office of the Dean \nof Students.   \nDoctoral Stipend Continuation (Gestational Parents) \u2013 Doctoral students who are the \ngestational parent and who receive an academic stipend funded by Carnegie Mellon are eligible to continue to receive stipend funding for up to six (6) weeks during a Short -Term \nAccommodation for Gestational Parents or during a Formal Leave of Absence. Continued \nLTI Ph.D.  Graduate Student Handbook  Page 32 \n academic stipend funding may be extended by two (2) weeks, for a total of eight (8) weeks, if an",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 3.txt"
        },
        "page_content":"to visa restrictions.  \nLTI Ph.D.  Graduate Student Handbook  Page 25 \n Note that self- funded Ph.D.  students (e.g., those registered for five units while on semester \ninterns hip) are not permitted to receive a partial stipend for the semester of their internship, while \nfull- time LTI -sponsored students are eligible for a partial stipend.  \nAll students are caution ed to be aware of potential intellectual property (IP) problems with \ninternships, and to review any IP agreements with their advisors before signing them. It is possible \nto lose ownership of your ideas.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 4.txt"
        },
        "page_content":"The impact of outside fellowships and scholarships on departmental support -decrease by the \namount, added bonus, etc.  \nIf a Ph.D.  student receives an outside graduate fellowship (e.g., NSF, Fulbright), the student is \nexpected to accept it in place of the LTI\u2019s graduate fellowship. As an extra incentive to do so, the LTI will supplement the award so that the student will receive full tuition and a combined stipend 10 percent higher than that of the standard LTI graduate fellowship.  \nStudents are required to inform the LTI about any external funding that they receive.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 4.txt"
        },
        "page_content":"and fees, and a monthly Ph.D.  stipend that is fixed across SCS. In addition, the LTI pays a \ndependency allowance of 10% of the student's monthly stipend to any student with a child, unless they have a spouse who earns more than $200 per month.  \nThe impact of outside fellowships and scholarships on departmental support -decrease by the \namount, added bonus, etc.  \nIf a Ph.D.  student receives an outside graduate fellowship (e.g., NSF, Fulbright), the student is",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 5.txt"
        },
        "page_content":".  \n \n \nLTI Ph.D.  Graduate Student Handbook  Page 35 \n 6.4 Transcripts  \nAll units required for the Ph.D.  degree, whether earned in residence or tr ansferred from another \ninstitution, must be recorded on the transcript within ten years of the date on which the student \nenrolled in the program (CMU policy), or less if required by a more restrictive department, school, or college policy. This statutory p eriod can be extended by the SCS Associate Dean for Graduate",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 3.txt"
        },
        "page_content":"requirements.  \nEarly Completion  \nThe Ph.D. is granted when  all degree requirements are satisfied. Some students complete the \nprogram in fewer than five years.  \nLTI Ph.D.  Graduate Student Handbook  Page 24 \n Extended or Longer- than -Standard Competition  \nLonger- than -standard degree completion may occur due to academic interruptions in making \nprogress toward the d egree as defined by the academic program, interruptions of full -time study \nor progress towards the degree due to serious, documented medical issues, or other unusual or \nunforeseen circumstances.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 2.txt"
        },
        "page_content":"guaranteeing that the proposed research is interesting to the larger scientific community and demonstrating that the student will finish the program if the work is completed as outlined.  \n \n\u2022 Thesis Defense:  The dissertation document itself, normally expected at the end of the fifth \nyear, will include a detailed description of all the work done, including a clear evaluation",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 4.txt"
        },
        "page_content":"PhD_Student_Handbook_2023-2024 \n5 Financial Support  \n5.1 Graduate Student Funding  \nFor all LTI Ph.D.  students, full funding (tuition plus stipend) is guaranteed for the first year . This \nsupport is normally continued for at least 5 years, with possibility of further continuance, subject to continuing satisfactory progress and availability of funding. The fellowship includes full tuition \nand fees, and a monthly Ph.D.  stipend that is fixed across SCS. In addition, the LTI pays a \ndependency allowance of 10% of the student's monthly stipend to any student with a child, unless they have a spouse who earns more than $200 per month.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 5.txt"
        },
        "page_content":"MLT Student Handbook 2023 - 2024\n6 Financial Issues  \n6.1 Graduate Student Funding  \nFor all LTI MLT students, full funding (tuition plus stipend) is guaranteed for the first year. This support is normally continued for the duration of the program, subject to continuing satisfactory progress and availability of funding. The fellowship includes full tuition and fees, \nand a monthly MLT stipend. In addition, the LTI pays a dependency allowance of 10% of the \nstudent's monthly stipend to any student with a child, unless they have a spouse who earns \nmore than $200 per month.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 3.txt"
        },
        "page_content":"Accommodation for Gestational Parents or during a Formal Leave of Absence. Continued \nLTI Ph.D.  Graduate Student Handbook  Page 32 \n academic stipend funding may be extended by two (2) weeks, for a total of eight (8) weeks, if an \nabsence longer than six weeks is medically necessary.   \nDoctoral Stipend Continuation (Non- gestational Parents) \u2013 Doctoral students who receive an \nacademic stipend funded by Carnegie Mellon and are becoming a parent by adoption, birth, or through guardianship are eligible to continue to receive stipend funding for up to fo ur (4) weeks \nduring a Short- Term Parental Accommodation.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 3.txt"
        },
        "page_content":"free parental loan  (https:\/\/www.cmu.edu\/student -affairs\/dean\/loans\/ ) from the Office of the Dean \nof Students.   \nDoctoral Stipend Continuation (Gestational Parents) \u2013 Doctoral students who are the \ngestational parent and who receive an academic stipend funded by Carnegie Mellon are eligible to continue to receive stipend funding for up to six (6) weeks during a Short -Term \nAccommodation for Gestational Parents or during a Formal Leave of Absence. Continued \nLTI Ph.D.  Graduate Student Handbook  Page 32 \n academic stipend funding may be extended by two (2) weeks, for a total of eight (8) weeks, if an",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 3.txt"
        },
        "page_content":"to visa restrictions.  \nLTI Ph.D.  Graduate Student Handbook  Page 25 \n Note that self- funded Ph.D.  students (e.g., those registered for five units while on semester \ninterns hip) are not permitted to receive a partial stipend for the semester of their internship, while \nfull- time LTI -sponsored students are eligible for a partial stipend.  \nAll students are caution ed to be aware of potential intellectual property (IP) problems with \ninternships, and to review any IP agreements with their advisors before signing them. It is possible \nto lose ownership of your ideas.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 4.txt"
        },
        "page_content":"The impact of outside fellowships and scholarships on departmental support -decrease by the \namount, added bonus, etc.  \nIf a Ph.D.  student receives an outside graduate fellowship (e.g., NSF, Fulbright), the student is \nexpected to accept it in place of the LTI\u2019s graduate fellowship. As an extra incentive to do so, the LTI will supplement the award so that the student will receive full tuition and a combined stipend 10 percent higher than that of the standard LTI graduate fellowship.  \nStudents are required to inform the LTI about any external funding that they receive.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 4.txt"
        },
        "page_content":"and fees, and a monthly Ph.D.  stipend that is fixed across SCS. In addition, the LTI pays a \ndependency allowance of 10% of the student's monthly stipend to any student with a child, unless they have a spouse who earns more than $200 per month.  \nThe impact of outside fellowships and scholarships on departmental support -decrease by the \namount, added bonus, etc.  \nIf a Ph.D.  student receives an outside graduate fellowship (e.g., NSF, Fulbright), the student is",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 5.txt"
        },
        "page_content":".  \n \n \nLTI Ph.D.  Graduate Student Handbook  Page 35 \n 6.4 Transcripts  \nAll units required for the Ph.D.  degree, whether earned in residence or tr ansferred from another \ninstitution, must be recorded on the transcript within ten years of the date on which the student \nenrolled in the program (CMU policy), or less if required by a more restrictive department, school, or college policy. This statutory p eriod can be extended by the SCS Associate Dean for Graduate",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 3.txt"
        },
        "page_content":"requirements.  \nEarly Completion  \nThe Ph.D. is granted when  all degree requirements are satisfied. Some students complete the \nprogram in fewer than five years.  \nLTI Ph.D.  Graduate Student Handbook  Page 24 \n Extended or Longer- than -Standard Competition  \nLonger- than -standard degree completion may occur due to academic interruptions in making \nprogress toward the d egree as defined by the academic program, interruptions of full -time study \nor progress towards the degree due to serious, documented medical issues, or other unusual or \nunforeseen circumstances.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/PhD Student Handbook 2023-2024 2.txt"
        },
        "page_content":"guaranteeing that the proposed research is interesting to the larger scientific community and demonstrating that the student will finish the program if the work is completed as outlined.  \n \n\u2022 Thesis Defense:  The dissertation document itself, normally expected at the end of the fifth \nyear, will include a detailed description of all the work done, including a clear evaluation",
        "type":"Document"
      }
    ],
    "model_output":"\nFull funding (tuition and stipend) is guaranteed for the first year for all LTI Ph.D. students. Additionally, support is normally continued for at least 5 years, with the possibility of further continuance, subject to continuing satisfactory progress and availability of funding.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"For which year or years is full funding (i.e. tuition and stipend) guaranteed for a Ph.D. student at LTI?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nPhD_Student_Handbook_2023-2024 \n5 Financial Support  \n5.1 Graduate Student Funding  \nFor all LTI Ph.D.  students, full funding (tuition plus stipend) is guaranteed for the first year . This \nsupport is normally continued for at least 5 years, with possibility of further continuance, subject to continuing satisfactory progress and availability of funding. The fellowship includes full tuition \nand fees, and a monthly Ph.D.  stipend that is fixed across SCS. In addition, the LTI pays a \ndependency allowance of 10% of the student's monthly stipend to any student with a child, unless they have a spouse who earns more than $200 per month.\n-----\nMLT Student Handbook 2023 - 2024\n6 Financial Issues  \n6.1 Graduate Student Funding  \nFor all LTI MLT students, full funding (tuition plus stipend) is guaranteed for the first year. This support is normally continued for the duration of the program, subject to continuing satisfactory progress and availability of funding. The fellowship includes full tuition and fees, \nand a monthly MLT stipend. In addition, the LTI pays a dependency allowance of 10% of the \nstudent's monthly stipend to any student with a child, unless they have a spouse who earns \nmore than $200 per month.\n-----\nAccommodation for Gestational Parents or during a Formal Leave of Absence. Continued \nLTI Ph.D.  Graduate Student Handbook  Page 32 \n academic stipend funding may be extended by two (2) weeks, for a total of eight (8) weeks, if an \nabsence longer than six weeks is medically necessary.   \nDoctoral Stipend Continuation (Non- gestational Parents) \u2013 Doctoral students who receive an \nacademic stipend funded by Carnegie Mellon and are becoming a parent by adoption, birth, or through guardianship are eligible to continue to receive stipend funding for up to fo ur (4) weeks \nduring a Short- Term Parental Accommodation.\n-----\nfree parental loan  (https:\/\/www.cmu.edu\/student -affairs\/dean\/loans\/ ) from the Office of the Dean \nof Students.   \nDoctoral Stipend Continuation (Gestational Parents) \u2013 Doctoral students who are the \ngestational parent and who receive an academic stipend funded by Carnegie Mellon are eligible to continue to receive stipend funding for up to six (6) weeks during a Short -Term \nAccommodation for Gestational Parents or during a Formal Leave of Absence. Continued \nLTI Ph.D.  Graduate Student Handbook  Page 32 \n academic stipend funding may be extended by two (2) weeks, for a total of eight (8) weeks, if an\n-----\nto visa restrictions.  \nLTI Ph.D.  Graduate Student Handbook  Page 25 \n Note that self- funded Ph.D.  students (e.g., those registered for five units while on semester \ninterns hip) are not permitted to receive a partial stipend for the semester of their internship, while \nfull- time LTI -sponsored students are eligible for a partial stipend.  \nAll students are caution ed to be aware of potential intellectual property (IP) problems with \ninternships, and to review any IP agreements with their advisors before signing them. It is possible \nto lose ownership of your ideas.\n-----\nThe impact of outside fellowships and scholarships on departmental support -decrease by the \namount, added bonus, etc.  \nIf a Ph.D.  student receives an outside graduate fellowship (e.g., NSF, Fulbright), the student is \nexpected to accept it in place of the LTI\u2019s graduate fellowship. As an extra incentive to do so, the LTI will supplement the award so that the student will receive full tuition and a combined stipend 10 percent higher than that of the standard LTI graduate fellowship.  \nStudents are required to inform the LTI about any external funding that they receive.\n-----\nand fees, and a monthly Ph.D.  stipend that is fixed across SCS. In addition, the LTI pays a \ndependency allowance of 10% of the student's monthly stipend to any student with a child, unless they have a spouse who earns more than $200 per month.  \nThe impact of outside fellowships and scholarships on departmental support -decrease by the \namount, added bonus, etc.  \nIf a Ph.D.  student receives an outside graduate fellowship (e.g., NSF, Fulbright), the student is\n-----\n.  \n \n \nLTI Ph.D.  Graduate Student Handbook  Page 35 \n 6.4 Transcripts  \nAll units required for the Ph.D.  degree, whether earned in residence or tr ansferred from another \ninstitution, must be recorded on the transcript within ten years of the date on which the student \nenrolled in the program (CMU policy), or less if required by a more restrictive department, school, or college policy. This statutory p eriod can be extended by the SCS Associate Dean for Graduate\n-----\nrequirements.  \nEarly Completion  \nThe Ph.D. is granted when  all degree requirements are satisfied. Some students complete the \nprogram in fewer than five years.  \nLTI Ph.D.  Graduate Student Handbook  Page 24 \n Extended or Longer- than -Standard Competition  \nLonger- than -standard degree completion may occur due to academic interruptions in making \nprogress toward the d egree as defined by the academic program, interruptions of full -time study \nor progress towards the degree due to serious, documented medical issues, or other unusual or \nunforeseen circumstances.\n-----\nguaranteeing that the proposed research is interesting to the larger scientific community and demonstrating that the student will finish the program if the work is completed as outlined.  \n \n\u2022 Thesis Defense:  The dissertation document itself, normally expected at the end of the fifth \nyear, will include a detailed description of all the work done, including a clear evaluation\n-----\n\n### Response ###\n\nUser: For which year or years is full funding (i.e. tuition and stipend) guaranteed for a Ph.D. student at LTI?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.1428571429,
    "recall":0.5,
    "precision":0.0833333333,
    "A_hat":"11-910 Directed Research, 11-920 Independent Study: Breadth, or 11-925 Independent Study: Area",
    "index":18,
    "Q":"What's the Summer requirement for Year 1 in the Master of Language Technologies program?",
    "A":"Required Research",
    "category":"programs",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"four academic semesters (fall, spring, fall, spring) and a summer internship.  \nMIIS: Advanced Study track offers in depth  degree in one of the following areas of \nconcentration:  \n\u2022 Human Language for Language Technologies  \n\u2022 Language Technology Application  \n\u2022 Machine Learning for Language Technologies  \nPart- time options are available in some cases.  \n4.2 Required Units for Degree Attainment  \nTo complete the Master of Science in Intelligent Information Systems, a student must satisfy \nthree types of requirements. Curricular requirements ensure that MIIS students receive",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/LTI Concentration.txt"
        },
        "page_content":"Requirements: Students interested in the language technologies minor must complete our prerequisite courses with an average grade of B (3.0) or better before applying to the program. (Students who do not meet this average must submit a letter of explanation along with their application.) Prerequisites include:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/LTI Concentration.txt"
        },
        "page_content":"Students must complete a semester-long directed research project in the context of being registered for an independent study or thesis.  This should provide hands-on experience and an in-depth study of a topic in same area as a chosen elective.\nAdmission: Students interested in earning a minor in language technologies must apply for admission no later than September 30 of their senior year. An admission decision will usually be made within one month. Students may petition the LTI undergraduate program director to be admitted to the minor earlier or later in their undergraduate careers. To apply, contact the program's director, Carolyn Ros\u00e9.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 3.txt"
        },
        "page_content":"MLT Student Handbook 2023 - 2024\n4 MLT Degree Attainment  \n4.1 Course Requirements  \nIn order to  complete the Master of Language Technologies degree, the student must pass 120 \nor more course units of senior- to-graduate courses, and meet the following criteria:  \n\u2022 within those 120 units, at least 72 units of \u201cLTI\u201d courses and 24 units of \u201cSCS\u201d courses, \n\u2022 within those 72 units, 11 -711, 11- 791 (or an equivalent , see below ), and one ``Task \nOrientation Focus'' class, and  \n\u2022 within those 72 units, at least one of the following:  \no an LTI lab course,  \no 11-792, or  \no project -oriented Masters \u2019 thesis;",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Option 1. Standard MIIS degree (MIIS-16) - A 16-month track that is completed in three academic semesters (fall, spring, fall) and a summer internship.  \n\nOption 2. MIIS: Advanced Study degree (MIIS-21) - A 21-month track that is completed in four academic semesters (fall, spring, fall, spring) and a summer internship.\n\nMIIS: Advanced Study track offers indepth degree in one of the following areas of concentration:\n\nHuman Language for Language Technologies\nLanguage Technology Application\nMachine Learning for Language Technologies\nPart-time education option is available in some cases.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 0.txt"
        },
        "page_content":"Office of Graduate and Postdoc Affairs, the Office of the Dean of Student Affairs, and others, \nare included in Appendix A of this handbook.  \n1.2 The MLT Degree  \nThe Master of Language Technologies (MLT) is a research- oriented Master of Science degree \noffered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MLT program is a 24 -month program \nconsisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-920 Independent Study_ Breadth.txt"
        },
        "page_content":"<start course metadata for 11-920 Independent Study: Breadth>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Independent Study: Breadth\nCourse Number: 11-920\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan, Robert Frederking\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-920 Independent Study: Breadth>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-930 Dissertation Research.txt"
        },
        "page_content":"<start course metadata for 11-930 Dissertation Research>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Dissertation Research\nCourse Number: 11-930\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: \nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-930 Dissertation Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-925 Independent Study_ Area.txt"
        },
        "page_content":"<start course metadata for 11-925 Independent Study: Area>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Independent Study: Area\nCourse Number: 11-925\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-925 Independent Study: Area>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-910 Directed Research.txt"
        },
        "page_content":"<start course metadata for 11-910 Directed Research>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Directed Research\nCourse Number: 11-910\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan, Robert Frederking\nRooms: \nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-910 Directed Research>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 3.txt"
        },
        "page_content":"four academic semesters (fall, spring, fall, spring) and a summer internship.  \nMIIS: Advanced Study track offers in depth  degree in one of the following areas of \nconcentration:  \n\u2022 Human Language for Language Technologies  \n\u2022 Language Technology Application  \n\u2022 Machine Learning for Language Technologies  \nPart- time options are available in some cases.  \n4.2 Required Units for Degree Attainment  \nTo complete the Master of Science in Intelligent Information Systems, a student must satisfy \nthree types of requirements. Curricular requirements ensure that MIIS students receive",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/LTI Concentration.txt"
        },
        "page_content":"Requirements: Students interested in the language technologies minor must complete our prerequisite courses with an average grade of B (3.0) or better before applying to the program. (Students who do not meet this average must submit a letter of explanation along with their application.) Prerequisites include:",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/LTI Concentration.txt"
        },
        "page_content":"Students must complete a semester-long directed research project in the context of being registered for an independent study or thesis.  This should provide hands-on experience and an in-depth study of a topic in same area as a chosen elective.\nAdmission: Students interested in earning a minor in language technologies must apply for admission no later than September 30 of their senior year. An admission decision will usually be made within one month. Students may petition the LTI undergraduate program director to be admitted to the minor earlier or later in their undergraduate careers. To apply, contact the program's director, Carolyn Ros\u00e9.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 3.txt"
        },
        "page_content":"MLT Student Handbook 2023 - 2024\n4 MLT Degree Attainment  \n4.1 Course Requirements  \nIn order to  complete the Master of Language Technologies degree, the student must pass 120 \nor more course units of senior- to-graduate courses, and meet the following criteria:  \n\u2022 within those 120 units, at least 72 units of \u201cLTI\u201d courses and 24 units of \u201cSCS\u201d courses, \n\u2022 within those 72 units, 11 -711, 11- 791 (or an equivalent , see below ), and one ``Task \nOrientation Focus'' class, and  \n\u2022 within those 72 units, at least one of the following:  \no an LTI lab course,  \no 11-792, or  \no project -oriented Masters \u2019 thesis;",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Option 1. Standard MIIS degree (MIIS-16) - A 16-month track that is completed in three academic semesters (fall, spring, fall) and a summer internship.  \n\nOption 2. MIIS: Advanced Study degree (MIIS-21) - A 21-month track that is completed in four academic semesters (fall, spring, fall, spring) and a summer internship.\n\nMIIS: Advanced Study track offers indepth degree in one of the following areas of concentration:\n\nHuman Language for Language Technologies\nLanguage Technology Application\nMachine Learning for Language Technologies\nPart-time education option is available in some cases.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 0.txt"
        },
        "page_content":"Office of Graduate and Postdoc Affairs, the Office of the Dean of Student Affairs, and others, \nare included in Appendix A of this handbook.  \n1.2 The MLT Degree  \nThe Master of Language Technologies (MLT) is a research- oriented Master of Science degree \noffered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MLT program is a 24 -month program \nconsisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-920 Independent Study_ Breadth.txt"
        },
        "page_content":"<start course metadata for 11-920 Independent Study: Breadth>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Independent Study: Breadth\nCourse Number: 11-920\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan, Robert Frederking\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-920 Independent Study: Breadth>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-930 Dissertation Research.txt"
        },
        "page_content":"<start course metadata for 11-930 Dissertation Research>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Dissertation Research\nCourse Number: 11-930\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: \nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-930 Dissertation Research>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-925 Independent Study_ Area.txt"
        },
        "page_content":"<start course metadata for 11-925 Independent Study: Area>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Independent Study: Area\nCourse Number: 11-925\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-925 Independent Study: Area>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Summer 2024 (Mini 1 and Full Summer) 11-910 Directed Research.txt"
        },
        "page_content":"<start course metadata for 11-910 Directed Research>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Directed Research\nCourse Number: 11-910\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan, Robert Frederking\nRooms: \nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-910 Directed Research>",
        "type":"Document"
      }
    ],
    "model_output":"\nThe Summer requirement for Year 1 in the Master of Language Technologies program is to complete a directed research project, which can be done through courses such as 11-910 Directed Research, 11-920 Independent Study: Breadth, or 11-925 Independent Study: Area. These courses provide hands-on experience and an in-depth study of a topic in the same area as a chosen elective.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"What's the Summer requirement for Year 1 in the Master of Language Technologies program?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nfour academic semesters (fall, spring, fall, spring) and a summer internship.  \nMIIS: Advanced Study track offers in depth  degree in one of the following areas of \nconcentration:  \n\u2022 Human Language for Language Technologies  \n\u2022 Language Technology Application  \n\u2022 Machine Learning for Language Technologies  \nPart- time options are available in some cases.  \n4.2 Required Units for Degree Attainment  \nTo complete the Master of Science in Intelligent Information Systems, a student must satisfy \nthree types of requirements. Curricular requirements ensure that MIIS students receive\n-----\nRequirements: Students interested in the language technologies minor must complete our prerequisite courses with an average grade of B (3.0) or better before applying to the program. (Students who do not meet this average must submit a letter of explanation along with their application.) Prerequisites include:\n-----\nStudents must complete a semester-long directed research project in the context of being registered for an independent study or thesis.  This should provide hands-on experience and an in-depth study of a topic in same area as a chosen elective.\nAdmission: Students interested in earning a minor in language technologies must apply for admission no later than September 30 of their senior year. An admission decision will usually be made within one month. Students may petition the LTI undergraduate program director to be admitted to the minor earlier or later in their undergraduate careers. To apply, contact the program's director, Carolyn Ros\u00e9.\n-----\nMLT Student Handbook 2023 - 2024\n4 MLT Degree Attainment  \n4.1 Course Requirements  \nIn order to  complete the Master of Language Technologies degree, the student must pass 120 \nor more course units of senior- to-graduate courses, and meet the following criteria:  \n\u2022 within those 120 units, at least 72 units of \u201cLTI\u201d courses and 24 units of \u201cSCS\u201d courses, \n\u2022 within those 72 units, 11 -711, 11- 791 (or an equivalent , see below ), and one ``Task \nOrientation Focus'' class, and  \n\u2022 within those 72 units, at least one of the following:  \no an LTI lab course,  \no 11-792, or  \no project -oriented Masters \u2019 thesis;\n-----\nOption 1. Standard MIIS degree (MIIS-16) - A 16-month track that is completed in three academic semesters (fall, spring, fall) and a summer internship.  \n\nOption 2. MIIS: Advanced Study degree (MIIS-21) - A 21-month track that is completed in four academic semesters (fall, spring, fall, spring) and a summer internship.\n\nMIIS: Advanced Study track offers indepth degree in one of the following areas of concentration:\n\nHuman Language for Language Technologies\nLanguage Technology Application\nMachine Learning for Language Technologies\nPart-time education option is available in some cases.\n-----\nOffice of Graduate and Postdoc Affairs, the Office of the Dean of Student Affairs, and others, \nare included in Appendix A of this handbook.  \n1.2 The MLT Degree  \nThe Master of Language Technologies (MLT) is a research- oriented Master of Science degree \noffered by the Language Technologies Institute (LTI), a graduate department in the School of \nComputer Science at Carnegie Mellon University.  The MLT program is a 24 -month program \nconsisting of courses, directed research, and an optional Masters ' Thesis.  Typical research \nareas include speech processing, information retrieval, machine translation, natural language\n-----\n<start course metadata for 11-920 Independent Study: Breadth>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Independent Study: Breadth\nCourse Number: 11-920\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan, Robert Frederking\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-920 Independent Study: Breadth>\n-----\n<start course metadata for 11-930 Dissertation Research>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Dissertation Research\nCourse Number: 11-930\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: \nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-930 Dissertation Research>\n-----\n<start course metadata for 11-925 Independent Study: Area>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Independent Study: Area\nCourse Number: 11-925\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-925 Independent Study: Area>\n-----\n<start course metadata for 11-910 Directed Research>\nSemester: Summer One\/All 2024 (aka M24, M24 Mini 1 or M24 Full, Summer 2024 Mini 1)\nCourse Name: Directed Research\nCourse Number: 11-910\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan, Robert Frederking\nRooms: \nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-910 Directed Research>\n-----\n\n### Response ###\n\nUser: What's the Summer requirement for Year 1 in the Master of Language Technologies program?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"September 6, 2023",
    "index":19,
    "Q":"When does application for Master of Language Technologies at LTI open for the Fall 2024 period?",
    "A":"September 6, 2023",
    "category":"programs",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Artificial Intelligence and Innovation (MSAII).txt"
        },
        "page_content":"AI Innovation\n\nNatural Language Processing\n\nApplied Machine Learning\n\nWeb Application Development*\n\nDeep Learning\n\nCapstone Project\n(36 units)\n\n*Elective course\n\nFor more information on the MSAII program curriculum and requirements, see the program website.\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Language Technologies (MLT).txt"
        },
        "page_content":"Machine Translation\n\nSelf-Paced Lab\n\nDirected Study\n\nRequired Research\n\n \n\nYear 2\n\nSoftware Engineering for LT (I)\n\nSpeech Understanding\n\nSelf-Paced Lab\n\nDirected Study\n\nSoftware Engineering for LT (II)\n\nDirected Study\n\nElective\n\nRequired Research\nAdmissions: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Intro to ML (MLD)\n\nMIIS Directed Study\n\nQuestion Answering\n\nIntro to Deep Learning\n\nMIIS Capstone Planning Seminar\n\nMIIS Directed Study\n\nInternship\t\nMIIS Capstone Project\n\nLanguage and Statistics\n\nComp Semantics for NLP\n\nML for Signal Processing\n\nElective\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Directed Research\nAdmission: Students applying to the dual degree program must apply through Carnegie Mellon's online application. In addition to the requirements listed below, prospective students must also contact Stacey Young when applying.\n\nCarnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.\n\nFinal Application Deadline",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Computational Data Science (MCDS).txt"
        },
        "page_content":"Advanced Storage Systems\n\nCloud Computing\n\nDistributed Systems\n\nMachine Learning\n\nComputational Data Science Seminar\n\nParallel Computer Architecture and Programming\n\nAdvanced Databases\n\nSearch Engines\n\nSummer Internship\n\n Year 2\n\nComputational Data Science Systems Capstone\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Ph.D. in Language and Information Technology.txt"
        },
        "page_content":"Self-Paced Lab\n\nDirected Study\n\nRequired Research\n\nYear 3\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 4\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 5\n\nDirected Research\n\nDirected Research\n\nDirected Research\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.\n\nFinal Application Deadline",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-700 LTI Colloquium.txt"
        },
        "page_content":"<start course metadata for 11-700 LTI Colloquium>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Yonatan Bisk\nRooms: POS A35\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-935 LTI Practicum.txt"
        },
        "page_content":"<start course metadata for 11-935 LTI Practicum>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Practicum\nCourse Number: 11-935\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-935 LTI Practicum>\n\n<start course description for 11-935 LTI Practicum>\nSemester: Fall 2023 (aka F23)\nCourse Description: This course number is used for students who are on an internship as part of their graduate degree.\n<\/end course description for 11-935 LTI Practicum>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/LTI Concentration.txt"
        },
        "page_content":"Students must complete a semester-long directed research project in the context of being registered for an independent study or thesis.  This should provide hands-on experience and an in-depth study of a topic in same area as a chosen elective.\nAdmission: Students interested in earning a minor in language technologies must apply for admission no later than September 30 of their senior year. An admission decision will usually be made within one month. Students may petition the LTI undergraduate program director to be admitted to the minor earlier or later in their undergraduate careers. To apply, contact the program's director, Carolyn Ros\u00e9.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-590 LTI Minor Project - Advanced.txt"
        },
        "page_content":"<start course metadata for 11-590 LTI Minor Project - Advanced>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Minor Project - Advanced\nCourse Number: 11-590\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-590 LTI Minor Project - Advanced>\n\n<start course description for 11-590 LTI Minor Project - Advanced>\nSemester: Fall 2023 (aka F23)\nCourse Description: No course description provided.\n<\/end course description for 11-590 LTI Minor Project - Advanced>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Artificial Intelligence and Innovation (MSAII).txt"
        },
        "page_content":"AI Innovation\n\nNatural Language Processing\n\nApplied Machine Learning\n\nWeb Application Development*\n\nDeep Learning\n\nCapstone Project\n(36 units)\n\n*Elective course\n\nFor more information on the MSAII program curriculum and requirements, see the program website.\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Language Technologies (MLT).txt"
        },
        "page_content":"Machine Translation\n\nSelf-Paced Lab\n\nDirected Study\n\nRequired Research\n\n \n\nYear 2\n\nSoftware Engineering for LT (I)\n\nSpeech Understanding\n\nSelf-Paced Lab\n\nDirected Study\n\nSoftware Engineering for LT (II)\n\nDirected Study\n\nElective\n\nRequired Research\nAdmissions: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Science in Intelligent Information Systems (MIIS).txt"
        },
        "page_content":"Intro to ML (MLD)\n\nMIIS Directed Study\n\nQuestion Answering\n\nIntro to Deep Learning\n\nMIIS Capstone Planning Seminar\n\nMIIS Directed Study\n\nInternship\t\nMIIS Capstone Project\n\nLanguage and Statistics\n\nComp Semantics for NLP\n\nML for Signal Processing\n\nElective\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Dual-Degree Ph.D. in Language and Information Technologies (Portugal Partnership).txt"
        },
        "page_content":"Directed Research\nAdmission: Students applying to the dual degree program must apply through Carnegie Mellon's online application. In addition to the requirements listed below, prospective students must also contact Stacey Young when applying.\n\nCarnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.\n\nFinal Application Deadline",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Master of Computational Data Science (MCDS).txt"
        },
        "page_content":"Advanced Storage Systems\n\nCloud Computing\n\nDistributed Systems\n\nMachine Learning\n\nComputational Data Science Seminar\n\nParallel Computer Architecture and Programming\n\nAdvanced Databases\n\nSearch Engines\n\nSummer Internship\n\n Year 2\n\nComputational Data Science Systems Capstone\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/Ph.D. in Language and Information Technology.txt"
        },
        "page_content":"Self-Paced Lab\n\nDirected Study\n\nRequired Research\n\nYear 3\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 4\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 5\n\nDirected Research\n\nDirected Research\n\nDirected Research\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.\n\nFinal Application Deadline",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-700 LTI Colloquium.txt"
        },
        "page_content":"<start course metadata for 11-700 LTI Colloquium>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Yonatan Bisk\nRooms: POS A35\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-935 LTI Practicum.txt"
        },
        "page_content":"<start course metadata for 11-935 LTI Practicum>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Practicum\nCourse Number: 11-935\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-935 LTI Practicum>\n\n<start course description for 11-935 LTI Practicum>\nSemester: Fall 2023 (aka F23)\nCourse Description: This course number is used for students who are on an internship as part of their graduate degree.\n<\/end course description for 11-935 LTI Practicum>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/webpages\/LTI Concentration.txt"
        },
        "page_content":"Students must complete a semester-long directed research project in the context of being registered for an independent study or thesis.  This should provide hands-on experience and an in-depth study of a topic in same area as a chosen elective.\nAdmission: Students interested in earning a minor in language technologies must apply for admission no later than September 30 of their senior year. An admission decision will usually be made within one month. Students may petition the LTI undergraduate program director to be admitted to the minor earlier or later in their undergraduate careers. To apply, contact the program's director, Carolyn Ros\u00e9.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 11-590 LTI Minor Project - Advanced.txt"
        },
        "page_content":"<start course metadata for 11-590 LTI Minor Project - Advanced>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Minor Project - Advanced\nCourse Number: 11-590\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-590 LTI Minor Project - Advanced>\n\n<start course description for 11-590 LTI Minor Project - Advanced>\nSemester: Fall 2023 (aka F23)\nCourse Description: No course description provided.\n<\/end course description for 11-590 LTI Minor Project - Advanced>",
        "type":"Document"
      }
    ],
    "model_output":"\nThe application period for Fall 2024 will open on September 6, 2023.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"When does application for Master of Language Technologies at LTI open for the Fall 2024 period?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nAI Innovation\n\nNatural Language Processing\n\nApplied Machine Learning\n\nWeb Application Development*\n\nDeep Learning\n\nCapstone Project\n(36 units)\n\n*Elective course\n\nFor more information on the MSAII program curriculum and requirements, see the program website.\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.\n-----\nMachine Translation\n\nSelf-Paced Lab\n\nDirected Study\n\nRequired Research\n\n \n\nYear 2\n\nSoftware Engineering for LT (I)\n\nSpeech Understanding\n\nSelf-Paced Lab\n\nDirected Study\n\nSoftware Engineering for LT (II)\n\nDirected Study\n\nElective\n\nRequired Research\nAdmissions: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.\n-----\nIntro to ML (MLD)\n\nMIIS Directed Study\n\nQuestion Answering\n\nIntro to Deep Learning\n\nMIIS Capstone Planning Seminar\n\nMIIS Directed Study\n\nInternship\t\nMIIS Capstone Project\n\nLanguage and Statistics\n\nComp Semantics for NLP\n\nML for Signal Processing\n\nElective\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.\n-----\nDirected Research\nAdmission: Students applying to the dual degree program must apply through Carnegie Mellon's online application. In addition to the requirements listed below, prospective students must also contact Stacey Young when applying.\n\nCarnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.\n\nFinal Application Deadline\n-----\nAdvanced Storage Systems\n\nCloud Computing\n\nDistributed Systems\n\nMachine Learning\n\nComputational Data Science Seminar\n\nParallel Computer Architecture and Programming\n\nAdvanced Databases\n\nSearch Engines\n\nSummer Internship\n\n Year 2\n\nComputational Data Science Systems Capstone\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.\n-----\nSelf-Paced Lab\n\nDirected Study\n\nRequired Research\n\nYear 3\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 4\n\nDirected Research\n\nDirected Research\n\nDirected Research\n\nYear 5\n\nDirected Research\n\nDirected Research\n\nDirected Research\nAdmission: Carnegie Mellon's School of Computer Science has a centralized online application process. Applications and all supporting documentation for fall admission to any of the LTI's graduate programs must be received by the application deadline. Incomplete applications will not be considered. The application period for Fall 2024 will open on September 6, 2023.\n\nFinal Application Deadline\n-----\n<start course metadata for 11-700 LTI Colloquium>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Colloquium\nCourse Number: 11-700\nDepartment: Language Technologies Institute\nNumber of Units: 6\nPrerequisites: None\nInstructors: Fernando Diaz, Yonatan Bisk\nRooms: POS A35\nLocations: Lisbon, Portugal; Pittsburgh, Pennsylvania\n<\/end course metadata for 11-700 LTI Colloquium>\n-----\n<start course metadata for 11-935 LTI Practicum>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Practicum\nCourse Number: 11-935\nDepartment: Language Technologies Institute\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Jamie Callan\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-935 LTI Practicum>\n\n<start course description for 11-935 LTI Practicum>\nSemester: Fall 2023 (aka F23)\nCourse Description: This course number is used for students who are on an internship as part of their graduate degree.\n<\/end course description for 11-935 LTI Practicum>\n-----\nStudents must complete a semester-long directed research project in the context of being registered for an independent study or thesis.  This should provide hands-on experience and an in-depth study of a topic in same area as a chosen elective.\nAdmission: Students interested in earning a minor in language technologies must apply for admission no later than September 30 of their senior year. An admission decision will usually be made within one month. Students may petition the LTI undergraduate program director to be admitted to the minor earlier or later in their undergraduate careers. To apply, contact the program's director, Carolyn Ros\u00e9.\n-----\n<start course metadata for 11-590 LTI Minor Project - Advanced>\nSemester: Fall 2023 (aka F23)\nCourse Name: LTI Minor Project - Advanced\nCourse Number: 11-590\nDepartment: Language Technologies Institute\nNumber of Units: 12\nPrerequisites: None\nInstructors: Instructor TBA\nRooms: \nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 11-590 LTI Minor Project - Advanced>\n\n<start course description for 11-590 LTI Minor Project - Advanced>\nSemester: Fall 2023 (aka F23)\nCourse Description: No course description provided.\n<\/end course description for 11-590 LTI Minor Project - Advanced>\n-----\n\n### Response ###\n\nUser: When does application for Master of Language Technologies at LTI open for the Fall 2024 period?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.6666666667,
    "recall":1.0,
    "precision":0.5,
    "A_hat":"8:00 AM-9:00 AM ET, 2:00 PM-11:00 PM ET",
    "index":20,
    "Q":"At what time of the day can one attend the Mixed Reality: A Virtual Reality Escape Room Experience event at the 2024 CMU Carnival?",
    "A":"8:00 AM-9:00 AM ET",
    "category":"events",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 12, 2024.txt"
        },
        "page_content":"Title: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 12, 2024\nTime: 2:00 PM-11:00 PM ET\n\nGet ready to experience an evolution of gaming as participants step through a Meta Quest 3-powered walkthrough\/escape room with interactive installations. This project is part of the LBE Project Showcase, which is hosted by master's\u00a0students from the Entertainment Technology Center (ETC). Note: No advance registration required. No event fee. This event is open to the entire CMU community and their guests. This experience is recommended for children ages 12 and older.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 11, 2024.txt"
        },
        "page_content":"Title: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 11, 2024\nTime: 8:00 AM-9:00 AM ET\n\nGet ready to experience an evolution of gaming as participants step through a Meta Quest 3-powered walkthrough\/escape room with interactive installations. This project is part of the LBE Project Showcase, which is hosted by master's\u00a0students from the Entertainment Technology Center (ETC). Note: No advance registration required. No event fee. This event is open to the entire CMU community and their guests. This experience is recommended for children ages 12 and older.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 12, 2024\nTime: 2:00 PM-11:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 11, 2024\nTime: 8:00 AM-9:00 AM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth! on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 11, 2024\nTime: 3:30 PM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth! on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth! on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Wellness Tent on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Wellness Tent\n\nTitle: Carnival Wellness Tent\nDate: April 11, 2024\nTime: 3:30 PM-7:00 PM ET\n\nRelax and breathe with calming activities, sessions, information and much more. Full schedule available in March. Sponsored by Wellness Initiatives and the CMU Alumni Association. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Wellness Tent on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Wellness Tent\n\nTitle: Carnival Wellness Tent\nDate: April 12, 2024\nTime: 11:00 AM-7:00 PM ET\n\nRelax and breathe with calming activities, sessions, information and much more. Full schedule available in March. Sponsored by Wellness Initiatives and the CMU Alumni Association.Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Wellness Tent on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Wellness Tent\n\nTitle: Carnival Wellness Tent\nDate: April 13, 2024\nTime: 11:00 AM-7:00 PM ET\n\nRelax and breathe with calming activities, sessions, information and much more. Full schedule available in March. Sponsored by Wellness Initiatives and the CMU Alumni Association.Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 12, 2024.txt"
        },
        "page_content":"Title: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 12, 2024\nTime: 2:00 PM-11:00 PM ET\n\nGet ready to experience an evolution of gaming as participants step through a Meta Quest 3-powered walkthrough\/escape room with interactive installations. This project is part of the LBE Project Showcase, which is hosted by master's\u00a0students from the Entertainment Technology Center (ETC). Note: No advance registration required. No event fee. This event is open to the entire CMU community and their guests. This experience is recommended for children ages 12 and older.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 11, 2024.txt"
        },
        "page_content":"Title: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 11, 2024\nTime: 8:00 AM-9:00 AM ET\n\nGet ready to experience an evolution of gaming as participants step through a Meta Quest 3-powered walkthrough\/escape room with interactive installations. This project is part of the LBE Project Showcase, which is hosted by master's\u00a0students from the Entertainment Technology Center (ETC). Note: No advance registration required. No event fee. This event is open to the entire CMU community and their guests. This experience is recommended for children ages 12 and older.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 12, 2024\nTime: 2:00 PM-11:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 11, 2024\nTime: 8:00 AM-9:00 AM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth! on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 11, 2024\nTime: 3:30 PM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth! on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth! on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Wellness Tent on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Wellness Tent\n\nTitle: Carnival Wellness Tent\nDate: April 11, 2024\nTime: 3:30 PM-7:00 PM ET\n\nRelax and breathe with calming activities, sessions, information and much more. Full schedule available in March. Sponsored by Wellness Initiatives and the CMU Alumni Association. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Wellness Tent on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Wellness Tent\n\nTitle: Carnival Wellness Tent\nDate: April 12, 2024\nTime: 11:00 AM-7:00 PM ET\n\nRelax and breathe with calming activities, sessions, information and much more. Full schedule available in March. Sponsored by Wellness Initiatives and the CMU Alumni Association.Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Wellness Tent on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Wellness Tent\n\nTitle: Carnival Wellness Tent\nDate: April 13, 2024\nTime: 11:00 AM-7:00 PM ET\n\nRelax and breathe with calming activities, sessions, information and much more. Full schedule available in March. Sponsored by Wellness Initiatives and the CMU Alumni Association.Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe Mixed Reality: A Virtual Reality Escape Room Experience event at the 2024 CMU Carnival can be attended at the following times:\n\n* April 11, 2024: 8:00 AM-9:00 AM ET\n* April 12, 2024: 2:00 PM-11:00 PM ET\n\n",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"At what time of the day can one attend the Mixed Reality: A Virtual Reality Escape Room Experience event at the 2024 CMU Carnival?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 12, 2024\nTime: 2:00 PM-11:00 PM ET\n\nGet ready to experience an evolution of gaming as participants step through a Meta Quest 3-powered walkthrough\/escape room with interactive installations. This project is part of the LBE Project Showcase, which is hosted by master's\u00a0students from the Entertainment Technology Center (ETC). Note: No advance registration required. No event fee. This event is open to the entire CMU community and their guests. This experience is recommended for children ages 12 and older.\n-----\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 11, 2024\nTime: 8:00 AM-9:00 AM ET\n\nGet ready to experience an evolution of gaming as participants step through a Meta Quest 3-powered walkthrough\/escape room with interactive installations. This project is part of the LBE Project Showcase, which is hosted by master's\u00a0students from the Entertainment Technology Center (ETC). Note: No advance registration required. No event fee. This event is open to the entire CMU community and their guests. This experience is recommended for children ages 12 and older.\n-----\nSpring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 12, 2024\nTime: 2:00 PM-11:00 PM ET\n-----\nSpring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 11, 2024\nTime: 8:00 AM-9:00 AM ET\n-----\nSpring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 11, 2024\nTime: 3:30 PM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.\n-----\nSpring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.\n-----\nSpring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.\n-----\nSpring Carnival 2024 Event Carnival Wellness Tent\n\nTitle: Carnival Wellness Tent\nDate: April 11, 2024\nTime: 3:30 PM-7:00 PM ET\n\nRelax and breathe with calming activities, sessions, information and much more. Full schedule available in March. Sponsored by Wellness Initiatives and the CMU Alumni Association. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.\n-----\nSpring Carnival 2024 Event Carnival Wellness Tent\n\nTitle: Carnival Wellness Tent\nDate: April 12, 2024\nTime: 11:00 AM-7:00 PM ET\n\nRelax and breathe with calming activities, sessions, information and much more. Full schedule available in March. Sponsored by Wellness Initiatives and the CMU Alumni Association.Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.\n-----\nSpring Carnival 2024 Event Carnival Wellness Tent\n\nTitle: Carnival Wellness Tent\nDate: April 13, 2024\nTime: 11:00 AM-7:00 PM ET\n\nRelax and breathe with calming activities, sessions, information and much more. Full schedule available in March. Sponsored by Wellness Initiatives and the CMU Alumni Association.Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.\n-----\n\n### Response ###\n\nUser: At what time of the day can one attend the Mixed Reality: A Virtual Reality Escape Room Experience event at the 2024 CMU Carnival?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Yes",
    "index":21,
    "Q":"Is registration required for the AB Tech Alumni & Student Mixer event at the 2024 CMU Carnival?",
    "A":"Yes",
    "category":"events",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event AB Tech Alumni & Student Mixer on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event AB Tech Alumni & Student Mixer\n\nTitle: AB Tech Alumni & Student Mixer\nDate: April 12, 2024\nTime: 4:00 PM-6:00 PM ET\n\nJoin current and former members of AB Tech for food, fun and conversation during our annual Spring Carnival gathering. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the AB Tech community and their guests.Cost: $10\/per attendee for alumni and guestsNo fee for undergraduate students.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event ChemE Alumni, Faculty & Student Mixer on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event ChemE Alumni, Faculty & Student Mixer\n\nTitle: ChemE Alumni, Faculty & Student Mixer\nDate: April 12, 2024\nTime: 3:00 PM-5:00 PM ET\n\nChemE alumni are invited to join the faculty and students in the Rothfus Lab for a meet and greet with refreshments. Catch up on what's new with student and faculty research projects and other department activities. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the ChemE community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Reunion Reserved Seating During Campus Community Lunch on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Reunion Reserved Seating During Campus Community Lunch\n\nTitle: Reunion Reserved Seating During Campus Community Lunch\nDate: April 12, 2024\nTime: 11:30 AM-1:30 PM ET\n\nReunion attendees are welcome to celebrate campus sustainability at a complimentary lunch open to the entire CMU community.\u00a0There will be reserved seating in the Reunion Tent for all Reunion celebrants with a name badge.Note: No registration required. Walk-ins welcome. No event fee. This event is open to alumni Reunion celebrants and their guests only.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event The Tartan Alumni & Student Reception on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event The Tartan Alumni & Student Reception\n\nTitle: The Tartan Alumni & Student Reception\nDate: April 13, 2024\nTime: 2:00 PM-3:00 PM ET\n\nMeet the current student staff of The Tartan and mingle with your former classmates from your time as part of CMU's student-run newspaper.Note: Registration required. No event fee. This event is for alumni and families of the The Tartan community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Activities Tent on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Activities Tent\n\nTitle: Carnival Activities Tent\nDate: April 12, 2024\nTime: 11:00 AM-7:00 PM ET\n\nFeaturing entertainment and games for students, alumni, faculty and staff throughout the entire weekend. Full schedule coming in March. Sponsored by the Spring Carnival Committee and the CMU Alumni Association.\u00a0 \u00a0Note: No registration required. No event fee. This event is open to students, faculty, staff and alumni. Parents: Check out the separate kidzone area for kid-focused fun and activities.   Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Activities Tent on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Activities Tent\n\nTitle: Carnival Activities Tent\nDate: April 13, 2024\nTime: 11:00 AM-7:00 PM ET\n\nFeaturing entertainment and games for students, alumni, faculty and staff throughout the entire weekend. Full schedule coming in March. Sponsored by the Spring Carnival Committee and the CMU Alumni Association.\u00a0 \u00a0Note: No registration required. No event fee. This event is open to students, faculty, staff and alumni. Parents: Check out the separate kidzone area for kid-focused fun and activities.   Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Project Olympus Show & Tell on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Project Olympus Show & Tell\n\nTitle: Project Olympus Show & Tell\nDate: April 11, 2024\nTime: 4:00 PM-6:00 PM ET\n\nMeet current student and alumni entrepreneurs at this showcase of research with a focus on startups and spin-offs. Note: Registration required. No event fee. Open to the CMU community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Activities Tent on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Activities Tent\n\nTitle: Carnival Activities Tent\nDate: April 11, 2024\nTime: 3:30 PM-7:00 PM ET\n\nFeaturing entertainment and games for students, alumni, faculty and staff throughout the entire weekend. Full schedule coming in March. Sponsored by the Spring Carnival Committee and the CMU Alumni Association. Note: No registration required. No event fee. This event is open to students, faculty, staff and alumni. Parents: Check out the separate kidzone area for kid-focused fun and activities. Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Buggy Alumni Association Information Tent on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Buggy Alumni Association Information Tent\n\nTitle: Buggy Alumni Association Information Tent\nDate: April 13, 2024\nTime: 8:00 AM-12:00 PM ET\n\nCome by the Buggy Alumni Association tent during Sweepstakes races to meet your BAA officers and learn about our work. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Buggy Alumni Association Information Tent on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Buggy Alumni Association Information Tent\n\nTitle: Buggy Alumni Association Information Tent\nDate: April 12, 2024\nTime: 8:00 AM-12:00 PM ET\n\nCome by the Buggy Alumni Association tent during Sweepstakes races to meet your BAA officers and learn about our work. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event AB Tech Alumni & Student Mixer on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event AB Tech Alumni & Student Mixer\n\nTitle: AB Tech Alumni & Student Mixer\nDate: April 12, 2024\nTime: 4:00 PM-6:00 PM ET\n\nJoin current and former members of AB Tech for food, fun and conversation during our annual Spring Carnival gathering. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the AB Tech community and their guests.Cost: $10\/per attendee for alumni and guestsNo fee for undergraduate students.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event ChemE Alumni, Faculty & Student Mixer on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event ChemE Alumni, Faculty & Student Mixer\n\nTitle: ChemE Alumni, Faculty & Student Mixer\nDate: April 12, 2024\nTime: 3:00 PM-5:00 PM ET\n\nChemE alumni are invited to join the faculty and students in the Rothfus Lab for a meet and greet with refreshments. Catch up on what's new with student and faculty research projects and other department activities. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the ChemE community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Reunion Reserved Seating During Campus Community Lunch on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Reunion Reserved Seating During Campus Community Lunch\n\nTitle: Reunion Reserved Seating During Campus Community Lunch\nDate: April 12, 2024\nTime: 11:30 AM-1:30 PM ET\n\nReunion attendees are welcome to celebrate campus sustainability at a complimentary lunch open to the entire CMU community.\u00a0There will be reserved seating in the Reunion Tent for all Reunion celebrants with a name badge.Note: No registration required. Walk-ins welcome. No event fee. This event is open to alumni Reunion celebrants and their guests only.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event The Tartan Alumni & Student Reception on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event The Tartan Alumni & Student Reception\n\nTitle: The Tartan Alumni & Student Reception\nDate: April 13, 2024\nTime: 2:00 PM-3:00 PM ET\n\nMeet the current student staff of The Tartan and mingle with your former classmates from your time as part of CMU's student-run newspaper.Note: Registration required. No event fee. This event is for alumni and families of the The Tartan community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Activities Tent on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Activities Tent\n\nTitle: Carnival Activities Tent\nDate: April 12, 2024\nTime: 11:00 AM-7:00 PM ET\n\nFeaturing entertainment and games for students, alumni, faculty and staff throughout the entire weekend. Full schedule coming in March. Sponsored by the Spring Carnival Committee and the CMU Alumni Association.\u00a0 \u00a0Note: No registration required. No event fee. This event is open to students, faculty, staff and alumni. Parents: Check out the separate kidzone area for kid-focused fun and activities.   Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Activities Tent on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Activities Tent\n\nTitle: Carnival Activities Tent\nDate: April 13, 2024\nTime: 11:00 AM-7:00 PM ET\n\nFeaturing entertainment and games for students, alumni, faculty and staff throughout the entire weekend. Full schedule coming in March. Sponsored by the Spring Carnival Committee and the CMU Alumni Association.\u00a0 \u00a0Note: No registration required. No event fee. This event is open to students, faculty, staff and alumni. Parents: Check out the separate kidzone area for kid-focused fun and activities.   Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Project Olympus Show & Tell on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Project Olympus Show & Tell\n\nTitle: Project Olympus Show & Tell\nDate: April 11, 2024\nTime: 4:00 PM-6:00 PM ET\n\nMeet current student and alumni entrepreneurs at this showcase of research with a focus on startups and spin-offs. Note: Registration required. No event fee. Open to the CMU community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Activities Tent on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Activities Tent\n\nTitle: Carnival Activities Tent\nDate: April 11, 2024\nTime: 3:30 PM-7:00 PM ET\n\nFeaturing entertainment and games for students, alumni, faculty and staff throughout the entire weekend. Full schedule coming in March. Sponsored by the Spring Carnival Committee and the CMU Alumni Association. Note: No registration required. No event fee. This event is open to students, faculty, staff and alumni. Parents: Check out the separate kidzone area for kid-focused fun and activities. Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Buggy Alumni Association Information Tent on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Buggy Alumni Association Information Tent\n\nTitle: Buggy Alumni Association Information Tent\nDate: April 13, 2024\nTime: 8:00 AM-12:00 PM ET\n\nCome by the Buggy Alumni Association tent during Sweepstakes races to meet your BAA officers and learn about our work. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Buggy Alumni Association Information Tent on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Buggy Alumni Association Information Tent\n\nTitle: Buggy Alumni Association Information Tent\nDate: April 12, 2024\nTime: 8:00 AM-12:00 PM ET\n\nCome by the Buggy Alumni Association tent during Sweepstakes races to meet your BAA officers and learn about our work. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.",
        "type":"Document"
      }
    ],
    "model_output":"\nYes, registration is required for the AB Tech Alumni & Student Mixer event at the 2024 CMU Carnival. According to the event description, registration is required for this event, and walk-ins are welcome as space permits. There is no event fee for this event, and it is open to the AB Tech community and their guests.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Is registration required for the AB Tech Alumni & Student Mixer event at the 2024 CMU Carnival?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nSpring Carnival 2024 Event AB Tech Alumni & Student Mixer\n\nTitle: AB Tech Alumni & Student Mixer\nDate: April 12, 2024\nTime: 4:00 PM-6:00 PM ET\n\nJoin current and former members of AB Tech for food, fun and conversation during our annual Spring Carnival gathering. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the AB Tech community and their guests.Cost: $10\/per attendee for alumni and guestsNo fee for undergraduate students.\n-----\nSpring Carnival 2024 Event ChemE Alumni, Faculty & Student Mixer\n\nTitle: ChemE Alumni, Faculty & Student Mixer\nDate: April 12, 2024\nTime: 3:00 PM-5:00 PM ET\n\nChemE alumni are invited to join the faculty and students in the Rothfus Lab for a meet and greet with refreshments. Catch up on what's new with student and faculty research projects and other department activities. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the ChemE community and their guests.\n-----\nSpring Carnival 2024 Event Reunion Reserved Seating During Campus Community Lunch\n\nTitle: Reunion Reserved Seating During Campus Community Lunch\nDate: April 12, 2024\nTime: 11:30 AM-1:30 PM ET\n\nReunion attendees are welcome to celebrate campus sustainability at a complimentary lunch open to the entire CMU community.\u00a0There will be reserved seating in the Reunion Tent for all Reunion celebrants with a name badge.Note: No registration required. Walk-ins welcome. No event fee. This event is open to alumni Reunion celebrants and their guests only.\n-----\nSpring Carnival 2024 Event The Tartan Alumni & Student Reception\n\nTitle: The Tartan Alumni & Student Reception\nDate: April 13, 2024\nTime: 2:00 PM-3:00 PM ET\n\nMeet the current student staff of The Tartan and mingle with your former classmates from your time as part of CMU's student-run newspaper.Note: Registration required. No event fee. This event is for alumni and families of the The Tartan community and their guests.\n-----\nSpring Carnival 2024 Event Carnival Activities Tent\n\nTitle: Carnival Activities Tent\nDate: April 12, 2024\nTime: 11:00 AM-7:00 PM ET\n\nFeaturing entertainment and games for students, alumni, faculty and staff throughout the entire weekend. Full schedule coming in March. Sponsored by the Spring Carnival Committee and the CMU Alumni Association.\u00a0 \u00a0Note: No registration required. No event fee. This event is open to students, faculty, staff and alumni. Parents: Check out the separate kidzone area for kid-focused fun and activities.   Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.\n-----\nSpring Carnival 2024 Event Carnival Activities Tent\n\nTitle: Carnival Activities Tent\nDate: April 13, 2024\nTime: 11:00 AM-7:00 PM ET\n\nFeaturing entertainment and games for students, alumni, faculty and staff throughout the entire weekend. Full schedule coming in March. Sponsored by the Spring Carnival Committee and the CMU Alumni Association.\u00a0 \u00a0Note: No registration required. No event fee. This event is open to students, faculty, staff and alumni. Parents: Check out the separate kidzone area for kid-focused fun and activities.   Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.\n-----\nSpring Carnival 2024 Event Project Olympus Show & Tell\n\nTitle: Project Olympus Show & Tell\nDate: April 11, 2024\nTime: 4:00 PM-6:00 PM ET\n\nMeet current student and alumni entrepreneurs at this showcase of research with a focus on startups and spin-offs. Note: Registration required. No event fee. Open to the CMU community and their guests.\n-----\nSpring Carnival 2024 Event Carnival Activities Tent\n\nTitle: Carnival Activities Tent\nDate: April 11, 2024\nTime: 3:30 PM-7:00 PM ET\n\nFeaturing entertainment and games for students, alumni, faculty and staff throughout the entire weekend. Full schedule coming in March. Sponsored by the Spring Carnival Committee and the CMU Alumni Association. Note: No registration required. No event fee. This event is open to students, faculty, staff and alumni. Parents: Check out the separate kidzone area for kid-focused fun and activities. Weekend hours:Thursday: 3-7 p.m.Friday & Saturday: 11 a.m. to 7 p.m.\n-----\nSpring Carnival 2024 Event Buggy Alumni Association Information Tent\n\nTitle: Buggy Alumni Association Information Tent\nDate: April 13, 2024\nTime: 8:00 AM-12:00 PM ET\n\nCome by the Buggy Alumni Association tent during Sweepstakes races to meet your BAA officers and learn about our work. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.\n-----\nSpring Carnival 2024 Event Buggy Alumni Association Information Tent\n\nTitle: Buggy Alumni Association Information Tent\nDate: April 12, 2024\nTime: 8:00 AM-12:00 PM ET\n\nCome by the Buggy Alumni Association tent during Sweepstakes races to meet your BAA officers and learn about our work. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.\n-----\n\n### Response ###\n\nUser: Is registration required for the AB Tech Alumni & Student Mixer event at the 2024 CMU Carnival?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"10",
    "index":22,
    "Q":"What's the cost of seeing Scotch'n'Soda Theatre Carnival Show: The Little Mermaid for alumni and guests at Carnival?",
    "A":"$10",
    "category":"events",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 13, 2024\nTime: 7:00 PM-9:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 11, 2024\nTime: 7:00 PM-9:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 12, 2024\nTime: 4\/12\/24 \u2013 4\/13\/2411:00 PM-1:00 AM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 13, 2024.txt"
        },
        "page_content":"March and at the door. Cost: $5 for students\/faculty\/staff; $10 for alumni and guests. Note: Disney's The Little Mermaid is presented through special arrangement with Music Theatre International (MTI). All authorized performance materials are also supplied by MTI.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 13, 2024.txt"
        },
        "page_content":"Come celebrate Carnival with Scotch'n'Soda Theatre, and join us for a performance under the sea! This year, Scotch'n'Soda is thrilled to present our production of Disney's The Little Mermaid! Adapted from the wildly popular animated film and Hans Christian Anderson's original\u00a0fairytale, the musical follows Ariel, King Triton's youngest daughter, who wishes to explore the world up above and pursue the human Prince Eric. But the bargains and sea witches aren't all that they seem, and Ariel needs the help of her colorful friends, Flounder the fish, Scuttle the seagull and Sebastian the crab to restore order under the sea. Sing along with all of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/Spring Carnival 2024 Overview.txt"
        },
        "page_content":"-   Scotch\u2019n\u2019Soda\u2019s Carnival Show: The Little Mermaid: Join S\u2019n\u2019S for their biggest S\u2019n\u2019S production of the year.\n-   Daily \u201ccan\u2019t miss\u201d events:\n    -   Thursday: Carnival Opening Ceremony; Kiltie Band Concert\n    -   Friday: Buggy; Community Lunch; Mobot; Douse-a-Dean; Tartans Got Talent\n    -   Saturday: Buggy; Food Truck Fest; AB Concert",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 11, 2024.txt"
        },
        "page_content":"and guests. Note: Disney's The Little Mermaid is presented through special arrangement with Music Theatre International (MTI). All authorized performance materials are also supplied by MTI.CostTickets will be available online in March and at the door. Cost: $5 for students\/faculty\/staff; $10 for alumni and guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 12, 2024.txt"
        },
        "page_content":"and guests.Note: Disney's The Little Mermaid is presented through special arrangement with Music Theatre International (MTI). All authorized performance materials are also supplied by MTI.CostTickets will be available online in March and at the door. Cost: $5 for students\/faculty\/staff; $10 for alumni and guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Alumni Brunch on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Alumni Brunch\n\nTitle: Scotch'n'Soda Theatre Alumni Brunch\nDate: April 13, 2024\nTime: 12:00 PM-2:00 PM ET\n\nScotch'n'Soda alumni and students are invited to celebrate 86 years of student theater! Network with friends new and old and learn about what is going on in Scotch'n'Soda and the Alumni Association. There is no admission fee and the event ends before the matinee performance. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the S\u2019n\u2019S community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/Spring Carnival 2024 Overview.txt"
        },
        "page_content":"-   Build Week (April 5-11): Follow the student progress during Booth Build  in person or virtually. For those on campus, look for teasers and giveaways to get in the Carnival spirit.\n-   Midway activities throughout the weekend: Booth, rides, inflatables, Activities tent, Wellness tent, Kidzone tent, lawn games and much more. Look for the full schedule of family-friendly activities in March!\n-   Scotch\u2019n\u2019Soda\u2019s Carnival Show: The Little Mermaid: Join S\u2019n\u2019S for their biggest S\u2019n\u2019S production of the year.\n-   Daily \u201ccan\u2019t miss\u201d events:\n    -   Thursday: Carnival Opening Ceremony; Kiltie Band Concert",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 13, 2024\nTime: 7:00 PM-9:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 11, 2024\nTime: 7:00 PM-9:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 12, 2024\nTime: 4\/12\/24 \u2013 4\/13\/2411:00 PM-1:00 AM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 13, 2024.txt"
        },
        "page_content":"March and at the door. Cost: $5 for students\/faculty\/staff; $10 for alumni and guests. Note: Disney's The Little Mermaid is presented through special arrangement with Music Theatre International (MTI). All authorized performance materials are also supplied by MTI.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 13, 2024.txt"
        },
        "page_content":"Come celebrate Carnival with Scotch'n'Soda Theatre, and join us for a performance under the sea! This year, Scotch'n'Soda is thrilled to present our production of Disney's The Little Mermaid! Adapted from the wildly popular animated film and Hans Christian Anderson's original\u00a0fairytale, the musical follows Ariel, King Triton's youngest daughter, who wishes to explore the world up above and pursue the human Prince Eric. But the bargains and sea witches aren't all that they seem, and Ariel needs the help of her colorful friends, Flounder the fish, Scuttle the seagull and Sebastian the crab to restore order under the sea. Sing along with all of",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/Spring Carnival 2024 Overview.txt"
        },
        "page_content":"-   Scotch\u2019n\u2019Soda\u2019s Carnival Show: The Little Mermaid: Join S\u2019n\u2019S for their biggest S\u2019n\u2019S production of the year.\n-   Daily \u201ccan\u2019t miss\u201d events:\n    -   Thursday: Carnival Opening Ceremony; Kiltie Band Concert\n    -   Friday: Buggy; Community Lunch; Mobot; Douse-a-Dean; Tartans Got Talent\n    -   Saturday: Buggy; Food Truck Fest; AB Concert",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 11, 2024.txt"
        },
        "page_content":"and guests. Note: Disney's The Little Mermaid is presented through special arrangement with Music Theatre International (MTI). All authorized performance materials are also supplied by MTI.CostTickets will be available online in March and at the door. Cost: $5 for students\/faculty\/staff; $10 for alumni and guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 12, 2024.txt"
        },
        "page_content":"and guests.Note: Disney's The Little Mermaid is presented through special arrangement with Music Theatre International (MTI). All authorized performance materials are also supplied by MTI.CostTickets will be available online in March and at the door. Cost: $5 for students\/faculty\/staff; $10 for alumni and guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Alumni Brunch on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Alumni Brunch\n\nTitle: Scotch'n'Soda Theatre Alumni Brunch\nDate: April 13, 2024\nTime: 12:00 PM-2:00 PM ET\n\nScotch'n'Soda alumni and students are invited to celebrate 86 years of student theater! Network with friends new and old and learn about what is going on in Scotch'n'Soda and the Alumni Association. There is no admission fee and the event ends before the matinee performance. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the S\u2019n\u2019S community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/Spring Carnival 2024 Overview.txt"
        },
        "page_content":"-   Build Week (April 5-11): Follow the student progress during Booth Build  in person or virtually. For those on campus, look for teasers and giveaways to get in the Carnival spirit.\n-   Midway activities throughout the weekend: Booth, rides, inflatables, Activities tent, Wellness tent, Kidzone tent, lawn games and much more. Look for the full schedule of family-friendly activities in March!\n-   Scotch\u2019n\u2019Soda\u2019s Carnival Show: The Little Mermaid: Join S\u2019n\u2019S for their biggest S\u2019n\u2019S production of the year.\n-   Daily \u201ccan\u2019t miss\u201d events:\n    -   Thursday: Carnival Opening Ceremony; Kiltie Band Concert",
        "type":"Document"
      }
    ],
    "model_output":"\nThe cost of seeing Scotch'n'Soda Theatre Carnival Show: The Little Mermaid for alumni and guests at Carnival is $10.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"What's the cost of seeing Scotch'n'Soda Theatre Carnival Show: The Little Mermaid for alumni and guests at Carnival?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nSpring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 13, 2024\nTime: 7:00 PM-9:00 PM ET\n-----\nSpring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 11, 2024\nTime: 7:00 PM-9:00 PM ET\n-----\nSpring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 12, 2024\nTime: 4\/12\/24 \u2013 4\/13\/2411:00 PM-1:00 AM ET\n-----\nMarch and at the door. Cost: $5 for students\/faculty\/staff; $10 for alumni and guests. Note: Disney's The Little Mermaid is presented through special arrangement with Music Theatre International (MTI). All authorized performance materials are also supplied by MTI.\n-----\nCome celebrate Carnival with Scotch'n'Soda Theatre, and join us for a performance under the sea! This year, Scotch'n'Soda is thrilled to present our production of Disney's The Little Mermaid! Adapted from the wildly popular animated film and Hans Christian Anderson's original\u00a0fairytale, the musical follows Ariel, King Triton's youngest daughter, who wishes to explore the world up above and pursue the human Prince Eric. But the bargains and sea witches aren't all that they seem, and Ariel needs the help of her colorful friends, Flounder the fish, Scuttle the seagull and Sebastian the crab to restore order under the sea. Sing along with all of\n-----\n-   Scotch\u2019n\u2019Soda\u2019s Carnival Show: The Little Mermaid: Join S\u2019n\u2019S for their biggest S\u2019n\u2019S production of the year.\n-   Daily \u201ccan\u2019t miss\u201d events:\n    -   Thursday: Carnival Opening Ceremony; Kiltie Band Concert\n    -   Friday: Buggy; Community Lunch; Mobot; Douse-a-Dean; Tartans Got Talent\n    -   Saturday: Buggy; Food Truck Fest; AB Concert\n-----\nand guests. Note: Disney's The Little Mermaid is presented through special arrangement with Music Theatre International (MTI). All authorized performance materials are also supplied by MTI.CostTickets will be available online in March and at the door. Cost: $5 for students\/faculty\/staff; $10 for alumni and guests.\n-----\nand guests.Note: Disney's The Little Mermaid is presented through special arrangement with Music Theatre International (MTI). All authorized performance materials are also supplied by MTI.CostTickets will be available online in March and at the door. Cost: $5 for students\/faculty\/staff; $10 for alumni and guests.\n-----\nSpring Carnival 2024 Event Scotch'n'Soda Theatre Alumni Brunch\n\nTitle: Scotch'n'Soda Theatre Alumni Brunch\nDate: April 13, 2024\nTime: 12:00 PM-2:00 PM ET\n\nScotch'n'Soda alumni and students are invited to celebrate 86 years of student theater! Network with friends new and old and learn about what is going on in Scotch'n'Soda and the Alumni Association. There is no admission fee and the event ends before the matinee performance. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the S\u2019n\u2019S community and their guests.\n-----\n-   Build Week (April 5-11): Follow the student progress during Booth Build  in person or virtually. For those on campus, look for teasers and giveaways to get in the Carnival spirit.\n-   Midway activities throughout the weekend: Booth, rides, inflatables, Activities tent, Wellness tent, Kidzone tent, lawn games and much more. Look for the full schedule of family-friendly activities in March!\n-   Scotch\u2019n\u2019Soda\u2019s Carnival Show: The Little Mermaid: Join S\u2019n\u2019S for their biggest S\u2019n\u2019S production of the year.\n-   Daily \u201ccan\u2019t miss\u201d events:\n    -   Thursday: Carnival Opening Ceremony; Kiltie Band Concert\n-----\n\n### Response ###\n\nUser: What's the cost of seeing Scotch'n'Soda Theatre Carnival Show: The Little Mermaid for alumni and guests at Carnival?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"School of Architecture Pavilion Dedication & Alumni Open House",
    "index":23,
    "Q":"At which event at the 2024 Carnival can you expect to see Omar Khan?",
    "A":"School of Architecture Pavilion Dedication & Alumni Open House",
    "category":"events",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event School of Architecture Pavilion Dedication & Alumni Open House on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event School of Architecture Pavilion Dedication & Alumni Open House\n\nTitle: School of Architecture Pavilion Dedication & Alumni Open House\nDate: April 13, 2024\nTime: 1:00 PM-2:30 PM ET\n\nDrop by the official Spring Carnival entrance pavilion to meet School of Architecture Head Omar Khan and current students who designed and built this NOMAS-led project. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Architecture community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY).txt"
        },
        "page_content":"<start course description for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>\nSemester: Spring 2024 (aka S24)\nCourse Description: \"In this course you will fabricate and construct the Carnival Entryway Pavilion, to be completed for the 2024 CMU Carnival, April 11-14.   The course is conducted by NOMAS and advised by Professor Omar Khan.\"\n<\/end course description for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 48-617 Carnival Gateway Project Management.txt"
        },
        "page_content":"<start course description for 48-617 Carnival Gateway Project Management>\nSemester: Spring 2024 (aka S24)\nCourse Description: This course is for the team responsible or the design and project management of the Carnival Entryway Pavilion, to be completed for the 2024 CMU Carnival, April 11-14. The course is conducted by NOMAS and advised by Professor Omar Khan.\n<\/end course description for 48-617 Carnival Gateway Project Management>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 48-516 Carnival Gateway Special Project.txt"
        },
        "page_content":"<start course metadata for 48-516 Carnival Gateway Special Project>\nSemester: Spring 2024 (aka S24)\nCourse Name: Carnival Gateway Special Project\nCourse Number: 48-516\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: 48-105\nInstructors: Omar Khan\nRooms: CFA 206A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-516 Carnival Gateway Special Project>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 48-307 Carnival Pavilion.txt"
        },
        "page_content":"<start course metadata for 48-307 Carnival Pavilion>\nSemester: Fall 2023 (aka F23)\nCourse Name: Carnival Pavilion\nCourse Number: 48-307\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Omar Khan, Vicky Achnani\nRooms: CFA 211\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-307 Carnival Pavilion>\n\n<start course description for 48-307 Carnival Pavilion>\nSemester: Fall 2023 (aka F23)\nCourse Description: No course description provided.\n<\/end course description for 48-307 Carnival Pavilion>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 11, 2024\nTime: 3:30 PM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area. Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY).txt"
        },
        "page_content":"<start course metadata for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Carnival Gateway Special Project (CARNIVAL GATEWAY)\nCourse Number: 48-616\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Omar Khan\nRooms: CFA 206A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 48-617 Carnival Gateway Project Management.txt"
        },
        "page_content":"<start course metadata for 48-617 Carnival Gateway Project Management>\nSemester: Spring 2024 (aka S24)\nCourse Name: Carnival Gateway Project Management\nCourse Number: 48-617\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Omar Khan, Vicky Achnani\nRooms: CFA 206A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-617 Carnival Gateway Project Management>",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event School of Architecture Pavilion Dedication & Alumni Open House on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event School of Architecture Pavilion Dedication & Alumni Open House\n\nTitle: School of Architecture Pavilion Dedication & Alumni Open House\nDate: April 13, 2024\nTime: 1:00 PM-2:30 PM ET\n\nDrop by the official Spring Carnival entrance pavilion to meet School of Architecture Head Omar Khan and current students who designed and built this NOMAS-led project. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Architecture community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY).txt"
        },
        "page_content":"<start course description for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>\nSemester: Spring 2024 (aka S24)\nCourse Description: \"In this course you will fabricate and construct the Carnival Entryway Pavilion, to be completed for the 2024 CMU Carnival, April 11-14.   The course is conducted by NOMAS and advised by Professor Omar Khan.\"\n<\/end course description for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 48-617 Carnival Gateway Project Management.txt"
        },
        "page_content":"<start course description for 48-617 Carnival Gateway Project Management>\nSemester: Spring 2024 (aka S24)\nCourse Description: This course is for the team responsible or the design and project management of the Carnival Entryway Pavilion, to be completed for the 2024 CMU Carnival, April 11-14. The course is conducted by NOMAS and advised by Professor Omar Khan.\n<\/end course description for 48-617 Carnival Gateway Project Management>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 48-516 Carnival Gateway Special Project.txt"
        },
        "page_content":"<start course metadata for 48-516 Carnival Gateway Special Project>\nSemester: Spring 2024 (aka S24)\nCourse Name: Carnival Gateway Special Project\nCourse Number: 48-516\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: 48-105\nInstructors: Omar Khan\nRooms: CFA 206A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-516 Carnival Gateway Special Project>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Fall 2023 48-307 Carnival Pavilion.txt"
        },
        "page_content":"<start course metadata for 48-307 Carnival Pavilion>\nSemester: Fall 2023 (aka F23)\nCourse Name: Carnival Pavilion\nCourse Number: 48-307\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Omar Khan, Vicky Achnani\nRooms: CFA 211\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-307 Carnival Pavilion>\n\n<start course description for 48-307 Carnival Pavilion>\nSemester: Fall 2023 (aka F23)\nCourse Description: No course description provided.\n<\/end course description for 48-307 Carnival Pavilion>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 11, 2024\nTime: 3:30 PM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area. Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY).txt"
        },
        "page_content":"<start course metadata for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Carnival Gateway Special Project (CARNIVAL GATEWAY)\nCourse Number: 48-616\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Omar Khan\nRooms: CFA 206A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/courses\/Spring 2024 48-617 Carnival Gateway Project Management.txt"
        },
        "page_content":"<start course metadata for 48-617 Carnival Gateway Project Management>\nSemester: Spring 2024 (aka S24)\nCourse Name: Carnival Gateway Project Management\nCourse Number: 48-617\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Omar Khan, Vicky Achnani\nRooms: CFA 206A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-617 Carnival Gateway Project Management>",
        "type":"Document"
      }
    ],
    "model_output":"\nYou can expect to see Omar Khan at the School of Architecture Pavilion Dedication & Alumni Open House event at the 2024 Carnival. The event takes place on April 13, 2024, from 1:00 PM-2:30 PM ET.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"At which event at the 2024 Carnival can you expect to see Omar Khan?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nSpring Carnival 2024 Event School of Architecture Pavilion Dedication & Alumni Open House\n\nTitle: School of Architecture Pavilion Dedication & Alumni Open House\nDate: April 13, 2024\nTime: 1:00 PM-2:30 PM ET\n\nDrop by the official Spring Carnival entrance pavilion to meet School of Architecture Head Omar Khan and current students who designed and built this NOMAS-led project. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Architecture community and their guests.\n-----\n<start course description for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>\nSemester: Spring 2024 (aka S24)\nCourse Description: \"In this course you will fabricate and construct the Carnival Entryway Pavilion, to be completed for the 2024 CMU Carnival, April 11-14.   The course is conducted by NOMAS and advised by Professor Omar Khan.\"\n<\/end course description for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>\n-----\n<start course description for 48-617 Carnival Gateway Project Management>\nSemester: Spring 2024 (aka S24)\nCourse Description: This course is for the team responsible or the design and project management of the Carnival Entryway Pavilion, to be completed for the 2024 CMU Carnival, April 11-14. The course is conducted by NOMAS and advised by Professor Omar Khan.\n<\/end course description for 48-617 Carnival Gateway Project Management>\n-----\n<start course metadata for 48-516 Carnival Gateway Special Project>\nSemester: Spring 2024 (aka S24)\nCourse Name: Carnival Gateway Special Project\nCourse Number: 48-516\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: 48-105\nInstructors: Omar Khan\nRooms: CFA 206A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-516 Carnival Gateway Special Project>\n-----\n<start course metadata for 48-307 Carnival Pavilion>\nSemester: Fall 2023 (aka F23)\nCourse Name: Carnival Pavilion\nCourse Number: 48-307\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Omar Khan, Vicky Achnani\nRooms: CFA 211\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-307 Carnival Pavilion>\n\n<start course description for 48-307 Carnival Pavilion>\nSemester: Fall 2023 (aka F23)\nCourse Description: No course description provided.\n<\/end course description for 48-307 Carnival Pavilion>\n-----\nSpring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 11, 2024\nTime: 3:30 PM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area. Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.\n-----\nSpring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.\n-----\nSpring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.\n-----\n<start course metadata for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>\nSemester: Spring 2024 (aka S24)\nCourse Name: Carnival Gateway Special Project (CARNIVAL GATEWAY)\nCourse Number: 48-616\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Omar Khan\nRooms: CFA 206A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-616 Carnival Gateway Special Project (CARNIVAL GATEWAY)>\n-----\n<start course metadata for 48-617 Carnival Gateway Project Management>\nSemester: Spring 2024 (aka S24)\nCourse Name: Carnival Gateway Project Management\nCourse Number: 48-617\nDepartment: Architecture\nNumber of Units: N\/A\nPrerequisites: None\nInstructors: Omar Khan, Vicky Achnani\nRooms: CFA 206A\nLocations: Pittsburgh, Pennsylvania\n<\/end course metadata for 48-617 Carnival Gateway Project Management>\n-----\n\n### Response ###\n\nUser: At which event at the 2024 Carnival can you expect to see Omar Khan?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"Reunion Weekend",
    "index":24,
    "Q":"Which other major event is held in conjunction with Spring Carnival 2024?",
    "A":"Reunion Weekend",
    "category":"events",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/Spring Carnival 2024 Reunion Overview.txt"
        },
        "page_content":"Spring Carnival 2024 Reunion Overview\n\nIt\u2019s time to celebrate, show your Tartan Pride, revisit old memories and create new ones \u2014 together! This year\u2019s reunion celebration will be held on campus, April 11-14, in conjunction with Spring Carnival. We are excited to welcome back undergraduate classes ending in 4s and 9s, as well as the Class of 2023, this year. Additionally, we invite all Half Century Tartans (Classes of 1973 and prior) to attend reunion events.\n\nRegistration is required to attend both virtual and\/or in-person activities.\n\nReunion Weekend Highlights\n\nMolly\u2019s Trolleys Tours\n\nThursday, April 11",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event HLAA Presents_ Gozando y Triunfando, A Carnival Celebration on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event HLAA Presents: Gozando y Triunfando, A Carnival Celebration\n\nTitle: HLAA Presents: Gozando y Triunfando, A Carnival Celebration\nDate: April 13, 2024\nTime: 9:00 AM-12:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 12, 2024\nTime: 2:00 PM-11:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 11, 2024\nTime: 8:00 AM-9:00 AM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 13, 2024\nTime: 7:00 PM-9:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 11, 2024\nTime: 7:00 PM-9:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event CMBAA\u2019s Spring Carnival Meeting on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event CMBAA\u2019s Spring Carnival Meeting\n\nTitle: CMBAA\u2019s Spring Carnival Meeting\nDate: April 13, 2024\nTime: 1:00 PM-3:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 12, 2024\nTime: 4\/12\/24 \u2013 4\/13\/2411:00 PM-1:00 AM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event The Highmark Center for Health, Wellness and Athletics Tours on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event The Highmark Center for Health, Wellness and Athletics Tours\n\nTitle: The Highmark Center for Health, Wellness and Athletics Tours\nDate: April 13, 2024\nTime: 1:00 PM-4:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Crafting with the Spring Carnival Committee on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Crafting with the Spring Carnival Committee\n\nTitle: Crafting with the Spring Carnival Committee\nDate: April 13, 2024\nTime: 2:00 PM-4:00 PM ET\n\nThe Spring Carnival Committee (SCC) invites the CMU community to join them in some fun crafting projects.Note: Registration not required. No event fee.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/Spring Carnival 2024 Reunion Overview.txt"
        },
        "page_content":"Spring Carnival 2024 Reunion Overview\n\nIt\u2019s time to celebrate, show your Tartan Pride, revisit old memories and create new ones \u2014 together! This year\u2019s reunion celebration will be held on campus, April 11-14, in conjunction with Spring Carnival. We are excited to welcome back undergraduate classes ending in 4s and 9s, as well as the Class of 2023, this year. Additionally, we invite all Half Century Tartans (Classes of 1973 and prior) to attend reunion events.\n\nRegistration is required to attend both virtual and\/or in-person activities.\n\nReunion Weekend Highlights\n\nMolly\u2019s Trolleys Tours\n\nThursday, April 11",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event HLAA Presents_ Gozando y Triunfando, A Carnival Celebration on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event HLAA Presents: Gozando y Triunfando, A Carnival Celebration\n\nTitle: HLAA Presents: Gozando y Triunfando, A Carnival Celebration\nDate: April 13, 2024\nTime: 9:00 AM-12:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 12, 2024\nTime: 2:00 PM-11:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Mixed Reality_ A Virtual Reality Escape Room Experience on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 11, 2024\nTime: 8:00 AM-9:00 AM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 13, 2024\nTime: 7:00 PM-9:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 11, 2024\nTime: 7:00 PM-9:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event CMBAA\u2019s Spring Carnival Meeting on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event CMBAA\u2019s Spring Carnival Meeting\n\nTitle: CMBAA\u2019s Spring Carnival Meeting\nDate: April 13, 2024\nTime: 1:00 PM-3:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Scotch'n'Soda Theatre Carnival Show_ The Little Mermaid on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 12, 2024\nTime: 4\/12\/24 \u2013 4\/13\/2411:00 PM-1:00 AM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event The Highmark Center for Health, Wellness and Athletics Tours on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event The Highmark Center for Health, Wellness and Athletics Tours\n\nTitle: The Highmark Center for Health, Wellness and Athletics Tours\nDate: April 13, 2024\nTime: 1:00 PM-4:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Crafting with the Spring Carnival Committee on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Crafting with the Spring Carnival Committee\n\nTitle: Crafting with the Spring Carnival Committee\nDate: April 13, 2024\nTime: 2:00 PM-4:00 PM ET\n\nThe Spring Carnival Committee (SCC) invites the CMU community to join them in some fun crafting projects.Note: Registration not required. No event fee.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe other major event held in conjunction with Spring Carnival 2024 is Reunion Weekend, which is celebrated on campus from April 11-14, 2024, welcoming back undergraduate classes ending in 4s and 9s, the Class of 2023, and all Half Century Tartans (Classes of 1973 and prior).",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Which other major event is held in conjunction with Spring Carnival 2024?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nSpring Carnival 2024 Reunion Overview\n\nIt\u2019s time to celebrate, show your Tartan Pride, revisit old memories and create new ones \u2014 together! This year\u2019s reunion celebration will be held on campus, April 11-14, in conjunction with Spring Carnival. We are excited to welcome back undergraduate classes ending in 4s and 9s, as well as the Class of 2023, this year. Additionally, we invite all Half Century Tartans (Classes of 1973 and prior) to attend reunion events.\n\nRegistration is required to attend both virtual and\/or in-person activities.\n\nReunion Weekend Highlights\n\nMolly\u2019s Trolleys Tours\n\nThursday, April 11\n-----\nSpring Carnival 2024 Event HLAA Presents: Gozando y Triunfando, A Carnival Celebration\n\nTitle: HLAA Presents: Gozando y Triunfando, A Carnival Celebration\nDate: April 13, 2024\nTime: 9:00 AM-12:00 PM ET\n-----\nSpring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 12, 2024\nTime: 2:00 PM-11:00 PM ET\n-----\nSpring Carnival 2024 Event Mixed Reality: A Virtual Reality Escape Room Experience\n\nTitle: Mixed Reality: A Virtual Reality Escape Room Experience\nDate: April 11, 2024\nTime: 8:00 AM-9:00 AM ET\n-----\nSpring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 13, 2024\nTime: 7:00 PM-9:00 PM ET\n-----\nSpring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 11, 2024\nTime: 7:00 PM-9:00 PM ET\n-----\nSpring Carnival 2024 Event CMBAA\u2019s Spring Carnival Meeting\n\nTitle: CMBAA\u2019s Spring Carnival Meeting\nDate: April 13, 2024\nTime: 1:00 PM-3:00 PM ET\n-----\nSpring Carnival 2024 Event Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\n\nTitle: Scotch'n'Soda Theatre Carnival Show: The Little Mermaid\nDate: April 12, 2024\nTime: 4\/12\/24 \u2013 4\/13\/2411:00 PM-1:00 AM ET\n-----\nSpring Carnival 2024 Event The Highmark Center for Health, Wellness and Athletics Tours\n\nTitle: The Highmark Center for Health, Wellness and Athletics Tours\nDate: April 13, 2024\nTime: 1:00 PM-4:00 PM ET\n-----\nSpring Carnival 2024 Event Crafting with the Spring Carnival Committee\n\nTitle: Crafting with the Spring Carnival Committee\nDate: April 13, 2024\nTime: 2:00 PM-4:00 PM ET\n\nThe Spring Carnival Committee (SCC) invites the CMU community to join them in some fun crafting projects.Note: Registration not required. No event fee.\n-----\n\n### Response ###\n\nUser: Which other major event is held in conjunction with Spring Carnival 2024?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.8571428571,
    "recall":1.0,
    "precision":0.75,
    "A_hat":"Sunday, May 12, 2024",
    "index":25,
    "Q":"When is the main commencement ceremony?",
    "A":"Sunday, May 12",
    "category":"events",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   Bachelor\u2019s, master\u2019s and doctoral degree candidates and their guests are invited to join the main commencement ceremony on Sunday, May 12, for the conferral of all degrees.\n-   The main ceremony will include remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.\n-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"2024 Main Commencement Ceremony",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"Frequently Asked Questions\n\nCan\u2019t find an answer to your question below? Contact us at commencement@andrew.cmu.edu.\n\nCommencement 2024\n\nWhat is the difference between a diploma ceremony and the main commencement ceremony?\n\nAll graduates (bachelor\u2019s, master\u2019s and doctoral degree candidates) will be celebrated at the main commencement ceremony on Sunday, May 12. The ceremony will include a procession of graduates, conferral of degrees, remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize their graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12) and include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership.\n\nAre there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.\n-   The ceremony will take place on CMU\u2019s campus beginning at 10 a.m. and will be approximately 1.5 hours long. All guests must be seated by 9:15 a.m. for the start of the student procession. Access to guest seating will be restricted once the student procession begins.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize all graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12).\n-   Diploma ceremonies will include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership. Each ceremony is organized and customized by their college\/school\/department.\n-   Diploma ceremonies will take place both on and off campus. Locations and times for diploma ceremonies will be provided soon.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"Congratulations Graduates!\n\nCommencement Weekend: May 10-12, 2024\n\nWe\u2019re pleased to share preliminary information about the upcoming commencement exercises. During the weekend, we will honor the hard work and dedication of bachelor\u2019s, master\u2019s and doctoral degree candidates.\n\n-   On Saturday, May 11, doctoral candidates will celebrate their achievements during the President\u2019s Doctoral Candidate Reception.\n\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n\n-   Throughout the weekend, CMU\u2019s colleges, schools and departments will host diploma and doctoral hooding ceremonies for their graduates.\n\nWe will share more information about the weekend, so check back soon!",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 10.txt"
        },
        "page_content":"There are no August or December commencement ceremonies.  \n11.3.1 Withdrawal of Degree \nA degree once conferred can be withdrawn by the University under certain circumstances.  See \nthe Withdrawal of Degree Policy . \n11.4 LTI Academic Policies \n11.4.1 \u201cGrandfather\u201d policy \nA student can graduate under the policies in effect at the time that the student entered the \nprogram; or, at the student's choice, the student  can graduate under policies that are adopted \nafter the student entered the program. If it is no t realistic to follow a particular policy exactly,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 10.txt"
        },
        "page_content":"All tuition and fees must be paid in full by the due date; a student not in good financial standing \nwill be dismissed from the program. Students taking summer courses must pay tuition.   \n11.3 Graduation Ceremonies   \nThe University holds one Commencement ceremony in May of each year.  Only students who \nhave completed their degree requirements may participate in Commencement. \nThere are no August or December commencement ceremonies.  \n11.3.1 Withdrawal of Degree \nA degree once conferred can be withdrawn by the University under certain circumstances.  See \nthe Withdrawal of Degree Policy . \n11.4 LTI Academic Policies",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   Bachelor\u2019s, master\u2019s and doctoral degree candidates and their guests are invited to join the main commencement ceremony on Sunday, May 12, for the conferral of all degrees.\n-   The main ceremony will include remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.\n-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"2024 Main Commencement Ceremony",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"Frequently Asked Questions\n\nCan\u2019t find an answer to your question below? Contact us at commencement@andrew.cmu.edu.\n\nCommencement 2024\n\nWhat is the difference between a diploma ceremony and the main commencement ceremony?\n\nAll graduates (bachelor\u2019s, master\u2019s and doctoral degree candidates) will be celebrated at the main commencement ceremony on Sunday, May 12. The ceremony will include a procession of graduates, conferral of degrees, remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize their graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12) and include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership.\n\nAre there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.\n-   The ceremony will take place on CMU\u2019s campus beginning at 10 a.m. and will be approximately 1.5 hours long. All guests must be seated by 9:15 a.m. for the start of the student procession. Access to guest seating will be restricted once the student procession begins.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize all graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12).\n-   Diploma ceremonies will include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership. Each ceremony is organized and customized by their college\/school\/department.\n-   Diploma ceremonies will take place both on and off campus. Locations and times for diploma ceremonies will be provided soon.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"Congratulations Graduates!\n\nCommencement Weekend: May 10-12, 2024\n\nWe\u2019re pleased to share preliminary information about the upcoming commencement exercises. During the weekend, we will honor the hard work and dedication of bachelor\u2019s, master\u2019s and doctoral degree candidates.\n\n-   On Saturday, May 11, doctoral candidates will celebrate their achievements during the President\u2019s Doctoral Candidate Reception.\n\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n\n-   Throughout the weekend, CMU\u2019s colleges, schools and departments will host diploma and doctoral hooding ceremonies for their graduates.\n\nWe will share more information about the weekend, so check back soon!",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 10.txt"
        },
        "page_content":"There are no August or December commencement ceremonies.  \n11.3.1 Withdrawal of Degree \nA degree once conferred can be withdrawn by the University under certain circumstances.  See \nthe Withdrawal of Degree Policy . \n11.4 LTI Academic Policies \n11.4.1 \u201cGrandfather\u201d policy \nA student can graduate under the policies in effect at the time that the student entered the \nprogram; or, at the student's choice, the student  can graduate under policies that are adopted \nafter the student entered the program. If it is no t realistic to follow a particular policy exactly,",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 10.txt"
        },
        "page_content":"All tuition and fees must be paid in full by the due date; a student not in good financial standing \nwill be dismissed from the program. Students taking summer courses must pay tuition.   \n11.3 Graduation Ceremonies   \nThe University holds one Commencement ceremony in May of each year.  Only students who \nhave completed their degree requirements may participate in Commencement. \nThere are no August or December commencement ceremonies.  \n11.3.1 Withdrawal of Degree \nA degree once conferred can be withdrawn by the University under certain circumstances.  See \nthe Withdrawal of Degree Policy . \n11.4 LTI Academic Policies",
        "type":"Document"
      }
    ],
    "model_output":"\nThe main commencement ceremony will take place on Sunday, May 12, 2024.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"When is the main commencement ceremony?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\n-   Bachelor\u2019s, master\u2019s and doctoral degree candidates and their guests are invited to join the main commencement ceremony on Sunday, May 12, for the conferral of all degrees.\n-   The main ceremony will include remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.\n-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.\n-----\n2024 Main Commencement Ceremony\n-----\nFrequently Asked Questions\n\nCan\u2019t find an answer to your question below? Contact us at commencement@andrew.cmu.edu.\n\nCommencement 2024\n\nWhat is the difference between a diploma ceremony and the main commencement ceremony?\n\nAll graduates (bachelor\u2019s, master\u2019s and doctoral degree candidates) will be celebrated at the main commencement ceremony on Sunday, May 12. The ceremony will include a procession of graduates, conferral of degrees, remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.\n-----\nIn addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize their graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12) and include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership.\n\nAre there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed.\n-----\n-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.\n-   The ceremony will take place on CMU\u2019s campus beginning at 10 a.m. and will be approximately 1.5 hours long. All guests must be seated by 9:15 a.m. for the start of the student procession. Access to guest seating will be restricted once the student procession begins.\n-----\n-   In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize all graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12).\n-   Diploma ceremonies will include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership. Each ceremony is organized and customized by their college\/school\/department.\n-   Diploma ceremonies will take place both on and off campus. Locations and times for diploma ceremonies will be provided soon.\n-----\nCongratulations Graduates!\n\nCommencement Weekend: May 10-12, 2024\n\nWe\u2019re pleased to share preliminary information about the upcoming commencement exercises. During the weekend, we will honor the hard work and dedication of bachelor\u2019s, master\u2019s and doctoral degree candidates.\n\n-   On Saturday, May 11, doctoral candidates will celebrate their achievements during the President\u2019s Doctoral Candidate Reception.\n\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n-----\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n\n-   Throughout the weekend, CMU\u2019s colleges, schools and departments will host diploma and doctoral hooding ceremonies for their graduates.\n\nWe will share more information about the weekend, so check back soon!\n-----\nThere are no August or December commencement ceremonies.  \n11.3.1 Withdrawal of Degree \nA degree once conferred can be withdrawn by the University under certain circumstances.  See \nthe Withdrawal of Degree Policy . \n11.4 LTI Academic Policies \n11.4.1 \u201cGrandfather\u201d policy \nA student can graduate under the policies in effect at the time that the student entered the \nprogram; or, at the student's choice, the student  can graduate under policies that are adopted \nafter the student entered the program. If it is no t realistic to follow a particular policy exactly,\n-----\nAll tuition and fees must be paid in full by the due date; a student not in good financial standing \nwill be dismissed from the program. Students taking summer courses must pay tuition.   \n11.3 Graduation Ceremonies   \nThe University holds one Commencement ceremony in May of each year.  Only students who \nhave completed their degree requirements may participate in Commencement. \nThere are no August or December commencement ceremonies.  \n11.3.1 Withdrawal of Degree \nA degree once conferred can be withdrawn by the University under certain circumstances.  See \nthe Withdrawal of Degree Policy . \n11.4 LTI Academic Policies\n-----\n\n### Response ###\n\nUser: When is the main commencement ceremony?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"McConomy Auditorium, Cohon University Center",
    "index":26,
    "Q":"Where is the Phi Beta Kappa Initiation Ceremony located?",
    "A":"McConomy Auditorium, Cohon University Center",
    "category":"events",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"More details on the weekend schedule, including a diploma ceremony schedule, will be provided in the coming weeks.\n\nThursday, May 9\n\nPhi Beta Kappa Initiation Ceremony\nCeremony: 2\u20133 p.m.\n_McConomy Auditorium, Cohon University Center\n_Reception: 3\u20134 p.m.\nConnan Room, Cohon University Center\n\nContact:Joseph Devine\njd0x@andrew.cmu.edu \n\nJoanne Ursenbach\njoanneu@andrew.cmu.edu \n\nPresident\u2019s Graduates Toast (bachelor\u2019s students)\n3:30\u20134:30 p.m.\n_Location TBD\n_Registration required. Invitation, along with registration details, will be sent in late April.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Pi Kappa Alpha Alumni Gathering on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Pi Kappa Alpha Alumni Gathering\n\nTitle: Pi Kappa Alpha Alumni Gathering\nDate: April 12, 2024\nTime: 1:00 PM-3:00 PM ET\n\nAll PiKA undergraduates, alumni of all years, parents and their children are invited to attend this luncheon and are strongly encouraged to RSVP. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Pi Kappa Alpha community.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Beta Sigma Corporation Annual Meeting on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Beta Sigma Corporation Annual Meeting\n\nTitle: Beta Sigma Corporation Annual Meeting\nDate: April 13, 2024\nTime: 1:00 PM-3:00 PM ET\n\nJoin us for the annual meeting of the Beta Sigma Chapter of Pi Kappa Alpha with lunch included. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Beta Sigma Corporation community.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 8.txt"
        },
        "page_content":"an unwavering commitment to providing personalized attention towards meeting the unique \nindividual needs of students, alumni, and employers.  The CDPC  is located on the Lower Level \nof the University Center, 412 -268-2064  \n \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) offers a robust \nschedule of professional development opportunities.  Some are geared towards a specific \npopulation (master\u2019s students, PhD students at the beginning of their program, graduate",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 12.txt"
        },
        "page_content":"individual needs of students, alumni, and employers.  The CDPC is located on the second floor of \nthe West Wing Dormitory, 412-268-2064. \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) offers a robust \nschedule of professional development opportunities.  Some are geared towards a specific \npopulation (master\u2019s students, PhD students at  the beginning of their program, graduate \nstudents seeking tenure track positions, etc.) an d others are open to all graduate students (time \nmanagement, balancing, staying healthy).  A full schedule of programs can be found at: \nwww.cmu.edu\/graduate\/ .\u00a0\n13.9 University Libraries",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 5.txt"
        },
        "page_content":"attention towards meeting the unique individual needs of students, \nalumni, and employers. The CDPC is located on the Lower Level of the \nUniversity Center, 412-268-2064 \n \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) \noffers a robust schedule of professional development opportunities. Some \nare geared towards a specific population (master\u2019s students, PhD students \nat the beginning of their program, graduate students seeking tenure track \npositions, etc.) and others are open to all graduate students (time \nmanagement, balancing, staying healthy). A full schedule of programs can",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Delta Upsilon Reception for Alumni, Family and Friends on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Delta Upsilon Reception for Alumni, Family and Friends\n\nTitle: Delta Upsilon Reception for Alumni, Family and Friends\nDate: April 13, 2024\nTime: 4\/13\/24 \u2013 4\/14\/248:30 PM-1:00 AM ET\n\nReconnect with Delta Upsilon over heavy appetizers and drinks at a location off campus. This event is open to all DU alumni, family and friends. Food and drinks on your own. Note: Registration required. Walk-ins are welcome if space permits. No event fee. Open to the DU community and guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 5.txt"
        },
        "page_content":"the registration process orchestrated by the Office of the Dean of Student \nAffairs, located on the 3rd floor of Warner Hall. See the web site for \ninformation regarding the benefits available for domestic partners, \neligibility for domestic partner benefits, registration instructions and \nforms. \n \nMore information can be found at: \nhttp:\/\/www.studentaffairs.cmu.edu\/dean\/domestic_partner\/index.html  \n6.13 Housing \nThe University does not currently offer housing to graduate students. The \nOffice of Housing and Dining Services does provide community housing \ninformation on a very limited basis to assist graduate students who are",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 6.txt"
        },
        "page_content":"understanding of career and professional development theory, integration of technology, and \nan unwavering commitment to providing personalized attention towards meeting the unique \nindividual needs of students, alumni, and employers. The CDPC is located on the Lower Level of \nthe University Center, 412 -268- 2064. \n \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) offers a robust \nschedule of professio nal development opportunities. Some are geared towards a specific \npopulation (master\u2019s students, PhD students at the beginning of their program, graduate",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Saturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n\nNaval ROTC Commissioning\nCeremony: 1:30-2:30 p.m.\n_Auditorium, Soldiers & Sailors Memorial Hall & Museum *__4141 Fifth Avenue, Pittsburgh, PA 15213_\n\nContact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"More details on the weekend schedule, including a diploma ceremony schedule, will be provided in the coming weeks.\n\nThursday, May 9\n\nPhi Beta Kappa Initiation Ceremony\nCeremony: 2\u20133 p.m.\n_McConomy Auditorium, Cohon University Center\n_Reception: 3\u20134 p.m.\nConnan Room, Cohon University Center\n\nContact:Joseph Devine\njd0x@andrew.cmu.edu \n\nJoanne Ursenbach\njoanneu@andrew.cmu.edu \n\nPresident\u2019s Graduates Toast (bachelor\u2019s students)\n3:30\u20134:30 p.m.\n_Location TBD\n_Registration required. Invitation, along with registration details, will be sent in late April.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Pi Kappa Alpha Alumni Gathering on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Pi Kappa Alpha Alumni Gathering\n\nTitle: Pi Kappa Alpha Alumni Gathering\nDate: April 12, 2024\nTime: 1:00 PM-3:00 PM ET\n\nAll PiKA undergraduates, alumni of all years, parents and their children are invited to attend this luncheon and are strongly encouraged to RSVP. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Pi Kappa Alpha community.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Beta Sigma Corporation Annual Meeting on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Beta Sigma Corporation Annual Meeting\n\nTitle: Beta Sigma Corporation Annual Meeting\nDate: April 13, 2024\nTime: 1:00 PM-3:00 PM ET\n\nJoin us for the annual meeting of the Beta Sigma Chapter of Pi Kappa Alpha with lunch included. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Beta Sigma Corporation community.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MIIS Handbook 2023 - 2024 8.txt"
        },
        "page_content":"an unwavering commitment to providing personalized attention towards meeting the unique \nindividual needs of students, alumni, and employers.  The CDPC  is located on the Lower Level \nof the University Center, 412 -268-2064  \n \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) offers a robust \nschedule of professional development opportunities.  Some are geared towards a specific \npopulation (master\u2019s students, PhD students at the beginning of their program, graduate",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/Handbook-MSAII-2022-2023 12.txt"
        },
        "page_content":"individual needs of students, alumni, and employers.  The CDPC is located on the second floor of \nthe West Wing Dormitory, 412-268-2064. \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) offers a robust \nschedule of professional development opportunities.  Some are geared towards a specific \npopulation (master\u2019s students, PhD students at  the beginning of their program, graduate \nstudents seeking tenure track positions, etc.) an d others are open to all graduate students (time \nmanagement, balancing, staying healthy).  A full schedule of programs can be found at: \nwww.cmu.edu\/graduate\/ .\u00a0\n13.9 University Libraries",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 5.txt"
        },
        "page_content":"attention towards meeting the unique individual needs of students, \nalumni, and employers. The CDPC is located on the Lower Level of the \nUniversity Center, 412-268-2064 \n \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) \noffers a robust schedule of professional development opportunities. Some \nare geared towards a specific population (master\u2019s students, PhD students \nat the beginning of their program, graduate students seeking tenure track \npositions, etc.) and others are open to all graduate students (time \nmanagement, balancing, staying healthy). A full schedule of programs can",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Delta Upsilon Reception for Alumni, Family and Friends on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Delta Upsilon Reception for Alumni, Family and Friends\n\nTitle: Delta Upsilon Reception for Alumni, Family and Friends\nDate: April 13, 2024\nTime: 4\/13\/24 \u2013 4\/14\/248:30 PM-1:00 AM ET\n\nReconnect with Delta Upsilon over heavy appetizers and drinks at a location off campus. This event is open to all DU alumni, family and friends. Food and drinks on your own. Note: Registration required. Walk-ins are welcome if space permits. No event fee. Open to the DU community and guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MCDS Handbook 23-24 AY 5.txt"
        },
        "page_content":"the registration process orchestrated by the Office of the Dean of Student \nAffairs, located on the 3rd floor of Warner Hall. See the web site for \ninformation regarding the benefits available for domestic partners, \neligibility for domestic partner benefits, registration instructions and \nforms. \n \nMore information can be found at: \nhttp:\/\/www.studentaffairs.cmu.edu\/dean\/domestic_partner\/index.html  \n6.13 Housing \nThe University does not currently offer housing to graduate students. The \nOffice of Housing and Dining Services does provide community housing \ninformation on a very limited basis to assist graduate students who are",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/programs\/handbooks\/MLT Student Handbook 2023 - 2024 6.txt"
        },
        "page_content":"understanding of career and professional development theory, integration of technology, and \nan unwavering commitment to providing personalized attention towards meeting the unique \nindividual needs of students, alumni, and employers. The CDPC is located on the Lower Level of \nthe University Center, 412 -268- 2064. \n \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) offers a robust \nschedule of professio nal development opportunities. Some are geared towards a specific \npopulation (master\u2019s students, PhD students at the beginning of their program, graduate",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Saturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n\nNaval ROTC Commissioning\nCeremony: 1:30-2:30 p.m.\n_Auditorium, Soldiers & Sailors Memorial Hall & Museum *__4141 Fifth Avenue, Pittsburgh, PA 15213_\n\nContact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe Phi Beta Kappa Initiation Ceremony is located in the McConomy Auditorium, Cohon University Center.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"Where is the Phi Beta Kappa Initiation Ceremony located?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nMore details on the weekend schedule, including a diploma ceremony schedule, will be provided in the coming weeks.\n\nThursday, May 9\n\nPhi Beta Kappa Initiation Ceremony\nCeremony: 2\u20133 p.m.\n_McConomy Auditorium, Cohon University Center\n_Reception: 3\u20134 p.m.\nConnan Room, Cohon University Center\n\nContact:Joseph Devine\njd0x@andrew.cmu.edu \n\nJoanne Ursenbach\njoanneu@andrew.cmu.edu \n\nPresident\u2019s Graduates Toast (bachelor\u2019s students)\n3:30\u20134:30 p.m.\n_Location TBD\n_Registration required. Invitation, along with registration details, will be sent in late April.\n-----\nSpring Carnival 2024 Event Pi Kappa Alpha Alumni Gathering\n\nTitle: Pi Kappa Alpha Alumni Gathering\nDate: April 12, 2024\nTime: 1:00 PM-3:00 PM ET\n\nAll PiKA undergraduates, alumni of all years, parents and their children are invited to attend this luncheon and are strongly encouraged to RSVP. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Pi Kappa Alpha community.\n-----\nSpring Carnival 2024 Event Beta Sigma Corporation Annual Meeting\n\nTitle: Beta Sigma Corporation Annual Meeting\nDate: April 13, 2024\nTime: 1:00 PM-3:00 PM ET\n\nJoin us for the annual meeting of the Beta Sigma Chapter of Pi Kappa Alpha with lunch included. Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Beta Sigma Corporation community.\n-----\nan unwavering commitment to providing personalized attention towards meeting the unique \nindividual needs of students, alumni, and employers.  The CDPC  is located on the Lower Level \nof the University Center, 412 -268-2064  \n \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) offers a robust \nschedule of professional development opportunities.  Some are geared towards a specific \npopulation (master\u2019s students, PhD students at the beginning of their program, graduate\n-----\nindividual needs of students, alumni, and employers.  The CDPC is located on the second floor of \nthe West Wing Dormitory, 412-268-2064. \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) offers a robust \nschedule of professional development opportunities.  Some are geared towards a specific \npopulation (master\u2019s students, PhD students at  the beginning of their program, graduate \nstudents seeking tenure track positions, etc.) an d others are open to all graduate students (time \nmanagement, balancing, staying healthy).  A full schedule of programs can be found at: \nwww.cmu.edu\/graduate\/ .\u00a0\n13.9 University Libraries\n-----\nattention towards meeting the unique individual needs of students, \nalumni, and employers. The CDPC is located on the Lower Level of the \nUniversity Center, 412-268-2064 \n \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) \noffers a robust schedule of professional development opportunities. Some \nare geared towards a specific population (master\u2019s students, PhD students \nat the beginning of their program, graduate students seeking tenure track \npositions, etc.) and others are open to all graduate students (time \nmanagement, balancing, staying healthy). A full schedule of programs can\n-----\nSpring Carnival 2024 Event Delta Upsilon Reception for Alumni, Family and Friends\n\nTitle: Delta Upsilon Reception for Alumni, Family and Friends\nDate: April 13, 2024\nTime: 4\/13\/24 \u2013 4\/14\/248:30 PM-1:00 AM ET\n\nReconnect with Delta Upsilon over heavy appetizers and drinks at a location off campus. This event is open to all DU alumni, family and friends. Food and drinks on your own. Note: Registration required. Walk-ins are welcome if space permits. No event fee. Open to the DU community and guests.\n-----\nthe registration process orchestrated by the Office of the Dean of Student \nAffairs, located on the 3rd floor of Warner Hall. See the web site for \ninformation regarding the benefits available for domestic partners, \neligibility for domestic partner benefits, registration instructions and \nforms. \n \nMore information can be found at: \nhttp:\/\/www.studentaffairs.cmu.edu\/dean\/domestic_partner\/index.html  \n6.13 Housing \nThe University does not currently offer housing to graduate students. The \nOffice of Housing and Dining Services does provide community housing \ninformation on a very limited basis to assist graduate students who are\n-----\nunderstanding of career and professional development theory, integration of technology, and \nan unwavering commitment to providing personalized attention towards meeting the unique \nindividual needs of students, alumni, and employers. The CDPC is located on the Lower Level of \nthe University Center, 412 -268- 2064. \n \nThe Office of the Assistant Vice Provost for Graduate Education (AVPGE) offers a robust \nschedule of professio nal development opportunities. Some are geared towards a specific \npopulation (master\u2019s students, PhD students at the beginning of their program, graduate\n-----\nSaturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n\nNaval ROTC Commissioning\nCeremony: 1:30-2:30 p.m.\n_Auditorium, Soldiers & Sailors Memorial Hall & Museum *__4141 Fifth Avenue, Pittsburgh, PA 15213_\n\nContact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.\n-----\n\n### Response ###\n\nUser: Where is the Phi Beta Kappa Initiation Ceremony located?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.6,
    "recall":1.0,
    "precision":0.4285714286,
    "A_hat":"Saturday, May 11, 2024, from 4\u20136 p.m.",
    "index":27,
    "Q":"When is the President\u2019s Doctoral Candidate Reception?",
    "A":"Saturday, May 11",
    "category":"events",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"Congratulations Graduates!\n\nCommencement Weekend: May 10-12, 2024\n\nWe\u2019re pleased to share preliminary information about the upcoming commencement exercises. During the weekend, we will honor the hard work and dedication of bachelor\u2019s, master\u2019s and doctoral degree candidates.\n\n-   On Saturday, May 11, doctoral candidates will celebrate their achievements during the President\u2019s Doctoral Candidate Reception.\n\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Contact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.\n\nRobing and procession for graduates\n9\u201310 a.m.\nVarious locations across campus\n\nStudent procession begins9:15 a.m.\nAll guests in stadium must be seated. Access to guest seating will be restricted once the procession begins.\n\nCommencement Ceremony\n10\u201311:30 a.m._Gesling Stadium, CMU\u2019s campus_\n\nDiploma Ceremonies\nVarious times",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   Bachelor\u2019s, master\u2019s and doctoral degree candidates and their guests are invited to join the main commencement ceremony on Sunday, May 12, for the conferral of all degrees.\n-   The main ceremony will include remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.\n-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"Are there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed. \n\nThere is no limit to the number of guests for the President\u2019s Reception for Doctoral Candidates and tickets are not needed. However, we ask that all doctoral graduates register the number of guests they are planning to bring to the reception so that we can prepare accordingly. \n\nPlease note that some diploma ceremonies will limit guests based on venue capacity.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Saturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n\nNaval ROTC Commissioning\nCeremony: 1:30-2:30 p.m.\n_Auditorium, Soldiers & Sailors Memorial Hall & Museum *__4141 Fifth Avenue, Pittsburgh, PA 15213_\n\nContact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n\n-   Throughout the weekend, CMU\u2019s colleges, schools and departments will host diploma and doctoral hooding ceremonies for their graduates.\n\nWe will share more information about the weekend, so check back soon!",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"Frequently Asked Questions\n\nCan\u2019t find an answer to your question below? Contact us at commencement@andrew.cmu.edu.\n\nCommencement 2024\n\nWhat is the difference between a diploma ceremony and the main commencement ceremony?\n\nAll graduates (bachelor\u2019s, master\u2019s and doctoral degree candidates) will be celebrated at the main commencement ceremony on Sunday, May 12. The ceremony will include a procession of graduates, conferral of degrees, remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize their graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12) and include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership.\n\nAre there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Joanne Ursenbach\njoanneu@andrew.cmu.edu \n\nPresident\u2019s Graduates Toast (bachelor\u2019s students)\n3:30\u20134:30 p.m.\n_Location TBD\n_Registration required. Invitation, along with registration details, will be sent in late April.\n\nFirst Gen Graduation Recognition\nReception: 5-5:30 p.m.\nAlumni Concert Hall, _College of Fine Arts\n_Ceremony: 5:30-6:30p.m.\nKresge Theater, College of Fine Arts\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n412-268-7733\n\nFriday, May 10\n\nDiploma Ceremonies\nVarious times",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize all graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12).\n-   Diploma ceremonies will include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership. Each ceremony is organized and customized by their college\/school\/department.\n-   Diploma ceremonies will take place both on and off campus. Locations and times for diploma ceremonies will be provided soon.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"Congratulations Graduates!\n\nCommencement Weekend: May 10-12, 2024\n\nWe\u2019re pleased to share preliminary information about the upcoming commencement exercises. During the weekend, we will honor the hard work and dedication of bachelor\u2019s, master\u2019s and doctoral degree candidates.\n\n-   On Saturday, May 11, doctoral candidates will celebrate their achievements during the President\u2019s Doctoral Candidate Reception.\n\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Contact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.\n\nRobing and procession for graduates\n9\u201310 a.m.\nVarious locations across campus\n\nStudent procession begins9:15 a.m.\nAll guests in stadium must be seated. Access to guest seating will be restricted once the procession begins.\n\nCommencement Ceremony\n10\u201311:30 a.m._Gesling Stadium, CMU\u2019s campus_\n\nDiploma Ceremonies\nVarious times",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   Bachelor\u2019s, master\u2019s and doctoral degree candidates and their guests are invited to join the main commencement ceremony on Sunday, May 12, for the conferral of all degrees.\n-   The main ceremony will include remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.\n-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"Are there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed. \n\nThere is no limit to the number of guests for the President\u2019s Reception for Doctoral Candidates and tickets are not needed. However, we ask that all doctoral graduates register the number of guests they are planning to bring to the reception so that we can prepare accordingly. \n\nPlease note that some diploma ceremonies will limit guests based on venue capacity.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Saturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n\nNaval ROTC Commissioning\nCeremony: 1:30-2:30 p.m.\n_Auditorium, Soldiers & Sailors Memorial Hall & Museum *__4141 Fifth Avenue, Pittsburgh, PA 15213_\n\nContact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n\n-   Throughout the weekend, CMU\u2019s colleges, schools and departments will host diploma and doctoral hooding ceremonies for their graduates.\n\nWe will share more information about the weekend, so check back soon!",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"Frequently Asked Questions\n\nCan\u2019t find an answer to your question below? Contact us at commencement@andrew.cmu.edu.\n\nCommencement 2024\n\nWhat is the difference between a diploma ceremony and the main commencement ceremony?\n\nAll graduates (bachelor\u2019s, master\u2019s and doctoral degree candidates) will be celebrated at the main commencement ceremony on Sunday, May 12. The ceremony will include a procession of graduates, conferral of degrees, remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize their graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12) and include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership.\n\nAre there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Joanne Ursenbach\njoanneu@andrew.cmu.edu \n\nPresident\u2019s Graduates Toast (bachelor\u2019s students)\n3:30\u20134:30 p.m.\n_Location TBD\n_Registration required. Invitation, along with registration details, will be sent in late April.\n\nFirst Gen Graduation Recognition\nReception: 5-5:30 p.m.\nAlumni Concert Hall, _College of Fine Arts\n_Ceremony: 5:30-6:30p.m.\nKresge Theater, College of Fine Arts\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n412-268-7733\n\nFriday, May 10\n\nDiploma Ceremonies\nVarious times",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize all graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12).\n-   Diploma ceremonies will include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership. Each ceremony is organized and customized by their college\/school\/department.\n-   Diploma ceremonies will take place both on and off campus. Locations and times for diploma ceremonies will be provided soon.",
        "type":"Document"
      }
    ],
    "model_output":"\nThe President\u2019s Doctoral Candidate Reception will take place on Saturday, May 11, 2024, from 4\u20136 p.m. in the Tepper Building Atrium.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"When is the President\u2019s Doctoral Candidate Reception?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nCongratulations Graduates!\n\nCommencement Weekend: May 10-12, 2024\n\nWe\u2019re pleased to share preliminary information about the upcoming commencement exercises. During the weekend, we will honor the hard work and dedication of bachelor\u2019s, master\u2019s and doctoral degree candidates.\n\n-   On Saturday, May 11, doctoral candidates will celebrate their achievements during the President\u2019s Doctoral Candidate Reception.\n\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n-----\nContact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.\n\nRobing and procession for graduates\n9\u201310 a.m.\nVarious locations across campus\n\nStudent procession begins9:15 a.m.\nAll guests in stadium must be seated. Access to guest seating will be restricted once the procession begins.\n\nCommencement Ceremony\n10\u201311:30 a.m._Gesling Stadium, CMU\u2019s campus_\n\nDiploma Ceremonies\nVarious times\n-----\n-   Bachelor\u2019s, master\u2019s and doctoral degree candidates and their guests are invited to join the main commencement ceremony on Sunday, May 12, for the conferral of all degrees.\n-   The main ceremony will include remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.\n-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.\n-----\nAre there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed. \n\nThere is no limit to the number of guests for the President\u2019s Reception for Doctoral Candidates and tickets are not needed. However, we ask that all doctoral graduates register the number of guests they are planning to bring to the reception so that we can prepare accordingly. \n\nPlease note that some diploma ceremonies will limit guests based on venue capacity.\n-----\nSaturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n\nNaval ROTC Commissioning\nCeremony: 1:30-2:30 p.m.\n_Auditorium, Soldiers & Sailors Memorial Hall & Museum *__4141 Fifth Avenue, Pittsburgh, PA 15213_\n\nContact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.\n-----\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n\n-   Throughout the weekend, CMU\u2019s colleges, schools and departments will host diploma and doctoral hooding ceremonies for their graduates.\n\nWe will share more information about the weekend, so check back soon!\n-----\nFrequently Asked Questions\n\nCan\u2019t find an answer to your question below? Contact us at commencement@andrew.cmu.edu.\n\nCommencement 2024\n\nWhat is the difference between a diploma ceremony and the main commencement ceremony?\n\nAll graduates (bachelor\u2019s, master\u2019s and doctoral degree candidates) will be celebrated at the main commencement ceremony on Sunday, May 12. The ceremony will include a procession of graduates, conferral of degrees, remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.\n-----\nIn addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize their graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12) and include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership.\n\nAre there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed.\n-----\nJoanne Ursenbach\njoanneu@andrew.cmu.edu \n\nPresident\u2019s Graduates Toast (bachelor\u2019s students)\n3:30\u20134:30 p.m.\n_Location TBD\n_Registration required. Invitation, along with registration details, will be sent in late April.\n\nFirst Gen Graduation Recognition\nReception: 5-5:30 p.m.\nAlumni Concert Hall, _College of Fine Arts\n_Ceremony: 5:30-6:30p.m.\nKresge Theater, College of Fine Arts\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n412-268-7733\n\nFriday, May 10\n\nDiploma Ceremonies\nVarious times\n-----\n-   In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize all graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12).\n-   Diploma ceremonies will include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership. Each ceremony is organized and customized by their college\/school\/department.\n-   Diploma ceremonies will take place both on and off campus. Locations and times for diploma ceremonies will be provided soon.\n-----\n\n### Response ###\n\nUser: When is the President\u2019s Doctoral Candidate Reception?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":1.0,
    "f1":1.0,
    "recall":1.0,
    "precision":1.0,
    "A_hat":"8 a.m.",
    "index":28,
    "Q":"When will the Gesling Stadium open to guests on Sunday, May 12?",
    "A":"8 am",
    "category":"events",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Contact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.\n\nRobing and procession for graduates\n9\u201310 a.m.\nVarious locations across campus\n\nStudent procession begins9:15 a.m.\nAll guests in stadium must be seated. Access to guest seating will be restricted once the procession begins.\n\nCommencement Ceremony\n10\u201311:30 a.m._Gesling Stadium, CMU\u2019s campus_\n\nDiploma Ceremonies\nVarious times",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Saturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n\nNaval ROTC Commissioning\nCeremony: 1:30-2:30 p.m.\n_Auditorium, Soldiers & Sailors Memorial Hall & Museum *__4141 Fifth Avenue, Pittsburgh, PA 15213_\n\nContact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n\n-   Throughout the weekend, CMU\u2019s colleges, schools and departments will host diploma and doctoral hooding ceremonies for their graduates.\n\nWe will share more information about the weekend, so check back soon!",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"Congratulations Graduates!\n\nCommencement Weekend: May 10-12, 2024\n\nWe\u2019re pleased to share preliminary information about the upcoming commencement exercises. During the weekend, we will honor the hard work and dedication of bachelor\u2019s, master\u2019s and doctoral degree candidates.\n\n-   On Saturday, May 11, doctoral candidates will celebrate their achievements during the President\u2019s Doctoral Candidate Reception.\n\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   Bachelor\u2019s, master\u2019s and doctoral degree candidates and their guests are invited to join the main commencement ceremony on Sunday, May 12, for the conferral of all degrees.\n-   The main ceremony will include remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.\n-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize their graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12) and include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership.\n\nAre there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth! on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Buggy Bash on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Buggy Bash\n\nTitle: Buggy Bash\nDate: April 12, 2024\nTime: 7:00 PM-9:00 PM ET\n\nBuggy Bash RD24 is here! Join buggy students and alumni for a night of food, trivia and our finals lead truck auction. This auction will be open on the Buggy Alumni Association website on April 11 until 11 p.m.Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Buggy community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Contact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n412-268-7733\n\nFriday, May 10\n\nDiploma Ceremonies\nVarious times\n\nSenior Leadership Recognition Ceremony\n4\u20135:30 p.m.\nWiegand Gym, Cohon University Center\nUndergraduate students and their guests by invitation only. This ceremony recognizes nominated seniors who have reflected upon their specific leadership contributions during their time at CMU.\n\nSaturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth! on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Contact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.\n\nRobing and procession for graduates\n9\u201310 a.m.\nVarious locations across campus\n\nStudent procession begins9:15 a.m.\nAll guests in stadium must be seated. Access to guest seating will be restricted once the procession begins.\n\nCommencement Ceremony\n10\u201311:30 a.m._Gesling Stadium, CMU\u2019s campus_\n\nDiploma Ceremonies\nVarious times",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Saturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n\nNaval ROTC Commissioning\nCeremony: 1:30-2:30 p.m.\n_Auditorium, Soldiers & Sailors Memorial Hall & Museum *__4141 Fifth Avenue, Pittsburgh, PA 15213_\n\nContact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n\n-   Throughout the weekend, CMU\u2019s colleges, schools and departments will host diploma and doctoral hooding ceremonies for their graduates.\n\nWe will share more information about the weekend, so check back soon!",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Overview.txt"
        },
        "page_content":"Congratulations Graduates!\n\nCommencement Weekend: May 10-12, 2024\n\nWe\u2019re pleased to share preliminary information about the upcoming commencement exercises. During the weekend, we will honor the hard work and dedication of bachelor\u2019s, master\u2019s and doctoral degree candidates.\n\n-   On Saturday, May 11, doctoral candidates will celebrate their achievements during the President\u2019s Doctoral Candidate Reception.\n\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"-   Bachelor\u2019s, master\u2019s and doctoral degree candidates and their guests are invited to join the main commencement ceremony on Sunday, May 12, for the conferral of all degrees.\n-   The main ceremony will include remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.\n-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Frequently Asked Questions.txt"
        },
        "page_content":"In addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize their graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12) and include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership.\n\nAre there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth! on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Buggy Bash on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Buggy Bash\n\nTitle: Buggy Bash\nDate: April 12, 2024\nTime: 7:00 PM-9:00 PM ET\n\nBuggy Bash RD24 is here! Join buggy students and alumni for a night of food, trivia and our finals lead truck auction. This auction will be open on the Buggy Alumni Association website on April 11 until 11 p.m.Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Buggy community and their guests.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/commencement\/2024 Commencement Ceremonies and Schedule.txt"
        },
        "page_content":"Contact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n412-268-7733\n\nFriday, May 10\n\nDiploma Ceremonies\nVarious times\n\nSenior Leadership Recognition Ceremony\n4\u20135:30 p.m.\nWiegand Gym, Cohon University Center\nUndergraduate students and their guests by invitation only. This ceremony recognizes nominated seniors who have reflected upon their specific leadership contributions during their time at CMU.\n\nSaturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth! on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.",
        "type":"Document"
      }
    ],
    "model_output":"\nGesling Stadium will open to guests at 8 a.m. on Sunday, May 12.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"When will the Gesling Stadium open to guests on Sunday, May 12?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nContact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.\n\nRobing and procession for graduates\n9\u201310 a.m.\nVarious locations across campus\n\nStudent procession begins9:15 a.m.\nAll guests in stadium must be seated. Access to guest seating will be restricted once the procession begins.\n\nCommencement Ceremony\n10\u201311:30 a.m._Gesling Stadium, CMU\u2019s campus_\n\nDiploma Ceremonies\nVarious times\n-----\nSaturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n\nNaval ROTC Commissioning\nCeremony: 1:30-2:30 p.m.\n_Auditorium, Soldiers & Sailors Memorial Hall & Museum *__4141 Fifth Avenue, Pittsburgh, PA 15213_\n\nContact:\nMike Dankomdanko@andrew.cmu.edu \n\nThe President\u2019s Reception in honor of CMU\u2019s Doctoral Candidates\n4\u20136 p.m.\nTepper Building Atrium\n\nSunday, May 12\n\nGesling Stadium opens to guests\n8 a.m.\n-----\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n\n-   Throughout the weekend, CMU\u2019s colleges, schools and departments will host diploma and doctoral hooding ceremonies for their graduates.\n\nWe will share more information about the weekend, so check back soon!\n-----\nCongratulations Graduates!\n\nCommencement Weekend: May 10-12, 2024\n\nWe\u2019re pleased to share preliminary information about the upcoming commencement exercises. During the weekend, we will honor the hard work and dedication of bachelor\u2019s, master\u2019s and doctoral degree candidates.\n\n-   On Saturday, May 11, doctoral candidates will celebrate their achievements during the President\u2019s Doctoral Candidate Reception.\n\n-   On Sunday, May 12, bachelor\u2019s, master\u2019s and doctoral degree candidates will come together for a full commencement ceremony in Gesling Stadium on CMU\u2019s campus.\n-----\n-   Bachelor\u2019s, master\u2019s and doctoral degree candidates and their guests are invited to join the main commencement ceremony on Sunday, May 12, for the conferral of all degrees.\n-   The main ceremony will include remarks from the president, keynote speaker, student speaker and academic deans, in addition to recognition of the honorary degree recipients.\n-   There is no limit on number of guests who can attend the main commencement ceremony and tickets are not needed.\n-----\nIn addition to the main commencement ceremony, each college\/school\/department will host a diploma ceremony to recognize their graduating students. Diploma ceremonies will be held over the course of the weekend (Friday, May 10\u2013Sunday, May 12) and include the presentation of diplomas to graduates, hooding of doctoral candidates and remarks from their college\/school\/department leadership.\n\nAre there any restrictions for guests?\n\nGuests are welcome to attend commencement exercises. There is no limit to the number of guests for the main commencement ceremony and tickets are not needed.\n-----\nSpring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.\n-----\nSpring Carnival 2024 Event Buggy Bash\n\nTitle: Buggy Bash\nDate: April 12, 2024\nTime: 7:00 PM-9:00 PM ET\n\nBuggy Bash RD24 is here! Join buggy students and alumni for a night of food, trivia and our finals lead truck auction. This auction will be open on the Buggy Alumni Association website on April 11 until 11 p.m.Note: Registration required. Walk-ins are welcome as space permits. No event fee. This event is open to the Buggy community and their guests.\n-----\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu \n\nSam Colavecchio\nscolavec@andrew.cmu.edu \n412-268-7733\n\nFriday, May 10\n\nDiploma Ceremonies\nVarious times\n\nSenior Leadership Recognition Ceremony\n4\u20135:30 p.m.\nWiegand Gym, Cohon University Center\nUndergraduate students and their guests by invitation only. This ceremony recognizes nominated seniors who have reflected upon their specific leadership contributions during their time at CMU.\n\nSaturday, May 11\n\nDiploma Ceremonies\nVarious times\n\nCenter for Student Diversity and Inclusion Ceremony\n_Noon\u20132:30 p.m.\nSimmons Auditorium, Tepper Building_\n\nContact:\nM. Shernell Smith\nmssmith@andrew.cmu.edu\n-----\nSpring Carnival 2024 Event Booth!\n\nTitle: Booth!\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nThis year\u2019s theme is \u201cLet the Games Begin.\u201d Be sure to check out every booth and cast your vote for the top choice in each category. Note: No registration required. No event fee. This event is open to the entire CMU community and their guests.Weekend hours:Thursday: 3:30 to 11 p.m.Friday & Saturday: 11 a.m. to 11 p.m.\n-----\n\n### Response ###\n\nUser: When will the Gesling Stadium open to guests on Sunday, May 12?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  },
  {
    "em":0.0,
    "f1":0.4,
    "recall":0.5,
    "precision":0.3333333333,
    "A_hat":"April 14, 2024",
    "index":29,
    "Q":"When does Build Week end for Spring Carnival 2024?",
    "A":"April 11",
    "category":"events",
    "filepath":"..\/annotations\/leon-annotated.json",
    "retrieved":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth Build & Midway Cam on April 5, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth Build & Midway Cam\n\nTitle: Booth Build & Midway Cam\nDate: April 5, 2024\nTime: 4\/5\/24 \u2013 4\/14\/245:00 PM-12:00 PM ET\n\nFollow all of the action via livestream starting with Move On on April 5, followed by Build Week and finally the completed Booths beginning on April 11 through April 14.Note: Add event during registration for calendar hold. Link will be added prior to Build Week.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Here to Stay_ Celebrating 40 Years at the Architecture Archives on April 14, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 14, 2024\nTime: 4\/14\/24 \u2013 4\/15\/2412:00 PM-12:00 AM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Here to Stay_ Celebrating 40 Years at the Architecture Archives on April 10, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 10, 2024\nTime: 8:00 AM-6:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Here to Stay_ Celebrating 40 Years at the Architecture Archives on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 12, 2024\nTime: 8:00 AM-6:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Here to Stay_ Celebrating 40 Years at the Architecture Archives on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 13, 2024\nTime: 9:00 AM-9:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Here to Stay_ Celebrating 40 Years at the Architecture Archives on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 11, 2024\nTime: 8:00 AM-6:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 11, 2024\nTime: 3:30 PM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area. Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Douse-a-Dean on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Douse-a-Dean\n\nTitle: Douse-a-Dean\nDate: April 12, 2024\nTime: 12:00 PM-2:30 PM ET",
        "type":"Document"
      }
    ],
    "reranked":[
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Booth Build & Midway Cam on April 5, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Booth Build & Midway Cam\n\nTitle: Booth Build & Midway Cam\nDate: April 5, 2024\nTime: 4\/5\/24 \u2013 4\/14\/245:00 PM-12:00 PM ET\n\nFollow all of the action via livestream starting with Move On on April 5, followed by Build Week and finally the completed Booths beginning on April 11 through April 14.Note: Add event during registration for calendar hold. Link will be added prior to Build Week.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Here to Stay_ Celebrating 40 Years at the Architecture Archives on April 14, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 14, 2024\nTime: 4\/14\/24 \u2013 4\/15\/2412:00 PM-12:00 AM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Here to Stay_ Celebrating 40 Years at the Architecture Archives on April 10, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 10, 2024\nTime: 8:00 AM-6:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Here to Stay_ Celebrating 40 Years at the Architecture Archives on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 12, 2024\nTime: 8:00 AM-6:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Here to Stay_ Celebrating 40 Years at the Architecture Archives on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 13, 2024\nTime: 9:00 AM-9:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Here to Stay_ Celebrating 40 Years at the Architecture Archives on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 11, 2024\nTime: 8:00 AM-6:00 PM ET",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 13, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Carnival Rides on April 11, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 11, 2024\nTime: 3:30 PM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area. Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.",
        "type":"Document"
      },
      {
        "lc_attributes":{

        },
        "lc_secrets":{

        },
        "metadata":{
          "source":"..\/data\/events\/carnival\/out\/events\/Spring Carnival 2024 event Douse-a-Dean on April 12, 2024.txt"
        },
        "page_content":"Spring Carnival 2024 Event Douse-a-Dean\n\nTitle: Douse-a-Dean\nDate: April 12, 2024\nTime: 12:00 PM-2:30 PM ET",
        "type":"Document"
      }
    ],
    "model_output":"\nBuild Week for Spring Carnival 2024 ends on April 14, 2024.",
    "generation_prompt":"[INST] <<SYS>>### Instructions ###\nYou are a question-answering assistant at Carnegie Mellon University (CMU). You are tasked with answering factual questions CMU or the Language Technologies Institute (LTI) at CMU. Use the following documents as context to answer the question in one sentence. You are looking for the answer to the question \"When does Build Week end for Spring Carnival 2024?\".\n\n### Examples ###\n\nUser: Who taught the course 51-425 Design Center: Beginning Book Arts Lab in the semester Fall 2023?\nResponse: Joseph Dicey.\nUser: Which model did Fatemehsadat Mireshghallah find in their paper to have an AUC of 0.81?\nResponse: OPT-125M.\nUser: Who is sponsoring the event Carnival Activities Tent at CMU's Spring Carnival 2024?\nResponse: The Spring Carnival Committee and the CMU Alumni Association.\nUser: What are Graham Neubig's research interests?\nResponse: Machine Translation, Natural Language Processing, Spoken Language Processing, Machine Learning.<<\/SYS>>\n\n### Context ###\n\n-----\nSpring Carnival 2024 Event Booth Build & Midway Cam\n\nTitle: Booth Build & Midway Cam\nDate: April 5, 2024\nTime: 4\/5\/24 \u2013 4\/14\/245:00 PM-12:00 PM ET\n\nFollow all of the action via livestream starting with Move On on April 5, followed by Build Week and finally the completed Booths beginning on April 11 through April 14.Note: Add event during registration for calendar hold. Link will be added prior to Build Week.\n-----\nSpring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 14, 2024\nTime: 4\/14\/24 \u2013 4\/15\/2412:00 PM-12:00 AM ET\n-----\nSpring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 10, 2024\nTime: 8:00 AM-6:00 PM ET\n-----\nSpring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 12, 2024\nTime: 8:00 AM-6:00 PM ET\n-----\nSpring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 13, 2024\nTime: 9:00 AM-9:00 PM ET\n-----\nSpring Carnival 2024 Event Here to Stay: Celebrating 40 Years at the Architecture Archives\n\nTitle: Here to Stay: Celebrating 40 Years at the Architecture Archives\nDate: April 11, 2024\nTime: 8:00 AM-6:00 PM ET\n-----\nSpring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 12, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.\n-----\nSpring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 13, 2024\nTime: 11:00 AM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.\n-----\nSpring Carnival 2024 Event Carnival Rides\n\nTitle: Carnival Rides\nDate: April 11, 2024\nTime: 3:30 PM-11:00 PM ET\n\nBe sure to check out all of the rides and activities, including traditions like ferris wheel and swings. There will also be a special kid's ride area. Note: No registration required. Individual tickets or all-day passes may be purchased onsite at the vendor\u2019s ticketing booth.Weekend hours:Thursday: 3:30-11 p.m.Friday & Saturday: 11 a.m.-11 p.m.\n-----\nSpring Carnival 2024 Event Douse-a-Dean\n\nTitle: Douse-a-Dean\nDate: April 12, 2024\nTime: 12:00 PM-2:30 PM ET\n-----\n\n### Response ###\n\nUser: When does Build Week end for Spring Carnival 2024?\nResponse: [\/INST]\n",
    "Q_aug":"-"
  }
]